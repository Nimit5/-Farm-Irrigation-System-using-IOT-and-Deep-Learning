{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "name": "IOT A2.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X44X1-jfNZ0X"
      },
      "source": [
        "Importing Necessary libraries"
      ],
      "id": "X44X1-jfNZ0X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX_ssfC43iZ9"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import r2_score\n",
        "import random\n"
      ],
      "id": "vX_ssfC43iZ9",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de70d289"
      },
      "source": [
        "\n",
        "# Importing the dataset\n",
        "\n",
        "data=pd.read_csv(\"IOT_Assignment_2_data_regression_sensor_range.csv\")\n",
        "X=data[[\"Humidity(%)\",\"Temperature(Â°C)\"]]\n",
        "y=data[[\"WaterFlow(%)\"]]\n"
      ],
      "id": "de70d289",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a66j1MFsVmH-"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=0)\n"
      ],
      "id": "a66j1MFsVmH-",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL3_oNOvTVKZ"
      },
      "source": [
        "\n",
        "# Dictionary to store hyper parameters as key and its corresponding mean absolute error as value\n",
        "optim_param={}"
      ],
      "id": "nL3_oNOvTVKZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaW4PhPI9W8t"
      },
      "source": [
        "\n",
        "# Trying with batch size 16 and 32\n",
        "batch=[16,32]\n",
        "\n",
        "# Trying with epotch - 1000,2000\n",
        "epo=[1000,2000]\n",
        "\n",
        "# Trying with number of neurons at layer 1 = 6,7,8,9,10\n",
        "for n1 in range(6,11):\n",
        "    \n",
        "    # Trying with number of neurons at layer 2 = 6,7,8,9,10\n",
        "    for n2 in range(6,11):\n",
        "        \n",
        "        # Initialising the ANN\n",
        "        model = Sequential()\n",
        "\n",
        "        # Adding the input layer and the first hidden layer\n",
        "        model.add(Dense(units = n1, activation = 'relu', input_dim = 2))\n",
        "\n",
        "        # Adding the second hidden layer\n",
        "        model.add(Dense(units = n2, activation = 'relu'))\n",
        "\n",
        "        # Adding the output layer\n",
        "        model.add(Dense(units = 1))\n",
        "\n",
        "        # Compiling the ANN\n",
        "        opt = Adam(learning_rate=0.001)\n",
        "        model.compile(optimizer = opt, loss = 'mae',metrics=['mae'])\n",
        "\n",
        "        # Fitting the ANN to the Training set\n",
        "\n",
        "        for b_size in batch:\n",
        "            for ep in epo:\n",
        "                history=model.fit(X_train, y_train,validation_data=(X_test, y_test),batch_size = b_size,epochs=ep)\n",
        "                optim_param[(n1,n2,b_size,ep)]=history.history['mae'][-1]\n",
        "    "
      ],
      "id": "SaW4PhPI9W8t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8I60rjD9p-4"
      },
      "source": [
        "optim_param"
      ],
      "id": "N8I60rjD9p-4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn1jXVvljd8r"
      },
      "source": [
        "sorted(optim_param.items(),key=lambda x:x[1],reverse=True)"
      ],
      "id": "Nn1jXVvljd8r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-QLx1ns6ppF"
      },
      "source": [
        "From above results we got some combinations with good results, so now trying with that combinations."
      ],
      "id": "l-QLx1ns6ppF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwc-jinIqOaq"
      },
      "source": [
        "# Dictionary to store hyper parameters as key and its corresponding mean absolute error as value\n",
        "\n",
        "final_param={}"
      ],
      "id": "Nwc-jinIqOaq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDwmfKJbjgP_"
      },
      "source": [
        "# Trying this combination of (n1,n2)\n",
        "neurons=[(5,5),(6,8),(7,9),(2,3),(4,5),(8,10)]\n",
        "\n",
        "# Trying with epotch - 1000,2000\n",
        "epo=[1000,2000]\n",
        "\n",
        "for item in neurons:        \n",
        "      # Initialising the ANN\n",
        "      model = Sequential()\n",
        "\n",
        "      # Adding the input layer and the first hidden layer\n",
        "      model.add(Dense(units = item[0], activation = 'relu', input_dim = 2))\n",
        "\n",
        "      # Adding the second hidden layer\n",
        "      model.add(Dense(units = item[1], activation = 'relu'))\n",
        "\n",
        "      # Adding the output layer\n",
        "      model.add(Dense(units = 1))\n",
        "\n",
        "      # Compiling the ANN\n",
        "      opt = Adam(learning_rate=0.001)\n",
        "      model.compile(optimizer = opt, loss = 'mae',metrics=['mae'])\n",
        "\n",
        "      # Fitting the ANN to the Training set\n",
        "\n",
        "      for ep in epo:\n",
        "          history=model.fit(X_train, y_train,validation_data=(X_test, y_test),batch_size =32,epochs=ep)\n",
        "          final_param[(item[0],item[1],ep)]=history.history['mae'][-1]\n",
        "    "
      ],
      "id": "BDwmfKJbjgP_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Biya5HyLkj",
        "outputId": "6d7934e3-ff8f-4603-9efa-aff613216321"
      },
      "source": [
        "final_param"
      ],
      "id": "i9Biya5HyLkj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(2, 3, 1000): 26.96527099609375,\n",
              " (2, 3, 2000): 26.9652042388916,\n",
              " (4, 5, 1000): 26.96524429321289,\n",
              " (4, 5, 2000): 26.9652156829834,\n",
              " (5, 5, 1000): 26.965240478515625,\n",
              " (5, 5, 2000): 26.965219497680664,\n",
              " (6, 8, 1000): 12.388099670410156,\n",
              " (6, 8, 2000): 11.841711044311523,\n",
              " (7, 9, 1000): 12.205471992492676,\n",
              " (7, 9, 2000): 11.095603942871094,\n",
              " (8, 10, 1000): 12.096131324768066,\n",
              " (8, 10, 2000): 11.601614952087402}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rbby3xS7Fan"
      },
      "source": [
        "From above operation we found that \n",
        "\n",
        "*   Number of neurons at Layer1=7 \n",
        "*   Number of neurons at Layer2=9 \n",
        "*   Epoch=2000 \n",
        "*   Batch size=32\n",
        "\n",
        "is the best combination.So training model on this parameters."
      ],
      "id": "3Rbby3xS7Fan"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq494QOBU3Qb"
      },
      "source": [
        "# initializer - used to reproduce same model\n",
        "# seed = 1 "
      ],
      "id": "mq494QOBU3Qb",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjZRGteIQXS_",
        "outputId": "4dc83702-879b-411d-a14b-74aaad39de41"
      },
      "source": [
        "initializer = tf.keras.initializers.GlorotNormal(1)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(units = 7, activation = 'relu', input_dim = 2,kernel_initializer=initializer))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(units = 9, activation = 'relu',kernel_initializer=initializer))\n",
        "\n",
        "# Adding the output layer\n",
        "model.add(Dense(units = 1,kernel_initializer=initializer))\n",
        "\n",
        "# Compiling the ANN\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer = opt, loss = 'mae',metrics=['mae'])\n",
        "\n",
        "# Fitting the ANN to the Training set\n",
        "history=model.fit(X_train, y_train,validation_data=(X_test, y_test),batch_size =32,epochs=2000)\n",
        "    "
      ],
      "id": "SjZRGteIQXS_",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2000\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 28.5375 - mae: 28.5375 - val_loss: 20.7294 - val_mae: 20.7294\n",
            "Epoch 2/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 28.2103 - mae: 28.2103 - val_loss: 20.5121 - val_mae: 20.5121\n",
            "Epoch 3/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.9510 - mae: 27.9510 - val_loss: 20.3847 - val_mae: 20.3847\n",
            "Epoch 4/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.7411 - mae: 27.7411 - val_loss: 20.3613 - val_mae: 20.3613\n",
            "Epoch 5/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.5717 - mae: 27.5717 - val_loss: 20.3494 - val_mae: 20.3494\n",
            "Epoch 6/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.4502 - mae: 27.4502 - val_loss: 20.3371 - val_mae: 20.3371\n",
            "Epoch 7/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.3913 - mae: 27.3913 - val_loss: 20.3149 - val_mae: 20.3149\n",
            "Epoch 8/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.3432 - mae: 27.3432 - val_loss: 20.2879 - val_mae: 20.2879\n",
            "Epoch 9/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.3092 - mae: 27.3092 - val_loss: 20.2597 - val_mae: 20.2597\n",
            "Epoch 10/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.2659 - mae: 27.2659 - val_loss: 20.2318 - val_mae: 20.2318\n",
            "Epoch 11/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.2338 - mae: 27.2338 - val_loss: 20.2032 - val_mae: 20.2032\n",
            "Epoch 12/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.2023 - mae: 27.2023 - val_loss: 20.1741 - val_mae: 20.1741\n",
            "Epoch 13/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 27.1758 - mae: 27.1758 - val_loss: 20.1469 - val_mae: 20.1469\n",
            "Epoch 14/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.1479 - mae: 27.1479 - val_loss: 20.1192 - val_mae: 20.1192\n",
            "Epoch 15/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 27.1181 - mae: 27.1181 - val_loss: 20.0914 - val_mae: 20.0914\n",
            "Epoch 16/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.0897 - mae: 27.0897 - val_loss: 20.0605 - val_mae: 20.0605\n",
            "Epoch 17/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.0494 - mae: 27.0494 - val_loss: 20.0092 - val_mae: 20.0092\n",
            "Epoch 18/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 27.0029 - mae: 27.0029 - val_loss: 19.9556 - val_mae: 19.9556\n",
            "Epoch 19/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.9747 - mae: 26.9747 - val_loss: 19.9152 - val_mae: 19.9152\n",
            "Epoch 20/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 26.9420 - mae: 26.9420 - val_loss: 19.8777 - val_mae: 19.8777\n",
            "Epoch 21/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.9081 - mae: 26.9081 - val_loss: 19.8410 - val_mae: 19.8410\n",
            "Epoch 22/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 26.8739 - mae: 26.8739 - val_loss: 19.8091 - val_mae: 19.8091\n",
            "Epoch 23/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 26.8396 - mae: 26.8396 - val_loss: 19.7845 - val_mae: 19.7845\n",
            "Epoch 24/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.8009 - mae: 26.8009 - val_loss: 19.7340 - val_mae: 19.7340\n",
            "Epoch 25/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.7593 - mae: 26.7593 - val_loss: 19.6850 - val_mae: 19.6850\n",
            "Epoch 26/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.7203 - mae: 26.7203 - val_loss: 19.6380 - val_mae: 19.6380\n",
            "Epoch 27/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 26.6861 - mae: 26.6861 - val_loss: 19.6011 - val_mae: 19.6011\n",
            "Epoch 28/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.6436 - mae: 26.6436 - val_loss: 19.5589 - val_mae: 19.5589\n",
            "Epoch 29/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.6101 - mae: 26.6101 - val_loss: 19.5342 - val_mae: 19.5342\n",
            "Epoch 30/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.5713 - mae: 26.5713 - val_loss: 19.4970 - val_mae: 19.4970\n",
            "Epoch 31/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.5353 - mae: 26.5353 - val_loss: 19.4719 - val_mae: 19.4719\n",
            "Epoch 32/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.5031 - mae: 26.5031 - val_loss: 19.4541 - val_mae: 19.4541\n",
            "Epoch 33/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.4800 - mae: 26.4800 - val_loss: 19.4492 - val_mae: 19.4492\n",
            "Epoch 34/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 26.4267 - mae: 26.4267 - val_loss: 19.4214 - val_mae: 19.4214\n",
            "Epoch 35/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.3941 - mae: 26.3941 - val_loss: 19.4095 - val_mae: 19.4095\n",
            "Epoch 36/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.3538 - mae: 26.3538 - val_loss: 19.3947 - val_mae: 19.3947\n",
            "Epoch 37/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.3091 - mae: 26.3091 - val_loss: 19.3730 - val_mae: 19.3730\n",
            "Epoch 38/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.2644 - mae: 26.2644 - val_loss: 19.3560 - val_mae: 19.3560\n",
            "Epoch 39/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.2239 - mae: 26.2239 - val_loss: 19.3313 - val_mae: 19.3313\n",
            "Epoch 40/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 26.1881 - mae: 26.1881 - val_loss: 19.3260 - val_mae: 19.3260\n",
            "Epoch 41/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 26.1304 - mae: 26.1304 - val_loss: 19.3006 - val_mae: 19.3006\n",
            "Epoch 42/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 26.0763 - mae: 26.0763 - val_loss: 19.2502 - val_mae: 19.2502\n",
            "Epoch 43/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 26.0237 - mae: 26.0237 - val_loss: 19.2122 - val_mae: 19.2122\n",
            "Epoch 44/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.9735 - mae: 25.9735 - val_loss: 19.1781 - val_mae: 19.1781\n",
            "Epoch 45/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 25.9140 - mae: 25.9140 - val_loss: 19.1535 - val_mae: 19.1535\n",
            "Epoch 46/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 25.8648 - mae: 25.8648 - val_loss: 19.1217 - val_mae: 19.1217\n",
            "Epoch 47/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.7992 - mae: 25.7992 - val_loss: 19.0747 - val_mae: 19.0747\n",
            "Epoch 48/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 25.7406 - mae: 25.7406 - val_loss: 19.0237 - val_mae: 19.0237\n",
            "Epoch 49/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 25.6704 - mae: 25.6704 - val_loss: 18.9849 - val_mae: 18.9849\n",
            "Epoch 50/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.6168 - mae: 25.6168 - val_loss: 18.9671 - val_mae: 18.9671\n",
            "Epoch 51/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 25.5379 - mae: 25.5379 - val_loss: 18.9296 - val_mae: 18.9296\n",
            "Epoch 52/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 25.4683 - mae: 25.4683 - val_loss: 18.8677 - val_mae: 18.8677\n",
            "Epoch 53/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.4037 - mae: 25.4037 - val_loss: 18.8284 - val_mae: 18.8284\n",
            "Epoch 54/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 25.3257 - mae: 25.3257 - val_loss: 18.7903 - val_mae: 18.7903\n",
            "Epoch 55/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.2398 - mae: 25.2398 - val_loss: 18.7299 - val_mae: 18.7299\n",
            "Epoch 56/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.1529 - mae: 25.1529 - val_loss: 18.6643 - val_mae: 18.6643\n",
            "Epoch 57/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 25.0756 - mae: 25.0756 - val_loss: 18.6180 - val_mae: 18.6180\n",
            "Epoch 58/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 24.9983 - mae: 24.9983 - val_loss: 18.5918 - val_mae: 18.5918\n",
            "Epoch 59/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.8965 - mae: 24.8965 - val_loss: 18.5320 - val_mae: 18.5320\n",
            "Epoch 60/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 24.8017 - mae: 24.8017 - val_loss: 18.4588 - val_mae: 18.4588\n",
            "Epoch 61/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.7217 - mae: 24.7217 - val_loss: 18.4172 - val_mae: 18.4172\n",
            "Epoch 62/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.6141 - mae: 24.6141 - val_loss: 18.3638 - val_mae: 18.3638\n",
            "Epoch 63/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.5031 - mae: 24.5031 - val_loss: 18.3000 - val_mae: 18.3000\n",
            "Epoch 64/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.3862 - mae: 24.3862 - val_loss: 18.2321 - val_mae: 18.2321\n",
            "Epoch 65/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 24.2774 - mae: 24.2774 - val_loss: 18.1700 - val_mae: 18.1700\n",
            "Epoch 66/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.1649 - mae: 24.1649 - val_loss: 18.1151 - val_mae: 18.1151\n",
            "Epoch 67/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 24.0321 - mae: 24.0321 - val_loss: 18.0258 - val_mae: 18.0258\n",
            "Epoch 68/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 23.9119 - mae: 23.9119 - val_loss: 17.9665 - val_mae: 17.9665\n",
            "Epoch 69/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 23.8015 - mae: 23.8015 - val_loss: 17.9153 - val_mae: 17.9153\n",
            "Epoch 70/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 23.6526 - mae: 23.6526 - val_loss: 17.8263 - val_mae: 17.8263\n",
            "Epoch 71/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 23.4930 - mae: 23.4930 - val_loss: 17.7257 - val_mae: 17.7257\n",
            "Epoch 72/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 23.3545 - mae: 23.3545 - val_loss: 17.6386 - val_mae: 17.6386\n",
            "Epoch 73/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 23.1896 - mae: 23.1896 - val_loss: 17.5562 - val_mae: 17.5562\n",
            "Epoch 74/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 23.0395 - mae: 23.0395 - val_loss: 17.4581 - val_mae: 17.4581\n",
            "Epoch 75/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 22.8580 - mae: 22.8580 - val_loss: 17.3658 - val_mae: 17.3658\n",
            "Epoch 76/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 22.7133 - mae: 22.7133 - val_loss: 17.3034 - val_mae: 17.3034\n",
            "Epoch 77/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 22.5375 - mae: 22.5375 - val_loss: 17.2159 - val_mae: 17.2159\n",
            "Epoch 78/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 22.3468 - mae: 22.3468 - val_loss: 17.0979 - val_mae: 17.0979\n",
            "Epoch 79/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 22.1597 - mae: 22.1597 - val_loss: 16.9789 - val_mae: 16.9789\n",
            "Epoch 80/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 21.9596 - mae: 21.9596 - val_loss: 16.8538 - val_mae: 16.8538\n",
            "Epoch 81/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 21.7512 - mae: 21.7512 - val_loss: 16.7588 - val_mae: 16.7588\n",
            "Epoch 82/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 21.5412 - mae: 21.5412 - val_loss: 16.6395 - val_mae: 16.6395\n",
            "Epoch 83/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 21.3544 - mae: 21.3544 - val_loss: 16.5291 - val_mae: 16.5291\n",
            "Epoch 84/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 21.0761 - mae: 21.0761 - val_loss: 16.3796 - val_mae: 16.3796\n",
            "Epoch 85/2000\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 20.8642 - mae: 20.8642 - val_loss: 16.2500 - val_mae: 16.2500\n",
            "Epoch 86/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 20.6596 - mae: 20.6596 - val_loss: 16.1213 - val_mae: 16.1213\n",
            "Epoch 87/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 20.3861 - mae: 20.3861 - val_loss: 15.9680 - val_mae: 15.9680\n",
            "Epoch 88/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 20.1265 - mae: 20.1265 - val_loss: 15.8130 - val_mae: 15.8130\n",
            "Epoch 89/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 19.8541 - mae: 19.8541 - val_loss: 15.6491 - val_mae: 15.6491\n",
            "Epoch 90/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 19.5532 - mae: 19.5532 - val_loss: 15.4425 - val_mae: 15.4425\n",
            "Epoch 91/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 19.2974 - mae: 19.2974 - val_loss: 15.2903 - val_mae: 15.2903\n",
            "Epoch 92/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 19.0049 - mae: 19.0049 - val_loss: 15.1013 - val_mae: 15.1013\n",
            "Epoch 93/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 18.7574 - mae: 18.7574 - val_loss: 14.9352 - val_mae: 14.9352\n",
            "Epoch 94/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 18.4275 - mae: 18.4275 - val_loss: 14.7643 - val_mae: 14.7643\n",
            "Epoch 95/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 18.1452 - mae: 18.1452 - val_loss: 14.6073 - val_mae: 14.6073\n",
            "Epoch 96/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 17.8146 - mae: 17.8146 - val_loss: 14.4485 - val_mae: 14.4485\n",
            "Epoch 97/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 17.4945 - mae: 17.4945 - val_loss: 14.3209 - val_mae: 14.3209\n",
            "Epoch 98/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 17.1839 - mae: 17.1839 - val_loss: 14.1741 - val_mae: 14.1741\n",
            "Epoch 99/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 16.8467 - mae: 16.8467 - val_loss: 13.9323 - val_mae: 13.9323\n",
            "Epoch 100/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 16.6214 - mae: 16.6214 - val_loss: 13.7781 - val_mae: 13.7781\n",
            "Epoch 101/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 16.4224 - mae: 16.4224 - val_loss: 13.6317 - val_mae: 13.6317\n",
            "Epoch 102/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 16.2313 - mae: 16.2313 - val_loss: 13.4365 - val_mae: 13.4365\n",
            "Epoch 103/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 16.0724 - mae: 16.0724 - val_loss: 13.2237 - val_mae: 13.2237\n",
            "Epoch 104/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 15.9590 - mae: 15.9590 - val_loss: 13.0191 - val_mae: 13.0191\n",
            "Epoch 105/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 15.8618 - mae: 15.8618 - val_loss: 12.7797 - val_mae: 12.7797\n",
            "Epoch 106/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 15.7250 - mae: 15.7250 - val_loss: 12.4587 - val_mae: 12.4587\n",
            "Epoch 107/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 15.6560 - mae: 15.6560 - val_loss: 12.3061 - val_mae: 12.3061\n",
            "Epoch 108/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 15.5514 - mae: 15.5514 - val_loss: 12.0783 - val_mae: 12.0783\n",
            "Epoch 109/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 15.4771 - mae: 15.4771 - val_loss: 11.9156 - val_mae: 11.9156\n",
            "Epoch 110/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 15.3718 - mae: 15.3718 - val_loss: 11.6302 - val_mae: 11.6302\n",
            "Epoch 111/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 15.2920 - mae: 15.2920 - val_loss: 11.3939 - val_mae: 11.3939\n",
            "Epoch 112/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 15.2222 - mae: 15.2222 - val_loss: 11.2002 - val_mae: 11.2002\n",
            "Epoch 113/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 15.1330 - mae: 15.1330 - val_loss: 11.1226 - val_mae: 11.1226\n",
            "Epoch 114/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 15.0723 - mae: 15.0723 - val_loss: 10.9821 - val_mae: 10.9821\n",
            "Epoch 115/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.9992 - mae: 14.9992 - val_loss: 10.8177 - val_mae: 10.8177\n",
            "Epoch 116/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.9331 - mae: 14.9331 - val_loss: 10.6455 - val_mae: 10.6455\n",
            "Epoch 117/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.8753 - mae: 14.8753 - val_loss: 10.4897 - val_mae: 10.4897\n",
            "Epoch 118/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.7988 - mae: 14.7988 - val_loss: 10.4186 - val_mae: 10.4186\n",
            "Epoch 119/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.7462 - mae: 14.7462 - val_loss: 10.2985 - val_mae: 10.2985\n",
            "Epoch 120/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.6693 - mae: 14.6693 - val_loss: 10.1747 - val_mae: 10.1747\n",
            "Epoch 121/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.6306 - mae: 14.6306 - val_loss: 10.1198 - val_mae: 10.1198\n",
            "Epoch 122/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.5876 - mae: 14.5876 - val_loss: 9.9408 - val_mae: 9.9408\n",
            "Epoch 123/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.5163 - mae: 14.5163 - val_loss: 9.8809 - val_mae: 9.8809\n",
            "Epoch 124/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.4730 - mae: 14.4730 - val_loss: 9.8124 - val_mae: 9.8124\n",
            "Epoch 125/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.4358 - mae: 14.4358 - val_loss: 9.8026 - val_mae: 9.8026\n",
            "Epoch 126/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.3986 - mae: 14.3986 - val_loss: 9.6994 - val_mae: 9.6994\n",
            "Epoch 127/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.3529 - mae: 14.3529 - val_loss: 9.6349 - val_mae: 9.6349\n",
            "Epoch 128/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.3165 - mae: 14.3165 - val_loss: 9.5998 - val_mae: 9.5998\n",
            "Epoch 129/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 14.3013 - mae: 14.3013 - val_loss: 9.4670 - val_mae: 9.4670\n",
            "Epoch 130/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.2543 - mae: 14.2543 - val_loss: 9.4070 - val_mae: 9.4070\n",
            "Epoch 131/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.2219 - mae: 14.2219 - val_loss: 9.3986 - val_mae: 9.3986\n",
            "Epoch 132/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.1912 - mae: 14.1912 - val_loss: 9.3598 - val_mae: 9.3598\n",
            "Epoch 133/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.1844 - mae: 14.1844 - val_loss: 9.1896 - val_mae: 9.1896\n",
            "Epoch 134/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 14.1317 - mae: 14.1317 - val_loss: 9.1337 - val_mae: 9.1337\n",
            "Epoch 135/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.1011 - mae: 14.1011 - val_loss: 9.1677 - val_mae: 9.1677\n",
            "Epoch 136/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 14.0864 - mae: 14.0864 - val_loss: 9.1479 - val_mae: 9.1479\n",
            "Epoch 137/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.0463 - mae: 14.0463 - val_loss: 9.0061 - val_mae: 9.0061\n",
            "Epoch 138/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.0367 - mae: 14.0367 - val_loss: 8.8866 - val_mae: 8.8866\n",
            "Epoch 139/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 14.0050 - mae: 14.0050 - val_loss: 8.8343 - val_mae: 8.8343\n",
            "Epoch 140/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.9792 - mae: 13.9792 - val_loss: 8.8133 - val_mae: 8.8133\n",
            "Epoch 141/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.9594 - mae: 13.9594 - val_loss: 8.7908 - val_mae: 8.7908\n",
            "Epoch 142/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.9389 - mae: 13.9389 - val_loss: 8.7736 - val_mae: 8.7736\n",
            "Epoch 143/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.9383 - mae: 13.9383 - val_loss: 8.6294 - val_mae: 8.6294\n",
            "Epoch 144/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.9001 - mae: 13.9001 - val_loss: 8.6023 - val_mae: 8.6023\n",
            "Epoch 145/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.8863 - mae: 13.8863 - val_loss: 8.6552 - val_mae: 8.6552\n",
            "Epoch 146/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.8586 - mae: 13.8586 - val_loss: 8.5410 - val_mae: 8.5410\n",
            "Epoch 147/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.8361 - mae: 13.8361 - val_loss: 8.5221 - val_mae: 8.5221\n",
            "Epoch 148/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.8150 - mae: 13.8150 - val_loss: 8.4513 - val_mae: 8.4513\n",
            "Epoch 149/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.7965 - mae: 13.7965 - val_loss: 8.3971 - val_mae: 8.3971\n",
            "Epoch 150/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.7922 - mae: 13.7922 - val_loss: 8.3130 - val_mae: 8.3130\n",
            "Epoch 151/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.7623 - mae: 13.7623 - val_loss: 8.3054 - val_mae: 8.3054\n",
            "Epoch 152/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.7486 - mae: 13.7486 - val_loss: 8.2741 - val_mae: 8.2741\n",
            "Epoch 153/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 13.7170 - mae: 13.7170 - val_loss: 8.3014 - val_mae: 8.3014\n",
            "Epoch 154/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.7034 - mae: 13.7034 - val_loss: 8.3106 - val_mae: 8.3106\n",
            "Epoch 155/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.6909 - mae: 13.6909 - val_loss: 8.2384 - val_mae: 8.2384\n",
            "Epoch 156/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.6741 - mae: 13.6741 - val_loss: 8.1716 - val_mae: 8.1716\n",
            "Epoch 157/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.6644 - mae: 13.6644 - val_loss: 8.1136 - val_mae: 8.1136\n",
            "Epoch 158/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.6591 - mae: 13.6591 - val_loss: 8.1493 - val_mae: 8.1493\n",
            "Epoch 159/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.6280 - mae: 13.6280 - val_loss: 8.1233 - val_mae: 8.1233\n",
            "Epoch 160/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.6080 - mae: 13.6080 - val_loss: 8.0692 - val_mae: 8.0692\n",
            "Epoch 161/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.6117 - mae: 13.6117 - val_loss: 8.0094 - val_mae: 8.0094\n",
            "Epoch 162/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.5924 - mae: 13.5924 - val_loss: 7.9453 - val_mae: 7.9453\n",
            "Epoch 163/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.5696 - mae: 13.5696 - val_loss: 7.9495 - val_mae: 7.9495\n",
            "Epoch 164/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.5684 - mae: 13.5684 - val_loss: 7.9101 - val_mae: 7.9101\n",
            "Epoch 165/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.5500 - mae: 13.5500 - val_loss: 7.9204 - val_mae: 7.9204\n",
            "Epoch 166/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.5417 - mae: 13.5417 - val_loss: 7.9506 - val_mae: 7.9506\n",
            "Epoch 167/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.5321 - mae: 13.5321 - val_loss: 7.9405 - val_mae: 7.9405\n",
            "Epoch 168/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.5173 - mae: 13.5173 - val_loss: 7.9620 - val_mae: 7.9620\n",
            "Epoch 169/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.5132 - mae: 13.5132 - val_loss: 7.9586 - val_mae: 7.9586\n",
            "Epoch 170/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.5048 - mae: 13.5048 - val_loss: 7.8921 - val_mae: 7.8921\n",
            "Epoch 171/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.5001 - mae: 13.5001 - val_loss: 7.9183 - val_mae: 7.9183\n",
            "Epoch 172/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.4849 - mae: 13.4849 - val_loss: 7.9070 - val_mae: 7.9070\n",
            "Epoch 173/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.4855 - mae: 13.4855 - val_loss: 7.8731 - val_mae: 7.8731\n",
            "Epoch 174/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.4902 - mae: 13.4902 - val_loss: 7.9331 - val_mae: 7.9331\n",
            "Epoch 175/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.4656 - mae: 13.4656 - val_loss: 7.9581 - val_mae: 7.9581\n",
            "Epoch 176/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.4810 - mae: 13.4810 - val_loss: 8.0142 - val_mae: 8.0142\n",
            "Epoch 177/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.4385 - mae: 13.4385 - val_loss: 7.8983 - val_mae: 7.8983\n",
            "Epoch 178/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.4282 - mae: 13.4282 - val_loss: 7.8901 - val_mae: 7.8901\n",
            "Epoch 179/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.4293 - mae: 13.4293 - val_loss: 7.8306 - val_mae: 7.8306\n",
            "Epoch 180/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.4089 - mae: 13.4089 - val_loss: 7.8136 - val_mae: 7.8136\n",
            "Epoch 181/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.4243 - mae: 13.4243 - val_loss: 7.8882 - val_mae: 7.8882\n",
            "Epoch 182/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.3877 - mae: 13.3877 - val_loss: 7.8835 - val_mae: 7.8835\n",
            "Epoch 183/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.3852 - mae: 13.3852 - val_loss: 7.8562 - val_mae: 7.8562\n",
            "Epoch 184/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.3736 - mae: 13.3736 - val_loss: 7.8856 - val_mae: 7.8856\n",
            "Epoch 185/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.3675 - mae: 13.3675 - val_loss: 7.8545 - val_mae: 7.8545\n",
            "Epoch 186/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.3562 - mae: 13.3562 - val_loss: 7.8801 - val_mae: 7.8801\n",
            "Epoch 187/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.3400 - mae: 13.3400 - val_loss: 7.8524 - val_mae: 7.8524\n",
            "Epoch 188/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.3535 - mae: 13.3535 - val_loss: 7.7891 - val_mae: 7.7891\n",
            "Epoch 189/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.3295 - mae: 13.3295 - val_loss: 7.8280 - val_mae: 7.8280\n",
            "Epoch 190/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.3246 - mae: 13.3246 - val_loss: 7.7864 - val_mae: 7.7864\n",
            "Epoch 191/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.3079 - mae: 13.3079 - val_loss: 7.8111 - val_mae: 7.8111\n",
            "Epoch 192/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.3062 - mae: 13.3062 - val_loss: 7.8318 - val_mae: 7.8318\n",
            "Epoch 193/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.2925 - mae: 13.2925 - val_loss: 7.7826 - val_mae: 7.7826\n",
            "Epoch 194/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.2864 - mae: 13.2864 - val_loss: 7.7631 - val_mae: 7.7631\n",
            "Epoch 195/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.2895 - mae: 13.2895 - val_loss: 7.7549 - val_mae: 7.7549\n",
            "Epoch 196/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.2824 - mae: 13.2824 - val_loss: 7.7298 - val_mae: 7.7298\n",
            "Epoch 197/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.2670 - mae: 13.2670 - val_loss: 7.7332 - val_mae: 7.7332\n",
            "Epoch 198/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.2705 - mae: 13.2705 - val_loss: 7.7731 - val_mae: 7.7731\n",
            "Epoch 199/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.2530 - mae: 13.2530 - val_loss: 7.7176 - val_mae: 7.7176\n",
            "Epoch 200/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.2545 - mae: 13.2545 - val_loss: 7.6641 - val_mae: 7.6641\n",
            "Epoch 201/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.2357 - mae: 13.2357 - val_loss: 7.6437 - val_mae: 7.6437\n",
            "Epoch 202/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.2462 - mae: 13.2462 - val_loss: 7.6939 - val_mae: 7.6939\n",
            "Epoch 203/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.2222 - mae: 13.2222 - val_loss: 7.6698 - val_mae: 7.6698\n",
            "Epoch 204/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.2215 - mae: 13.2215 - val_loss: 7.6184 - val_mae: 7.6184\n",
            "Epoch 205/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.2172 - mae: 13.2172 - val_loss: 7.6137 - val_mae: 7.6137\n",
            "Epoch 206/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1983 - mae: 13.1983 - val_loss: 7.5818 - val_mae: 7.5818\n",
            "Epoch 207/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.2388 - mae: 13.2388 - val_loss: 7.4988 - val_mae: 7.4988\n",
            "Epoch 208/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1976 - mae: 13.1976 - val_loss: 7.4827 - val_mae: 7.4827\n",
            "Epoch 209/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1876 - mae: 13.1876 - val_loss: 7.4697 - val_mae: 7.4697\n",
            "Epoch 210/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1764 - mae: 13.1764 - val_loss: 7.4575 - val_mae: 7.4575\n",
            "Epoch 211/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1601 - mae: 13.1601 - val_loss: 7.4685 - val_mae: 7.4685\n",
            "Epoch 212/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1609 - mae: 13.1609 - val_loss: 7.4346 - val_mae: 7.4346\n",
            "Epoch 213/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1503 - mae: 13.1503 - val_loss: 7.4399 - val_mae: 7.4399\n",
            "Epoch 214/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1428 - mae: 13.1428 - val_loss: 7.4235 - val_mae: 7.4235\n",
            "Epoch 215/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1377 - mae: 13.1377 - val_loss: 7.4191 - val_mae: 7.4191\n",
            "Epoch 216/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.1323 - mae: 13.1323 - val_loss: 7.3573 - val_mae: 7.3573\n",
            "Epoch 217/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1465 - mae: 13.1465 - val_loss: 7.3941 - val_mae: 7.3941\n",
            "Epoch 218/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1093 - mae: 13.1093 - val_loss: 7.3551 - val_mae: 7.3551\n",
            "Epoch 219/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1057 - mae: 13.1057 - val_loss: 7.3338 - val_mae: 7.3338\n",
            "Epoch 220/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.1031 - mae: 13.1031 - val_loss: 7.3412 - val_mae: 7.3412\n",
            "Epoch 221/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0896 - mae: 13.0896 - val_loss: 7.3024 - val_mae: 7.3024\n",
            "Epoch 222/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.0845 - mae: 13.0845 - val_loss: 7.3334 - val_mae: 7.3334\n",
            "Epoch 223/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0863 - mae: 13.0863 - val_loss: 7.3111 - val_mae: 7.3111\n",
            "Epoch 224/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.1002 - mae: 13.1002 - val_loss: 7.2340 - val_mae: 7.2340\n",
            "Epoch 225/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.0727 - mae: 13.0727 - val_loss: 7.2314 - val_mae: 7.2314\n",
            "Epoch 226/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 13.0547 - mae: 13.0547 - val_loss: 7.2291 - val_mae: 7.2291\n",
            "Epoch 227/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0834 - mae: 13.0834 - val_loss: 7.2866 - val_mae: 7.2866\n",
            "Epoch 228/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0469 - mae: 13.0469 - val_loss: 7.2297 - val_mae: 7.2297\n",
            "Epoch 229/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.0469 - mae: 13.0469 - val_loss: 7.2297 - val_mae: 7.2297\n",
            "Epoch 230/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.0379 - mae: 13.0379 - val_loss: 7.2198 - val_mae: 7.2198\n",
            "Epoch 231/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.0355 - mae: 13.0355 - val_loss: 7.2211 - val_mae: 7.2211\n",
            "Epoch 232/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0369 - mae: 13.0369 - val_loss: 7.1672 - val_mae: 7.1672\n",
            "Epoch 233/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.0150 - mae: 13.0150 - val_loss: 7.1628 - val_mae: 7.1628\n",
            "Epoch 234/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13.0200 - mae: 13.0200 - val_loss: 7.2418 - val_mae: 7.2418\n",
            "Epoch 235/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 13.0181 - mae: 13.0181 - val_loss: 7.1718 - val_mae: 7.1718\n",
            "Epoch 236/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9978 - mae: 12.9978 - val_loss: 7.1427 - val_mae: 7.1427\n",
            "Epoch 237/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 13.0015 - mae: 13.0015 - val_loss: 7.1476 - val_mae: 7.1476\n",
            "Epoch 238/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.9909 - mae: 12.9909 - val_loss: 7.1456 - val_mae: 7.1456\n",
            "Epoch 239/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.9825 - mae: 12.9825 - val_loss: 7.1394 - val_mae: 7.1394\n",
            "Epoch 240/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9822 - mae: 12.9822 - val_loss: 7.0941 - val_mae: 7.0941\n",
            "Epoch 241/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.9679 - mae: 12.9679 - val_loss: 7.1016 - val_mae: 7.1016\n",
            "Epoch 242/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.9678 - mae: 12.9678 - val_loss: 7.0709 - val_mae: 7.0709\n",
            "Epoch 243/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.9629 - mae: 12.9629 - val_loss: 7.0940 - val_mae: 7.0940\n",
            "Epoch 244/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9565 - mae: 12.9565 - val_loss: 7.1027 - val_mae: 7.1027\n",
            "Epoch 245/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.9809 - mae: 12.9809 - val_loss: 7.0472 - val_mae: 7.0472\n",
            "Epoch 246/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9618 - mae: 12.9618 - val_loss: 7.0883 - val_mae: 7.0883\n",
            "Epoch 247/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9429 - mae: 12.9429 - val_loss: 7.0731 - val_mae: 7.0731\n",
            "Epoch 248/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9420 - mae: 12.9420 - val_loss: 7.0310 - val_mae: 7.0310\n",
            "Epoch 249/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.9329 - mae: 12.9329 - val_loss: 7.0552 - val_mae: 7.0552\n",
            "Epoch 250/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.9306 - mae: 12.9306 - val_loss: 7.0446 - val_mae: 7.0446\n",
            "Epoch 251/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.9324 - mae: 12.9324 - val_loss: 7.0512 - val_mae: 7.0512\n",
            "Epoch 252/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.9178 - mae: 12.9178 - val_loss: 7.0327 - val_mae: 7.0327\n",
            "Epoch 253/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.9153 - mae: 12.9153 - val_loss: 7.0336 - val_mae: 7.0336\n",
            "Epoch 254/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9212 - mae: 12.9212 - val_loss: 7.0030 - val_mae: 7.0030\n",
            "Epoch 255/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9009 - mae: 12.9009 - val_loss: 7.0063 - val_mae: 7.0063\n",
            "Epoch 256/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9393 - mae: 12.9393 - val_loss: 6.9946 - val_mae: 6.9946\n",
            "Epoch 257/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.9263 - mae: 12.9263 - val_loss: 7.0165 - val_mae: 7.0165\n",
            "Epoch 258/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9084 - mae: 12.9084 - val_loss: 6.9650 - val_mae: 6.9650\n",
            "Epoch 259/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.9128 - mae: 12.9128 - val_loss: 7.0199 - val_mae: 7.0199\n",
            "Epoch 260/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.9081 - mae: 12.9081 - val_loss: 6.9738 - val_mae: 6.9738\n",
            "Epoch 261/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.8848 - mae: 12.8848 - val_loss: 7.0466 - val_mae: 7.0466\n",
            "Epoch 262/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8924 - mae: 12.8924 - val_loss: 6.9725 - val_mae: 6.9725\n",
            "Epoch 263/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8822 - mae: 12.8822 - val_loss: 6.9676 - val_mae: 6.9676\n",
            "Epoch 264/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.8748 - mae: 12.8748 - val_loss: 6.9506 - val_mae: 6.9506\n",
            "Epoch 265/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8710 - mae: 12.8710 - val_loss: 6.9617 - val_mae: 6.9617\n",
            "Epoch 266/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8667 - mae: 12.8667 - val_loss: 6.9464 - val_mae: 6.9464\n",
            "Epoch 267/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8613 - mae: 12.8613 - val_loss: 6.9488 - val_mae: 6.9488\n",
            "Epoch 268/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8672 - mae: 12.8672 - val_loss: 6.9456 - val_mae: 6.9456\n",
            "Epoch 269/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8704 - mae: 12.8704 - val_loss: 6.9210 - val_mae: 6.9210\n",
            "Epoch 270/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.8580 - mae: 12.8580 - val_loss: 6.9327 - val_mae: 6.9327\n",
            "Epoch 271/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8661 - mae: 12.8661 - val_loss: 6.9424 - val_mae: 6.9424\n",
            "Epoch 272/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.8547 - mae: 12.8547 - val_loss: 6.9350 - val_mae: 6.9350\n",
            "Epoch 273/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8570 - mae: 12.8570 - val_loss: 6.8796 - val_mae: 6.8796\n",
            "Epoch 274/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8532 - mae: 12.8532 - val_loss: 6.9109 - val_mae: 6.9109\n",
            "Epoch 275/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8387 - mae: 12.8387 - val_loss: 6.8548 - val_mae: 6.8548\n",
            "Epoch 276/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.8410 - mae: 12.8410 - val_loss: 6.8663 - val_mae: 6.8663\n",
            "Epoch 277/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8346 - mae: 12.8346 - val_loss: 6.8505 - val_mae: 6.8505\n",
            "Epoch 278/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8374 - mae: 12.8374 - val_loss: 6.8290 - val_mae: 6.8290\n",
            "Epoch 279/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8331 - mae: 12.8331 - val_loss: 6.8780 - val_mae: 6.8780\n",
            "Epoch 280/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8457 - mae: 12.8457 - val_loss: 6.8519 - val_mae: 6.8519\n",
            "Epoch 281/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8311 - mae: 12.8311 - val_loss: 6.8128 - val_mae: 6.8128\n",
            "Epoch 282/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.8328 - mae: 12.8328 - val_loss: 6.8069 - val_mae: 6.8069\n",
            "Epoch 283/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8126 - mae: 12.8126 - val_loss: 6.8387 - val_mae: 6.8387\n",
            "Epoch 284/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8439 - mae: 12.8439 - val_loss: 6.8358 - val_mae: 6.8358\n",
            "Epoch 285/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.8472 - mae: 12.8472 - val_loss: 6.7903 - val_mae: 6.7903\n",
            "Epoch 286/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.8505 - mae: 12.8505 - val_loss: 6.8515 - val_mae: 6.8515\n",
            "Epoch 287/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.8311 - mae: 12.8311 - val_loss: 6.7892 - val_mae: 6.7892\n",
            "Epoch 288/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8169 - mae: 12.8169 - val_loss: 6.8134 - val_mae: 6.8134\n",
            "Epoch 289/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.8092 - mae: 12.8092 - val_loss: 6.7829 - val_mae: 6.7829\n",
            "Epoch 290/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.7982 - mae: 12.7982 - val_loss: 6.7842 - val_mae: 6.7842\n",
            "Epoch 291/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7988 - mae: 12.7988 - val_loss: 6.7600 - val_mae: 6.7600\n",
            "Epoch 292/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7987 - mae: 12.7987 - val_loss: 6.7793 - val_mae: 6.7793\n",
            "Epoch 293/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7860 - mae: 12.7860 - val_loss: 6.7519 - val_mae: 6.7519\n",
            "Epoch 294/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7926 - mae: 12.7926 - val_loss: 6.7572 - val_mae: 6.7572\n",
            "Epoch 295/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7826 - mae: 12.7826 - val_loss: 6.7421 - val_mae: 6.7421\n",
            "Epoch 296/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7791 - mae: 12.7791 - val_loss: 6.7354 - val_mae: 6.7354\n",
            "Epoch 297/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.7830 - mae: 12.7830 - val_loss: 6.7208 - val_mae: 6.7208\n",
            "Epoch 298/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7809 - mae: 12.7809 - val_loss: 6.7270 - val_mae: 6.7270\n",
            "Epoch 299/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7747 - mae: 12.7747 - val_loss: 6.7347 - val_mae: 6.7347\n",
            "Epoch 300/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7725 - mae: 12.7725 - val_loss: 6.7261 - val_mae: 6.7261\n",
            "Epoch 301/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.7913 - mae: 12.7913 - val_loss: 6.7095 - val_mae: 6.7095\n",
            "Epoch 302/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7639 - mae: 12.7639 - val_loss: 6.6985 - val_mae: 6.6985\n",
            "Epoch 303/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7639 - mae: 12.7639 - val_loss: 6.6986 - val_mae: 6.6986\n",
            "Epoch 304/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7573 - mae: 12.7573 - val_loss: 6.7038 - val_mae: 6.7038\n",
            "Epoch 305/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.7660 - mae: 12.7660 - val_loss: 6.6762 - val_mae: 6.6762\n",
            "Epoch 306/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.7603 - mae: 12.7603 - val_loss: 6.6793 - val_mae: 6.6793\n",
            "Epoch 307/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7922 - mae: 12.7922 - val_loss: 6.7803 - val_mae: 6.7803\n",
            "Epoch 308/2000\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 12.7798 - mae: 12.7798 - val_loss: 6.6698 - val_mae: 6.6698\n",
            "Epoch 309/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7635 - mae: 12.7635 - val_loss: 6.6612 - val_mae: 6.6612\n",
            "Epoch 310/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.7564 - mae: 12.7564 - val_loss: 6.6685 - val_mae: 6.6685\n",
            "Epoch 311/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7455 - mae: 12.7455 - val_loss: 6.6605 - val_mae: 6.6605\n",
            "Epoch 312/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7569 - mae: 12.7569 - val_loss: 6.6440 - val_mae: 6.6440\n",
            "Epoch 313/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7384 - mae: 12.7384 - val_loss: 6.6380 - val_mae: 6.6380\n",
            "Epoch 314/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7277 - mae: 12.7277 - val_loss: 6.6413 - val_mae: 6.6413\n",
            "Epoch 315/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7362 - mae: 12.7362 - val_loss: 6.6128 - val_mae: 6.6128\n",
            "Epoch 316/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.7236 - mae: 12.7236 - val_loss: 6.6075 - val_mae: 6.6075\n",
            "Epoch 317/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.7248 - mae: 12.7248 - val_loss: 6.6186 - val_mae: 6.6186\n",
            "Epoch 318/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7197 - mae: 12.7197 - val_loss: 6.5989 - val_mae: 6.5989\n",
            "Epoch 319/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.7137 - mae: 12.7137 - val_loss: 6.5821 - val_mae: 6.5821\n",
            "Epoch 320/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.7144 - mae: 12.7144 - val_loss: 6.5989 - val_mae: 6.5989\n",
            "Epoch 321/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.7140 - mae: 12.7140 - val_loss: 6.5741 - val_mae: 6.5741\n",
            "Epoch 322/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7093 - mae: 12.7093 - val_loss: 6.5880 - val_mae: 6.5880\n",
            "Epoch 323/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.7014 - mae: 12.7014 - val_loss: 6.5692 - val_mae: 6.5692\n",
            "Epoch 324/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.7131 - mae: 12.7131 - val_loss: 6.5543 - val_mae: 6.5543\n",
            "Epoch 325/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6960 - mae: 12.6960 - val_loss: 6.5891 - val_mae: 6.5891\n",
            "Epoch 326/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6932 - mae: 12.6932 - val_loss: 6.5279 - val_mae: 6.5279\n",
            "Epoch 327/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6907 - mae: 12.6907 - val_loss: 6.5546 - val_mae: 6.5546\n",
            "Epoch 328/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6896 - mae: 12.6896 - val_loss: 6.5123 - val_mae: 6.5123\n",
            "Epoch 329/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6771 - mae: 12.6771 - val_loss: 6.5335 - val_mae: 6.5335\n",
            "Epoch 330/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6757 - mae: 12.6757 - val_loss: 6.5172 - val_mae: 6.5172\n",
            "Epoch 331/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6666 - mae: 12.6666 - val_loss: 6.5163 - val_mae: 6.5163\n",
            "Epoch 332/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6632 - mae: 12.6632 - val_loss: 6.4881 - val_mae: 6.4881\n",
            "Epoch 333/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6686 - mae: 12.6686 - val_loss: 6.5141 - val_mae: 6.5141\n",
            "Epoch 334/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6540 - mae: 12.6540 - val_loss: 6.4804 - val_mae: 6.4804\n",
            "Epoch 335/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6669 - mae: 12.6669 - val_loss: 6.5049 - val_mae: 6.5049\n",
            "Epoch 336/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.6611 - mae: 12.6611 - val_loss: 6.4702 - val_mae: 6.4702\n",
            "Epoch 337/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6552 - mae: 12.6552 - val_loss: 6.4667 - val_mae: 6.4667\n",
            "Epoch 338/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6441 - mae: 12.6441 - val_loss: 6.4730 - val_mae: 6.4730\n",
            "Epoch 339/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6477 - mae: 12.6477 - val_loss: 6.4659 - val_mae: 6.4659\n",
            "Epoch 340/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6436 - mae: 12.6436 - val_loss: 6.4404 - val_mae: 6.4404\n",
            "Epoch 341/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.6341 - mae: 12.6341 - val_loss: 6.4440 - val_mae: 6.4440\n",
            "Epoch 342/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6281 - mae: 12.6281 - val_loss: 6.4420 - val_mae: 6.4420\n",
            "Epoch 343/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.6300 - mae: 12.6300 - val_loss: 6.4300 - val_mae: 6.4300\n",
            "Epoch 344/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6196 - mae: 12.6196 - val_loss: 6.4419 - val_mae: 6.4419\n",
            "Epoch 345/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6180 - mae: 12.6180 - val_loss: 6.4259 - val_mae: 6.4259\n",
            "Epoch 346/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6210 - mae: 12.6210 - val_loss: 6.4081 - val_mae: 6.4081\n",
            "Epoch 347/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6139 - mae: 12.6139 - val_loss: 6.4332 - val_mae: 6.4332\n",
            "Epoch 348/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.6169 - mae: 12.6169 - val_loss: 6.4095 - val_mae: 6.4095\n",
            "Epoch 349/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.6256 - mae: 12.6256 - val_loss: 6.4277 - val_mae: 6.4277\n",
            "Epoch 350/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6323 - mae: 12.6323 - val_loss: 6.4020 - val_mae: 6.4020\n",
            "Epoch 351/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.6295 - mae: 12.6295 - val_loss: 6.3968 - val_mae: 6.3968\n",
            "Epoch 352/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5976 - mae: 12.5976 - val_loss: 6.4000 - val_mae: 6.4000\n",
            "Epoch 353/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5950 - mae: 12.5950 - val_loss: 6.3989 - val_mae: 6.3989\n",
            "Epoch 354/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5932 - mae: 12.5932 - val_loss: 6.3726 - val_mae: 6.3726\n",
            "Epoch 355/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.5922 - mae: 12.5922 - val_loss: 6.3878 - val_mae: 6.3878\n",
            "Epoch 356/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5805 - mae: 12.5805 - val_loss: 6.3593 - val_mae: 6.3593\n",
            "Epoch 357/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5846 - mae: 12.5846 - val_loss: 6.3639 - val_mae: 6.3639\n",
            "Epoch 358/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5815 - mae: 12.5815 - val_loss: 6.3591 - val_mae: 6.3591\n",
            "Epoch 359/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.5795 - mae: 12.5795 - val_loss: 6.3566 - val_mae: 6.3566\n",
            "Epoch 360/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5783 - mae: 12.5783 - val_loss: 6.3499 - val_mae: 6.3499\n",
            "Epoch 361/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.5691 - mae: 12.5691 - val_loss: 6.3515 - val_mae: 6.3515\n",
            "Epoch 362/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5660 - mae: 12.5660 - val_loss: 6.3446 - val_mae: 6.3446\n",
            "Epoch 363/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5728 - mae: 12.5728 - val_loss: 6.3350 - val_mae: 6.3350\n",
            "Epoch 364/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5617 - mae: 12.5617 - val_loss: 6.3305 - val_mae: 6.3305\n",
            "Epoch 365/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5671 - mae: 12.5671 - val_loss: 6.3336 - val_mae: 6.3336\n",
            "Epoch 366/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5539 - mae: 12.5539 - val_loss: 6.3304 - val_mae: 6.3304\n",
            "Epoch 367/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5560 - mae: 12.5560 - val_loss: 6.3170 - val_mae: 6.3170\n",
            "Epoch 368/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5631 - mae: 12.5631 - val_loss: 6.3126 - val_mae: 6.3126\n",
            "Epoch 369/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5498 - mae: 12.5498 - val_loss: 6.3077 - val_mae: 6.3077\n",
            "Epoch 370/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5413 - mae: 12.5413 - val_loss: 6.2943 - val_mae: 6.2943\n",
            "Epoch 371/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5422 - mae: 12.5422 - val_loss: 6.3221 - val_mae: 6.3221\n",
            "Epoch 372/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5521 - mae: 12.5521 - val_loss: 6.3009 - val_mae: 6.3009\n",
            "Epoch 373/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5337 - mae: 12.5337 - val_loss: 6.3006 - val_mae: 6.3006\n",
            "Epoch 374/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5401 - mae: 12.5401 - val_loss: 6.3026 - val_mae: 6.3026\n",
            "Epoch 375/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5328 - mae: 12.5328 - val_loss: 6.2935 - val_mae: 6.2935\n",
            "Epoch 376/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5460 - mae: 12.5460 - val_loss: 6.2957 - val_mae: 6.2957\n",
            "Epoch 377/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5682 - mae: 12.5682 - val_loss: 6.2866 - val_mae: 6.2866\n",
            "Epoch 378/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5509 - mae: 12.5509 - val_loss: 6.3276 - val_mae: 6.3276\n",
            "Epoch 379/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5394 - mae: 12.5394 - val_loss: 6.2749 - val_mae: 6.2749\n",
            "Epoch 380/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5166 - mae: 12.5166 - val_loss: 6.3070 - val_mae: 6.3070\n",
            "Epoch 381/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.5511 - mae: 12.5511 - val_loss: 6.2876 - val_mae: 6.2876\n",
            "Epoch 382/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5267 - mae: 12.5267 - val_loss: 6.2945 - val_mae: 6.2945\n",
            "Epoch 383/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.5550 - mae: 12.5550 - val_loss: 6.3308 - val_mae: 6.3308\n",
            "Epoch 384/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5413 - mae: 12.5413 - val_loss: 6.2679 - val_mae: 6.2679\n",
            "Epoch 385/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5109 - mae: 12.5109 - val_loss: 6.3048 - val_mae: 6.3048\n",
            "Epoch 386/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5159 - mae: 12.5159 - val_loss: 6.2814 - val_mae: 6.2814\n",
            "Epoch 387/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5103 - mae: 12.5103 - val_loss: 6.3017 - val_mae: 6.3017\n",
            "Epoch 388/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.5170 - mae: 12.5170 - val_loss: 6.2603 - val_mae: 6.2603\n",
            "Epoch 389/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.5219 - mae: 12.5219 - val_loss: 6.3074 - val_mae: 6.3074\n",
            "Epoch 390/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5111 - mae: 12.5111 - val_loss: 6.2698 - val_mae: 6.2698\n",
            "Epoch 391/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5229 - mae: 12.5229 - val_loss: 6.2534 - val_mae: 6.2534\n",
            "Epoch 392/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4984 - mae: 12.4984 - val_loss: 6.3049 - val_mae: 6.3049\n",
            "Epoch 393/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.5019 - mae: 12.5019 - val_loss: 6.2565 - val_mae: 6.2565\n",
            "Epoch 394/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.4861 - mae: 12.4861 - val_loss: 6.2467 - val_mae: 6.2467\n",
            "Epoch 395/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4787 - mae: 12.4787 - val_loss: 6.2444 - val_mae: 6.2444\n",
            "Epoch 396/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4791 - mae: 12.4791 - val_loss: 6.2485 - val_mae: 6.2485\n",
            "Epoch 397/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.4722 - mae: 12.4722 - val_loss: 6.2416 - val_mae: 6.2416\n",
            "Epoch 398/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4822 - mae: 12.4822 - val_loss: 6.2260 - val_mae: 6.2260\n",
            "Epoch 399/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4682 - mae: 12.4682 - val_loss: 6.2461 - val_mae: 6.2461\n",
            "Epoch 400/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4662 - mae: 12.4662 - val_loss: 6.2310 - val_mae: 6.2310\n",
            "Epoch 401/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4700 - mae: 12.4700 - val_loss: 6.2224 - val_mae: 6.2224\n",
            "Epoch 402/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4593 - mae: 12.4593 - val_loss: 6.2395 - val_mae: 6.2395\n",
            "Epoch 403/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4678 - mae: 12.4678 - val_loss: 6.2267 - val_mae: 6.2267\n",
            "Epoch 404/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4909 - mae: 12.4909 - val_loss: 6.2422 - val_mae: 6.2422\n",
            "Epoch 405/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4780 - mae: 12.4780 - val_loss: 6.2228 - val_mae: 6.2228\n",
            "Epoch 406/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4554 - mae: 12.4554 - val_loss: 6.2309 - val_mae: 6.2309\n",
            "Epoch 407/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.4597 - mae: 12.4597 - val_loss: 6.2169 - val_mae: 6.2169\n",
            "Epoch 408/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4863 - mae: 12.4863 - val_loss: 6.2204 - val_mae: 6.2204\n",
            "Epoch 409/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4748 - mae: 12.4748 - val_loss: 6.2292 - val_mae: 6.2292\n",
            "Epoch 410/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4821 - mae: 12.4821 - val_loss: 6.2141 - val_mae: 6.2141\n",
            "Epoch 411/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4686 - mae: 12.4686 - val_loss: 6.2289 - val_mae: 6.2289\n",
            "Epoch 412/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4509 - mae: 12.4509 - val_loss: 6.2101 - val_mae: 6.2101\n",
            "Epoch 413/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4545 - mae: 12.4545 - val_loss: 6.2227 - val_mae: 6.2227\n",
            "Epoch 414/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4565 - mae: 12.4565 - val_loss: 6.2236 - val_mae: 6.2236\n",
            "Epoch 415/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4571 - mae: 12.4571 - val_loss: 6.1965 - val_mae: 6.1965\n",
            "Epoch 416/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4628 - mae: 12.4628 - val_loss: 6.2502 - val_mae: 6.2502\n",
            "Epoch 417/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4458 - mae: 12.4458 - val_loss: 6.2106 - val_mae: 6.2106\n",
            "Epoch 418/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4723 - mae: 12.4723 - val_loss: 6.2248 - val_mae: 6.2248\n",
            "Epoch 419/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4615 - mae: 12.4615 - val_loss: 6.2475 - val_mae: 6.2475\n",
            "Epoch 420/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4685 - mae: 12.4685 - val_loss: 6.2128 - val_mae: 6.2128\n",
            "Epoch 421/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4561 - mae: 12.4561 - val_loss: 6.2299 - val_mae: 6.2299\n",
            "Epoch 422/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4537 - mae: 12.4537 - val_loss: 6.1870 - val_mae: 6.1870\n",
            "Epoch 423/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4553 - mae: 12.4553 - val_loss: 6.2421 - val_mae: 6.2421\n",
            "Epoch 424/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4247 - mae: 12.4247 - val_loss: 6.1932 - val_mae: 6.1932\n",
            "Epoch 425/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.4259 - mae: 12.4259 - val_loss: 6.1924 - val_mae: 6.1924\n",
            "Epoch 426/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4157 - mae: 12.4157 - val_loss: 6.1948 - val_mae: 6.1948\n",
            "Epoch 427/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.4224 - mae: 12.4224 - val_loss: 6.1877 - val_mae: 6.1877\n",
            "Epoch 428/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4210 - mae: 12.4210 - val_loss: 6.1983 - val_mae: 6.1983\n",
            "Epoch 429/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4263 - mae: 12.4263 - val_loss: 6.1801 - val_mae: 6.1801\n",
            "Epoch 430/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4268 - mae: 12.4268 - val_loss: 6.1857 - val_mae: 6.1857\n",
            "Epoch 431/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4133 - mae: 12.4133 - val_loss: 6.1791 - val_mae: 6.1791\n",
            "Epoch 432/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4178 - mae: 12.4178 - val_loss: 6.1927 - val_mae: 6.1927\n",
            "Epoch 433/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4129 - mae: 12.4129 - val_loss: 6.1705 - val_mae: 6.1705\n",
            "Epoch 434/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4158 - mae: 12.4158 - val_loss: 6.1861 - val_mae: 6.1861\n",
            "Epoch 435/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4043 - mae: 12.4043 - val_loss: 6.1701 - val_mae: 6.1701\n",
            "Epoch 436/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4109 - mae: 12.4109 - val_loss: 6.1694 - val_mae: 6.1694\n",
            "Epoch 437/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4175 - mae: 12.4175 - val_loss: 6.1996 - val_mae: 6.1996\n",
            "Epoch 438/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.4062 - mae: 12.4062 - val_loss: 6.1774 - val_mae: 6.1774\n",
            "Epoch 439/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4169 - mae: 12.4169 - val_loss: 6.1640 - val_mae: 6.1640\n",
            "Epoch 440/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4072 - mae: 12.4072 - val_loss: 6.1944 - val_mae: 6.1944\n",
            "Epoch 441/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4198 - mae: 12.4198 - val_loss: 6.1563 - val_mae: 6.1563\n",
            "Epoch 442/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4040 - mae: 12.4040 - val_loss: 6.1655 - val_mae: 6.1655\n",
            "Epoch 443/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3928 - mae: 12.3928 - val_loss: 6.1733 - val_mae: 6.1733\n",
            "Epoch 444/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4033 - mae: 12.4033 - val_loss: 6.1519 - val_mae: 6.1519\n",
            "Epoch 445/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3967 - mae: 12.3967 - val_loss: 6.1669 - val_mae: 6.1669\n",
            "Epoch 446/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.4121 - mae: 12.4121 - val_loss: 6.1579 - val_mae: 6.1579\n",
            "Epoch 447/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4112 - mae: 12.4112 - val_loss: 6.1529 - val_mae: 6.1529\n",
            "Epoch 448/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4026 - mae: 12.4026 - val_loss: 6.1702 - val_mae: 6.1702\n",
            "Epoch 449/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4182 - mae: 12.4182 - val_loss: 6.2105 - val_mae: 6.2105\n",
            "Epoch 450/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.4079 - mae: 12.4079 - val_loss: 6.1600 - val_mae: 6.1600\n",
            "Epoch 451/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3900 - mae: 12.3900 - val_loss: 6.1427 - val_mae: 6.1427\n",
            "Epoch 452/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3817 - mae: 12.3817 - val_loss: 6.1530 - val_mae: 6.1530\n",
            "Epoch 453/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3873 - mae: 12.3873 - val_loss: 6.1418 - val_mae: 6.1418\n",
            "Epoch 454/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3839 - mae: 12.3839 - val_loss: 6.1569 - val_mae: 6.1569\n",
            "Epoch 455/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3855 - mae: 12.3855 - val_loss: 6.1446 - val_mae: 6.1446\n",
            "Epoch 456/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3774 - mae: 12.3774 - val_loss: 6.1496 - val_mae: 6.1496\n",
            "Epoch 457/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3753 - mae: 12.3753 - val_loss: 6.1411 - val_mae: 6.1411\n",
            "Epoch 458/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3758 - mae: 12.3758 - val_loss: 6.1442 - val_mae: 6.1442\n",
            "Epoch 459/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3744 - mae: 12.3744 - val_loss: 6.1329 - val_mae: 6.1329\n",
            "Epoch 460/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3787 - mae: 12.3787 - val_loss: 6.1342 - val_mae: 6.1342\n",
            "Epoch 461/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3699 - mae: 12.3699 - val_loss: 6.1424 - val_mae: 6.1424\n",
            "Epoch 462/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3793 - mae: 12.3793 - val_loss: 6.1321 - val_mae: 6.1321\n",
            "Epoch 463/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3710 - mae: 12.3710 - val_loss: 6.1352 - val_mae: 6.1352\n",
            "Epoch 464/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3672 - mae: 12.3672 - val_loss: 6.1322 - val_mae: 6.1322\n",
            "Epoch 465/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3712 - mae: 12.3712 - val_loss: 6.1417 - val_mae: 6.1417\n",
            "Epoch 466/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3667 - mae: 12.3667 - val_loss: 6.1233 - val_mae: 6.1233\n",
            "Epoch 467/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3726 - mae: 12.3726 - val_loss: 6.1344 - val_mae: 6.1344\n",
            "Epoch 468/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3702 - mae: 12.3702 - val_loss: 6.1248 - val_mae: 6.1248\n",
            "Epoch 469/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3678 - mae: 12.3678 - val_loss: 6.1388 - val_mae: 6.1388\n",
            "Epoch 470/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.4028 - mae: 12.4028 - val_loss: 6.1248 - val_mae: 6.1248\n",
            "Epoch 471/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3766 - mae: 12.3766 - val_loss: 6.1233 - val_mae: 6.1233\n",
            "Epoch 472/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3829 - mae: 12.3829 - val_loss: 6.1290 - val_mae: 6.1290\n",
            "Epoch 473/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3592 - mae: 12.3592 - val_loss: 6.1210 - val_mae: 6.1210\n",
            "Epoch 474/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3540 - mae: 12.3540 - val_loss: 6.1253 - val_mae: 6.1253\n",
            "Epoch 475/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3663 - mae: 12.3663 - val_loss: 6.1179 - val_mae: 6.1179\n",
            "Epoch 476/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3560 - mae: 12.3560 - val_loss: 6.1138 - val_mae: 6.1138\n",
            "Epoch 477/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3507 - mae: 12.3507 - val_loss: 6.1199 - val_mae: 6.1199\n",
            "Epoch 478/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3526 - mae: 12.3526 - val_loss: 6.1084 - val_mae: 6.1084\n",
            "Epoch 479/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3505 - mae: 12.3505 - val_loss: 6.1320 - val_mae: 6.1320\n",
            "Epoch 480/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3505 - mae: 12.3505 - val_loss: 6.1049 - val_mae: 6.1049\n",
            "Epoch 481/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3489 - mae: 12.3489 - val_loss: 6.1037 - val_mae: 6.1037\n",
            "Epoch 482/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3447 - mae: 12.3447 - val_loss: 6.1176 - val_mae: 6.1176\n",
            "Epoch 483/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3573 - mae: 12.3573 - val_loss: 6.0989 - val_mae: 6.0989\n",
            "Epoch 484/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.3506 - mae: 12.3506 - val_loss: 6.1375 - val_mae: 6.1375\n",
            "Epoch 485/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3498 - mae: 12.3498 - val_loss: 6.0999 - val_mae: 6.0999\n",
            "Epoch 486/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3460 - mae: 12.3460 - val_loss: 6.1044 - val_mae: 6.1044\n",
            "Epoch 487/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3340 - mae: 12.3340 - val_loss: 6.1071 - val_mae: 6.1071\n",
            "Epoch 488/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3387 - mae: 12.3387 - val_loss: 6.0964 - val_mae: 6.0964\n",
            "Epoch 489/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3485 - mae: 12.3485 - val_loss: 6.1029 - val_mae: 6.1029\n",
            "Epoch 490/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3411 - mae: 12.3411 - val_loss: 6.0911 - val_mae: 6.0911\n",
            "Epoch 491/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3420 - mae: 12.3420 - val_loss: 6.1162 - val_mae: 6.1162\n",
            "Epoch 492/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3391 - mae: 12.3391 - val_loss: 6.0919 - val_mae: 6.0919\n",
            "Epoch 493/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3415 - mae: 12.3415 - val_loss: 6.0925 - val_mae: 6.0925\n",
            "Epoch 494/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3349 - mae: 12.3349 - val_loss: 6.0850 - val_mae: 6.0850\n",
            "Epoch 495/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3342 - mae: 12.3342 - val_loss: 6.0847 - val_mae: 6.0847\n",
            "Epoch 496/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3392 - mae: 12.3392 - val_loss: 6.0845 - val_mae: 6.0845\n",
            "Epoch 497/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3311 - mae: 12.3311 - val_loss: 6.0825 - val_mae: 6.0825\n",
            "Epoch 498/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3243 - mae: 12.3243 - val_loss: 6.0860 - val_mae: 6.0860\n",
            "Epoch 499/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.3250 - mae: 12.3250 - val_loss: 6.0798 - val_mae: 6.0798\n",
            "Epoch 500/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3239 - mae: 12.3239 - val_loss: 6.0851 - val_mae: 6.0851\n",
            "Epoch 501/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3211 - mae: 12.3211 - val_loss: 6.0856 - val_mae: 6.0856\n",
            "Epoch 502/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3252 - mae: 12.3252 - val_loss: 6.0912 - val_mae: 6.0912\n",
            "Epoch 503/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3376 - mae: 12.3376 - val_loss: 6.0963 - val_mae: 6.0963\n",
            "Epoch 504/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3595 - mae: 12.3595 - val_loss: 6.0760 - val_mae: 6.0760\n",
            "Epoch 505/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3267 - mae: 12.3267 - val_loss: 6.0879 - val_mae: 6.0879\n",
            "Epoch 506/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3299 - mae: 12.3299 - val_loss: 6.0925 - val_mae: 6.0925\n",
            "Epoch 507/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3225 - mae: 12.3225 - val_loss: 6.0699 - val_mae: 6.0699\n",
            "Epoch 508/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3314 - mae: 12.3314 - val_loss: 6.0760 - val_mae: 6.0760\n",
            "Epoch 509/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3218 - mae: 12.3218 - val_loss: 6.0693 - val_mae: 6.0693\n",
            "Epoch 510/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3106 - mae: 12.3106 - val_loss: 6.0722 - val_mae: 6.0722\n",
            "Epoch 511/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3085 - mae: 12.3085 - val_loss: 6.0614 - val_mae: 6.0614\n",
            "Epoch 512/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.3132 - mae: 12.3132 - val_loss: 6.0665 - val_mae: 6.0665\n",
            "Epoch 513/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3336 - mae: 12.3336 - val_loss: 6.0606 - val_mae: 6.0606\n",
            "Epoch 514/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3389 - mae: 12.3389 - val_loss: 6.0754 - val_mae: 6.0754\n",
            "Epoch 515/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3242 - mae: 12.3242 - val_loss: 6.0601 - val_mae: 6.0601\n",
            "Epoch 516/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3096 - mae: 12.3096 - val_loss: 6.0587 - val_mae: 6.0587\n",
            "Epoch 517/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3036 - mae: 12.3036 - val_loss: 6.0563 - val_mae: 6.0563\n",
            "Epoch 518/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3038 - mae: 12.3038 - val_loss: 6.0627 - val_mae: 6.0627\n",
            "Epoch 519/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3212 - mae: 12.3212 - val_loss: 6.0722 - val_mae: 6.0722\n",
            "Epoch 520/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.3014 - mae: 12.3014 - val_loss: 6.0613 - val_mae: 6.0613\n",
            "Epoch 521/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3165 - mae: 12.3165 - val_loss: 6.0498 - val_mae: 6.0498\n",
            "Epoch 522/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3113 - mae: 12.3113 - val_loss: 6.0628 - val_mae: 6.0628\n",
            "Epoch 523/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2978 - mae: 12.2978 - val_loss: 6.0563 - val_mae: 6.0563\n",
            "Epoch 524/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3052 - mae: 12.3052 - val_loss: 6.0424 - val_mae: 6.0424\n",
            "Epoch 525/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2915 - mae: 12.2915 - val_loss: 6.0779 - val_mae: 6.0779\n",
            "Epoch 526/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3160 - mae: 12.3160 - val_loss: 6.0414 - val_mae: 6.0414\n",
            "Epoch 527/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.3062 - mae: 12.3062 - val_loss: 6.0614 - val_mae: 6.0614\n",
            "Epoch 528/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.3013 - mae: 12.3013 - val_loss: 6.0811 - val_mae: 6.0811\n",
            "Epoch 529/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.3023 - mae: 12.3023 - val_loss: 6.0403 - val_mae: 6.0403\n",
            "Epoch 530/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2870 - mae: 12.2870 - val_loss: 6.0437 - val_mae: 6.0437\n",
            "Epoch 531/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2970 - mae: 12.2970 - val_loss: 6.0452 - val_mae: 6.0452\n",
            "Epoch 532/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2917 - mae: 12.2917 - val_loss: 6.0333 - val_mae: 6.0333\n",
            "Epoch 533/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2896 - mae: 12.2896 - val_loss: 6.0319 - val_mae: 6.0319\n",
            "Epoch 534/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2864 - mae: 12.2864 - val_loss: 6.0427 - val_mae: 6.0427\n",
            "Epoch 535/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2873 - mae: 12.2873 - val_loss: 6.0287 - val_mae: 6.0287\n",
            "Epoch 536/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2987 - mae: 12.2987 - val_loss: 6.0371 - val_mae: 6.0371\n",
            "Epoch 537/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2950 - mae: 12.2950 - val_loss: 6.0624 - val_mae: 6.0624\n",
            "Epoch 538/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2937 - mae: 12.2937 - val_loss: 6.0247 - val_mae: 6.0247\n",
            "Epoch 539/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2760 - mae: 12.2760 - val_loss: 6.0322 - val_mae: 6.0322\n",
            "Epoch 540/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2817 - mae: 12.2817 - val_loss: 6.0228 - val_mae: 6.0228\n",
            "Epoch 541/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2835 - mae: 12.2835 - val_loss: 6.0223 - val_mae: 6.0223\n",
            "Epoch 542/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2945 - mae: 12.2945 - val_loss: 6.0499 - val_mae: 6.0499\n",
            "Epoch 543/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2902 - mae: 12.2902 - val_loss: 6.0216 - val_mae: 6.0216\n",
            "Epoch 544/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.3080 - mae: 12.3080 - val_loss: 6.0576 - val_mae: 6.0576\n",
            "Epoch 545/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2724 - mae: 12.2724 - val_loss: 6.0211 - val_mae: 6.0211\n",
            "Epoch 546/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.3000 - mae: 12.3000 - val_loss: 6.0274 - val_mae: 6.0274\n",
            "Epoch 547/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2772 - mae: 12.2772 - val_loss: 6.0351 - val_mae: 6.0351\n",
            "Epoch 548/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2766 - mae: 12.2766 - val_loss: 6.0387 - val_mae: 6.0387\n",
            "Epoch 549/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.2802 - mae: 12.2802 - val_loss: 6.0173 - val_mae: 6.0173\n",
            "Epoch 550/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 12.2810 - mae: 12.2810 - val_loss: 6.0278 - val_mae: 6.0278\n",
            "Epoch 551/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2749 - mae: 12.2749 - val_loss: 6.0298 - val_mae: 6.0298\n",
            "Epoch 552/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2720 - mae: 12.2720 - val_loss: 6.0062 - val_mae: 6.0062\n",
            "Epoch 553/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2853 - mae: 12.2853 - val_loss: 6.0265 - val_mae: 6.0265\n",
            "Epoch 554/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2757 - mae: 12.2757 - val_loss: 6.0112 - val_mae: 6.0112\n",
            "Epoch 555/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.2707 - mae: 12.2707 - val_loss: 6.0106 - val_mae: 6.0106\n",
            "Epoch 556/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2770 - mae: 12.2770 - val_loss: 6.0080 - val_mae: 6.0080\n",
            "Epoch 557/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2731 - mae: 12.2731 - val_loss: 6.0297 - val_mae: 6.0297\n",
            "Epoch 558/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2703 - mae: 12.2703 - val_loss: 5.9989 - val_mae: 5.9989\n",
            "Epoch 559/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2664 - mae: 12.2664 - val_loss: 6.0346 - val_mae: 6.0346\n",
            "Epoch 560/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2623 - mae: 12.2623 - val_loss: 6.0110 - val_mae: 6.0110\n",
            "Epoch 561/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2678 - mae: 12.2678 - val_loss: 6.0168 - val_mae: 6.0168\n",
            "Epoch 562/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2755 - mae: 12.2755 - val_loss: 6.0378 - val_mae: 6.0378\n",
            "Epoch 563/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2668 - mae: 12.2668 - val_loss: 6.0042 - val_mae: 6.0042\n",
            "Epoch 564/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2518 - mae: 12.2518 - val_loss: 6.0038 - val_mae: 6.0038\n",
            "Epoch 565/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2621 - mae: 12.2621 - val_loss: 6.0284 - val_mae: 6.0284\n",
            "Epoch 566/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2500 - mae: 12.2500 - val_loss: 5.9967 - val_mae: 5.9967\n",
            "Epoch 567/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2576 - mae: 12.2576 - val_loss: 5.9983 - val_mae: 5.9983\n",
            "Epoch 568/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2465 - mae: 12.2465 - val_loss: 5.9875 - val_mae: 5.9875\n",
            "Epoch 569/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2542 - mae: 12.2542 - val_loss: 5.9849 - val_mae: 5.9849\n",
            "Epoch 570/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2468 - mae: 12.2468 - val_loss: 6.0019 - val_mae: 6.0019\n",
            "Epoch 571/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2646 - mae: 12.2646 - val_loss: 5.9991 - val_mae: 5.9991\n",
            "Epoch 572/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2485 - mae: 12.2485 - val_loss: 5.9906 - val_mae: 5.9906\n",
            "Epoch 573/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2473 - mae: 12.2473 - val_loss: 5.9861 - val_mae: 5.9861\n",
            "Epoch 574/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2490 - mae: 12.2490 - val_loss: 5.9818 - val_mae: 5.9818\n",
            "Epoch 575/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2382 - mae: 12.2382 - val_loss: 5.9924 - val_mae: 5.9924\n",
            "Epoch 576/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2395 - mae: 12.2395 - val_loss: 5.9767 - val_mae: 5.9767\n",
            "Epoch 577/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2512 - mae: 12.2512 - val_loss: 5.9815 - val_mae: 5.9815\n",
            "Epoch 578/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2389 - mae: 12.2389 - val_loss: 6.0524 - val_mae: 6.0524\n",
            "Epoch 579/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2883 - mae: 12.2883 - val_loss: 6.0016 - val_mae: 6.0016\n",
            "Epoch 580/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2651 - mae: 12.2651 - val_loss: 6.0654 - val_mae: 6.0654\n",
            "Epoch 581/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2560 - mae: 12.2560 - val_loss: 5.9921 - val_mae: 5.9921\n",
            "Epoch 582/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.2561 - mae: 12.2561 - val_loss: 5.9746 - val_mae: 5.9746\n",
            "Epoch 583/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2339 - mae: 12.2339 - val_loss: 5.9742 - val_mae: 5.9742\n",
            "Epoch 584/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2323 - mae: 12.2323 - val_loss: 5.9680 - val_mae: 5.9680\n",
            "Epoch 585/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2473 - mae: 12.2473 - val_loss: 5.9683 - val_mae: 5.9683\n",
            "Epoch 586/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2564 - mae: 12.2564 - val_loss: 5.9710 - val_mae: 5.9710\n",
            "Epoch 587/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2426 - mae: 12.2426 - val_loss: 5.9838 - val_mae: 5.9838\n",
            "Epoch 588/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2536 - mae: 12.2536 - val_loss: 5.9704 - val_mae: 5.9704\n",
            "Epoch 589/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2369 - mae: 12.2369 - val_loss: 5.9643 - val_mae: 5.9643\n",
            "Epoch 590/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2375 - mae: 12.2375 - val_loss: 5.9582 - val_mae: 5.9582\n",
            "Epoch 591/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2264 - mae: 12.2264 - val_loss: 5.9629 - val_mae: 5.9629\n",
            "Epoch 592/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2212 - mae: 12.2212 - val_loss: 5.9581 - val_mae: 5.9581\n",
            "Epoch 593/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2254 - mae: 12.2254 - val_loss: 5.9546 - val_mae: 5.9546\n",
            "Epoch 594/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2280 - mae: 12.2280 - val_loss: 5.9656 - val_mae: 5.9656\n",
            "Epoch 595/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2366 - mae: 12.2366 - val_loss: 5.9834 - val_mae: 5.9834\n",
            "Epoch 596/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2292 - mae: 12.2292 - val_loss: 5.9983 - val_mae: 5.9983\n",
            "Epoch 597/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.2393 - mae: 12.2393 - val_loss: 5.9569 - val_mae: 5.9569\n",
            "Epoch 598/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2278 - mae: 12.2278 - val_loss: 5.9630 - val_mae: 5.9630\n",
            "Epoch 599/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2208 - mae: 12.2208 - val_loss: 5.9613 - val_mae: 5.9613\n",
            "Epoch 600/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.2285 - mae: 12.2285 - val_loss: 5.9535 - val_mae: 5.9535\n",
            "Epoch 601/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2238 - mae: 12.2238 - val_loss: 5.9482 - val_mae: 5.9482\n",
            "Epoch 602/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.2129 - mae: 12.2129 - val_loss: 5.9470 - val_mae: 5.9470\n",
            "Epoch 603/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.2122 - mae: 12.2122 - val_loss: 5.9475 - val_mae: 5.9475\n",
            "Epoch 604/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2122 - mae: 12.2122 - val_loss: 5.9559 - val_mae: 5.9559\n",
            "Epoch 605/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2244 - mae: 12.2244 - val_loss: 5.9405 - val_mae: 5.9405\n",
            "Epoch 606/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2321 - mae: 12.2321 - val_loss: 5.9762 - val_mae: 5.9762\n",
            "Epoch 607/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2241 - mae: 12.2241 - val_loss: 5.9541 - val_mae: 5.9541\n",
            "Epoch 608/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2098 - mae: 12.2098 - val_loss: 5.9621 - val_mae: 5.9621\n",
            "Epoch 609/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2212 - mae: 12.2212 - val_loss: 5.9481 - val_mae: 5.9481\n",
            "Epoch 610/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2374 - mae: 12.2374 - val_loss: 5.9793 - val_mae: 5.9793\n",
            "Epoch 611/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2286 - mae: 12.2286 - val_loss: 5.9556 - val_mae: 5.9556\n",
            "Epoch 612/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2277 - mae: 12.2277 - val_loss: 5.9541 - val_mae: 5.9541\n",
            "Epoch 613/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2185 - mae: 12.2185 - val_loss: 5.9321 - val_mae: 5.9321\n",
            "Epoch 614/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2303 - mae: 12.2303 - val_loss: 5.9328 - val_mae: 5.9328\n",
            "Epoch 615/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2368 - mae: 12.2368 - val_loss: 6.0066 - val_mae: 6.0066\n",
            "Epoch 616/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2170 - mae: 12.2170 - val_loss: 5.9727 - val_mae: 5.9727\n",
            "Epoch 617/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2259 - mae: 12.2259 - val_loss: 5.9464 - val_mae: 5.9464\n",
            "Epoch 618/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2190 - mae: 12.2190 - val_loss: 5.9256 - val_mae: 5.9256\n",
            "Epoch 619/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2273 - mae: 12.2273 - val_loss: 5.9516 - val_mae: 5.9516\n",
            "Epoch 620/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.2033 - mae: 12.2033 - val_loss: 5.9442 - val_mae: 5.9442\n",
            "Epoch 621/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1963 - mae: 12.1963 - val_loss: 5.9337 - val_mae: 5.9337\n",
            "Epoch 622/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2227 - mae: 12.2227 - val_loss: 5.9486 - val_mae: 5.9486\n",
            "Epoch 623/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2115 - mae: 12.2115 - val_loss: 5.9401 - val_mae: 5.9401\n",
            "Epoch 624/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1950 - mae: 12.1950 - val_loss: 5.9366 - val_mae: 5.9366\n",
            "Epoch 625/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.2048 - mae: 12.2048 - val_loss: 5.9310 - val_mae: 5.9310\n",
            "Epoch 626/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2069 - mae: 12.2069 - val_loss: 5.9194 - val_mae: 5.9194\n",
            "Epoch 627/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1953 - mae: 12.1953 - val_loss: 5.9323 - val_mae: 5.9323\n",
            "Epoch 628/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2167 - mae: 12.2167 - val_loss: 5.9434 - val_mae: 5.9434\n",
            "Epoch 629/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.2138 - mae: 12.2138 - val_loss: 5.9306 - val_mae: 5.9306\n",
            "Epoch 630/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2074 - mae: 12.2074 - val_loss: 5.9429 - val_mae: 5.9429\n",
            "Epoch 631/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.2030 - mae: 12.2030 - val_loss: 5.9146 - val_mae: 5.9146\n",
            "Epoch 632/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1852 - mae: 12.1852 - val_loss: 5.9206 - val_mae: 5.9206\n",
            "Epoch 633/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1956 - mae: 12.1956 - val_loss: 5.9191 - val_mae: 5.9191\n",
            "Epoch 634/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1825 - mae: 12.1825 - val_loss: 5.9090 - val_mae: 5.9090\n",
            "Epoch 635/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1771 - mae: 12.1771 - val_loss: 5.9174 - val_mae: 5.9174\n",
            "Epoch 636/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1801 - mae: 12.1801 - val_loss: 5.9107 - val_mae: 5.9107\n",
            "Epoch 637/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2023 - mae: 12.2023 - val_loss: 5.9098 - val_mae: 5.9098\n",
            "Epoch 638/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1842 - mae: 12.1842 - val_loss: 5.9282 - val_mae: 5.9282\n",
            "Epoch 639/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1894 - mae: 12.1894 - val_loss: 5.9244 - val_mae: 5.9244\n",
            "Epoch 640/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1808 - mae: 12.1808 - val_loss: 5.9165 - val_mae: 5.9165\n",
            "Epoch 641/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1863 - mae: 12.1863 - val_loss: 5.9022 - val_mae: 5.9022\n",
            "Epoch 642/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1925 - mae: 12.1925 - val_loss: 5.9121 - val_mae: 5.9121\n",
            "Epoch 643/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1763 - mae: 12.1763 - val_loss: 5.9546 - val_mae: 5.9546\n",
            "Epoch 644/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1920 - mae: 12.1920 - val_loss: 5.9181 - val_mae: 5.9181\n",
            "Epoch 645/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.1820 - mae: 12.1820 - val_loss: 5.9079 - val_mae: 5.9079\n",
            "Epoch 646/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1758 - mae: 12.1758 - val_loss: 5.9017 - val_mae: 5.9017\n",
            "Epoch 647/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1631 - mae: 12.1631 - val_loss: 5.9059 - val_mae: 5.9059\n",
            "Epoch 648/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1782 - mae: 12.1782 - val_loss: 5.9156 - val_mae: 5.9156\n",
            "Epoch 649/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1848 - mae: 12.1848 - val_loss: 5.9082 - val_mae: 5.9082\n",
            "Epoch 650/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1776 - mae: 12.1776 - val_loss: 5.9133 - val_mae: 5.9133\n",
            "Epoch 651/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.2035 - mae: 12.2035 - val_loss: 5.9176 - val_mae: 5.9176\n",
            "Epoch 652/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.1725 - mae: 12.1725 - val_loss: 5.9844 - val_mae: 5.9844\n",
            "Epoch 653/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1860 - mae: 12.1860 - val_loss: 5.9123 - val_mae: 5.9123\n",
            "Epoch 654/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1763 - mae: 12.1763 - val_loss: 5.9019 - val_mae: 5.9019\n",
            "Epoch 655/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1604 - mae: 12.1604 - val_loss: 5.8961 - val_mae: 5.8961\n",
            "Epoch 656/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1754 - mae: 12.1754 - val_loss: 5.9275 - val_mae: 5.9275\n",
            "Epoch 657/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1915 - mae: 12.1915 - val_loss: 5.9195 - val_mae: 5.9195\n",
            "Epoch 658/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1700 - mae: 12.1700 - val_loss: 5.9109 - val_mae: 5.9109\n",
            "Epoch 659/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1761 - mae: 12.1761 - val_loss: 5.9205 - val_mae: 5.9205\n",
            "Epoch 660/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1665 - mae: 12.1665 - val_loss: 5.8826 - val_mae: 5.8826\n",
            "Epoch 661/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1577 - mae: 12.1577 - val_loss: 5.8811 - val_mae: 5.8811\n",
            "Epoch 662/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1553 - mae: 12.1553 - val_loss: 5.8849 - val_mae: 5.8849\n",
            "Epoch 663/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1646 - mae: 12.1646 - val_loss: 5.8795 - val_mae: 5.8795\n",
            "Epoch 664/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1483 - mae: 12.1483 - val_loss: 5.8804 - val_mae: 5.8804\n",
            "Epoch 665/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.1474 - mae: 12.1474 - val_loss: 5.8822 - val_mae: 5.8822\n",
            "Epoch 666/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1498 - mae: 12.1498 - val_loss: 5.8770 - val_mae: 5.8770\n",
            "Epoch 667/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1477 - mae: 12.1477 - val_loss: 5.8722 - val_mae: 5.8722\n",
            "Epoch 668/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1447 - mae: 12.1447 - val_loss: 5.8890 - val_mae: 5.8890\n",
            "Epoch 669/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1535 - mae: 12.1535 - val_loss: 5.9030 - val_mae: 5.9030\n",
            "Epoch 670/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1665 - mae: 12.1665 - val_loss: 5.8797 - val_mae: 5.8797\n",
            "Epoch 671/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1526 - mae: 12.1526 - val_loss: 5.8759 - val_mae: 5.8759\n",
            "Epoch 672/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1478 - mae: 12.1478 - val_loss: 5.8704 - val_mae: 5.8704\n",
            "Epoch 673/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1460 - mae: 12.1460 - val_loss: 5.8644 - val_mae: 5.8644\n",
            "Epoch 674/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1440 - mae: 12.1440 - val_loss: 5.8662 - val_mae: 5.8662\n",
            "Epoch 675/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1361 - mae: 12.1361 - val_loss: 5.8700 - val_mae: 5.8700\n",
            "Epoch 676/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1409 - mae: 12.1409 - val_loss: 5.8721 - val_mae: 5.8721\n",
            "Epoch 677/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1517 - mae: 12.1517 - val_loss: 5.8663 - val_mae: 5.8663\n",
            "Epoch 678/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1835 - mae: 12.1835 - val_loss: 5.9181 - val_mae: 5.9181\n",
            "Epoch 679/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1833 - mae: 12.1833 - val_loss: 5.9114 - val_mae: 5.9114\n",
            "Epoch 680/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1581 - mae: 12.1581 - val_loss: 5.9192 - val_mae: 5.9192\n",
            "Epoch 681/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1694 - mae: 12.1694 - val_loss: 5.8776 - val_mae: 5.8776\n",
            "Epoch 682/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1488 - mae: 12.1488 - val_loss: 5.9147 - val_mae: 5.9147\n",
            "Epoch 683/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1888 - mae: 12.1888 - val_loss: 5.8996 - val_mae: 5.8996\n",
            "Epoch 684/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1696 - mae: 12.1696 - val_loss: 5.8845 - val_mae: 5.8845\n",
            "Epoch 685/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1498 - mae: 12.1498 - val_loss: 5.8646 - val_mae: 5.8646\n",
            "Epoch 686/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1304 - mae: 12.1304 - val_loss: 5.8563 - val_mae: 5.8563\n",
            "Epoch 687/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1277 - mae: 12.1277 - val_loss: 5.8527 - val_mae: 5.8527\n",
            "Epoch 688/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1328 - mae: 12.1328 - val_loss: 5.8628 - val_mae: 5.8628\n",
            "Epoch 689/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1313 - mae: 12.1313 - val_loss: 5.8507 - val_mae: 5.8507\n",
            "Epoch 690/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1290 - mae: 12.1290 - val_loss: 5.8615 - val_mae: 5.8615\n",
            "Epoch 691/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1363 - mae: 12.1363 - val_loss: 5.8561 - val_mae: 5.8561\n",
            "Epoch 692/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1191 - mae: 12.1191 - val_loss: 5.8588 - val_mae: 5.8588\n",
            "Epoch 693/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1396 - mae: 12.1396 - val_loss: 5.8451 - val_mae: 5.8451\n",
            "Epoch 694/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1157 - mae: 12.1157 - val_loss: 5.8457 - val_mae: 5.8457\n",
            "Epoch 695/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1299 - mae: 12.1299 - val_loss: 5.8460 - val_mae: 5.8460\n",
            "Epoch 696/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1440 - mae: 12.1440 - val_loss: 5.8445 - val_mae: 5.8445\n",
            "Epoch 697/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1270 - mae: 12.1270 - val_loss: 5.8530 - val_mae: 5.8530\n",
            "Epoch 698/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1281 - mae: 12.1281 - val_loss: 5.8841 - val_mae: 5.8841\n",
            "Epoch 699/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1299 - mae: 12.1299 - val_loss: 5.8741 - val_mae: 5.8741\n",
            "Epoch 700/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1386 - mae: 12.1386 - val_loss: 5.8457 - val_mae: 5.8457\n",
            "Epoch 701/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1498 - mae: 12.1498 - val_loss: 5.8714 - val_mae: 5.8714\n",
            "Epoch 702/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1459 - mae: 12.1459 - val_loss: 5.8728 - val_mae: 5.8728\n",
            "Epoch 703/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.1266 - mae: 12.1266 - val_loss: 5.8389 - val_mae: 5.8389\n",
            "Epoch 704/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1147 - mae: 12.1147 - val_loss: 5.8461 - val_mae: 5.8461\n",
            "Epoch 705/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1272 - mae: 12.1272 - val_loss: 5.8380 - val_mae: 5.8380\n",
            "Epoch 706/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.1249 - mae: 12.1249 - val_loss: 5.8381 - val_mae: 5.8381\n",
            "Epoch 707/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1162 - mae: 12.1162 - val_loss: 5.8501 - val_mae: 5.8501\n",
            "Epoch 708/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1289 - mae: 12.1289 - val_loss: 5.8371 - val_mae: 5.8371\n",
            "Epoch 709/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1066 - mae: 12.1066 - val_loss: 5.8338 - val_mae: 5.8338\n",
            "Epoch 710/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1064 - mae: 12.1064 - val_loss: 5.8392 - val_mae: 5.8392\n",
            "Epoch 711/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1104 - mae: 12.1104 - val_loss: 5.8351 - val_mae: 5.8351\n",
            "Epoch 712/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1047 - mae: 12.1047 - val_loss: 5.8383 - val_mae: 5.8383\n",
            "Epoch 713/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1073 - mae: 12.1073 - val_loss: 5.8334 - val_mae: 5.8334\n",
            "Epoch 714/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1126 - mae: 12.1126 - val_loss: 5.8355 - val_mae: 5.8355\n",
            "Epoch 715/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1125 - mae: 12.1125 - val_loss: 5.8376 - val_mae: 5.8376\n",
            "Epoch 716/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1016 - mae: 12.1016 - val_loss: 5.8221 - val_mae: 5.8221\n",
            "Epoch 717/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.1045 - mae: 12.1045 - val_loss: 5.8391 - val_mae: 5.8391\n",
            "Epoch 718/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1018 - mae: 12.1018 - val_loss: 5.8198 - val_mae: 5.8198\n",
            "Epoch 719/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1019 - mae: 12.1019 - val_loss: 5.8161 - val_mae: 5.8161\n",
            "Epoch 720/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0950 - mae: 12.0950 - val_loss: 5.8296 - val_mae: 5.8296\n",
            "Epoch 721/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1029 - mae: 12.1029 - val_loss: 5.8240 - val_mae: 5.8240\n",
            "Epoch 722/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1024 - mae: 12.1024 - val_loss: 5.8308 - val_mae: 5.8308\n",
            "Epoch 723/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1003 - mae: 12.1003 - val_loss: 5.8220 - val_mae: 5.8220\n",
            "Epoch 724/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.0955 - mae: 12.0955 - val_loss: 5.8165 - val_mae: 5.8165\n",
            "Epoch 725/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0984 - mae: 12.0984 - val_loss: 5.8358 - val_mae: 5.8358\n",
            "Epoch 726/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0909 - mae: 12.0909 - val_loss: 5.8349 - val_mae: 5.8349\n",
            "Epoch 727/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0943 - mae: 12.0943 - val_loss: 5.8430 - val_mae: 5.8430\n",
            "Epoch 728/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1214 - mae: 12.1214 - val_loss: 5.8428 - val_mae: 5.8428\n",
            "Epoch 729/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1039 - mae: 12.1039 - val_loss: 5.8195 - val_mae: 5.8195\n",
            "Epoch 730/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0932 - mae: 12.0932 - val_loss: 5.8417 - val_mae: 5.8417\n",
            "Epoch 731/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1283 - mae: 12.1283 - val_loss: 5.8289 - val_mae: 5.8289\n",
            "Epoch 732/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.1201 - mae: 12.1201 - val_loss: 5.8133 - val_mae: 5.8133\n",
            "Epoch 733/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1113 - mae: 12.1113 - val_loss: 5.8457 - val_mae: 5.8457\n",
            "Epoch 734/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1338 - mae: 12.1338 - val_loss: 5.8542 - val_mae: 5.8542\n",
            "Epoch 735/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1071 - mae: 12.1071 - val_loss: 5.8305 - val_mae: 5.8305\n",
            "Epoch 736/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1038 - mae: 12.1038 - val_loss: 5.8247 - val_mae: 5.8247\n",
            "Epoch 737/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.1157 - mae: 12.1157 - val_loss: 5.8222 - val_mae: 5.8222\n",
            "Epoch 738/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1035 - mae: 12.1035 - val_loss: 5.8150 - val_mae: 5.8150\n",
            "Epoch 739/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0884 - mae: 12.0884 - val_loss: 5.8312 - val_mae: 5.8312\n",
            "Epoch 740/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.1057 - mae: 12.1057 - val_loss: 5.8085 - val_mae: 5.8085\n",
            "Epoch 741/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0876 - mae: 12.0876 - val_loss: 5.8301 - val_mae: 5.8301\n",
            "Epoch 742/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0930 - mae: 12.0930 - val_loss: 5.8191 - val_mae: 5.8191\n",
            "Epoch 743/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0950 - mae: 12.0950 - val_loss: 5.8213 - val_mae: 5.8213\n",
            "Epoch 744/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0941 - mae: 12.0941 - val_loss: 5.7994 - val_mae: 5.7994\n",
            "Epoch 745/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0795 - mae: 12.0795 - val_loss: 5.8163 - val_mae: 5.8163\n",
            "Epoch 746/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0780 - mae: 12.0780 - val_loss: 5.7976 - val_mae: 5.7976\n",
            "Epoch 747/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0709 - mae: 12.0709 - val_loss: 5.7982 - val_mae: 5.7982\n",
            "Epoch 748/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0776 - mae: 12.0776 - val_loss: 5.8129 - val_mae: 5.8129\n",
            "Epoch 749/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0933 - mae: 12.0933 - val_loss: 5.8278 - val_mae: 5.8278\n",
            "Epoch 750/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.1011 - mae: 12.1011 - val_loss: 5.8357 - val_mae: 5.8357\n",
            "Epoch 751/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1314 - mae: 12.1314 - val_loss: 5.8534 - val_mae: 5.8534\n",
            "Epoch 752/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1357 - mae: 12.1357 - val_loss: 5.8654 - val_mae: 5.8654\n",
            "Epoch 753/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.1285 - mae: 12.1285 - val_loss: 5.8644 - val_mae: 5.8644\n",
            "Epoch 754/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1239 - mae: 12.1239 - val_loss: 5.8804 - val_mae: 5.8804\n",
            "Epoch 755/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.1095 - mae: 12.1095 - val_loss: 5.8120 - val_mae: 5.8120\n",
            "Epoch 756/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0788 - mae: 12.0788 - val_loss: 5.8277 - val_mae: 5.8277\n",
            "Epoch 757/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1035 - mae: 12.1035 - val_loss: 5.8299 - val_mae: 5.8299\n",
            "Epoch 758/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0868 - mae: 12.0868 - val_loss: 5.8363 - val_mae: 5.8363\n",
            "Epoch 759/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0878 - mae: 12.0878 - val_loss: 5.8511 - val_mae: 5.8511\n",
            "Epoch 760/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0785 - mae: 12.0785 - val_loss: 5.8183 - val_mae: 5.8183\n",
            "Epoch 761/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0718 - mae: 12.0718 - val_loss: 5.8021 - val_mae: 5.8021\n",
            "Epoch 762/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0936 - mae: 12.0936 - val_loss: 5.8204 - val_mae: 5.8204\n",
            "Epoch 763/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0867 - mae: 12.0867 - val_loss: 5.8103 - val_mae: 5.8103\n",
            "Epoch 764/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0753 - mae: 12.0753 - val_loss: 5.7982 - val_mae: 5.7982\n",
            "Epoch 765/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0605 - mae: 12.0605 - val_loss: 5.7937 - val_mae: 5.7937\n",
            "Epoch 766/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 12.0681 - mae: 12.0681 - val_loss: 5.8047 - val_mae: 5.8047\n",
            "Epoch 767/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0691 - mae: 12.0691 - val_loss: 5.8162 - val_mae: 5.8162\n",
            "Epoch 768/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0745 - mae: 12.0745 - val_loss: 5.8021 - val_mae: 5.8021\n",
            "Epoch 769/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0788 - mae: 12.0788 - val_loss: 5.8341 - val_mae: 5.8341\n",
            "Epoch 770/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0989 - mae: 12.0989 - val_loss: 5.7901 - val_mae: 5.7901\n",
            "Epoch 771/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0751 - mae: 12.0751 - val_loss: 5.8024 - val_mae: 5.8024\n",
            "Epoch 772/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0672 - mae: 12.0672 - val_loss: 5.8107 - val_mae: 5.8107\n",
            "Epoch 773/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0744 - mae: 12.0744 - val_loss: 5.8615 - val_mae: 5.8615\n",
            "Epoch 774/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1008 - mae: 12.1008 - val_loss: 5.8222 - val_mae: 5.8222\n",
            "Epoch 775/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1062 - mae: 12.1062 - val_loss: 5.8142 - val_mae: 5.8142\n",
            "Epoch 776/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0867 - mae: 12.0867 - val_loss: 5.8264 - val_mae: 5.8264\n",
            "Epoch 777/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0924 - mae: 12.0924 - val_loss: 5.8041 - val_mae: 5.8041\n",
            "Epoch 778/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0672 - mae: 12.0672 - val_loss: 5.8034 - val_mae: 5.8034\n",
            "Epoch 779/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0813 - mae: 12.0813 - val_loss: 5.8283 - val_mae: 5.8283\n",
            "Epoch 780/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0699 - mae: 12.0699 - val_loss: 5.7822 - val_mae: 5.7822\n",
            "Epoch 781/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0485 - mae: 12.0485 - val_loss: 5.7800 - val_mae: 5.7800\n",
            "Epoch 782/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0758 - mae: 12.0758 - val_loss: 5.8130 - val_mae: 5.8130\n",
            "Epoch 783/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0740 - mae: 12.0740 - val_loss: 5.7880 - val_mae: 5.7880\n",
            "Epoch 784/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0581 - mae: 12.0581 - val_loss: 5.7897 - val_mae: 5.7897\n",
            "Epoch 785/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0551 - mae: 12.0551 - val_loss: 5.7844 - val_mae: 5.7844\n",
            "Epoch 786/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0668 - mae: 12.0668 - val_loss: 5.8278 - val_mae: 5.8278\n",
            "Epoch 787/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0662 - mae: 12.0662 - val_loss: 5.8060 - val_mae: 5.8060\n",
            "Epoch 788/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0726 - mae: 12.0726 - val_loss: 5.8207 - val_mae: 5.8207\n",
            "Epoch 789/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0787 - mae: 12.0787 - val_loss: 5.8020 - val_mae: 5.8020\n",
            "Epoch 790/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0674 - mae: 12.0674 - val_loss: 5.7961 - val_mae: 5.7961\n",
            "Epoch 791/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0606 - mae: 12.0606 - val_loss: 5.8041 - val_mae: 5.8041\n",
            "Epoch 792/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0726 - mae: 12.0726 - val_loss: 5.8408 - val_mae: 5.8408\n",
            "Epoch 793/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0703 - mae: 12.0703 - val_loss: 5.7975 - val_mae: 5.7975\n",
            "Epoch 794/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0694 - mae: 12.0694 - val_loss: 5.7871 - val_mae: 5.7871\n",
            "Epoch 795/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0610 - mae: 12.0610 - val_loss: 5.7809 - val_mae: 5.7809\n",
            "Epoch 796/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0701 - mae: 12.0701 - val_loss: 5.8009 - val_mae: 5.8009\n",
            "Epoch 797/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0811 - mae: 12.0811 - val_loss: 5.7931 - val_mae: 5.7931\n",
            "Epoch 798/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0491 - mae: 12.0491 - val_loss: 5.7685 - val_mae: 5.7685\n",
            "Epoch 799/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.0371 - mae: 12.0371 - val_loss: 5.7686 - val_mae: 5.7686\n",
            "Epoch 800/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0423 - mae: 12.0423 - val_loss: 5.7633 - val_mae: 5.7633\n",
            "Epoch 801/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0356 - mae: 12.0356 - val_loss: 5.7832 - val_mae: 5.7832\n",
            "Epoch 802/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0439 - mae: 12.0439 - val_loss: 5.7706 - val_mae: 5.7706\n",
            "Epoch 803/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0328 - mae: 12.0328 - val_loss: 5.7804 - val_mae: 5.7804\n",
            "Epoch 804/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0453 - mae: 12.0453 - val_loss: 5.7623 - val_mae: 5.7623\n",
            "Epoch 805/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0398 - mae: 12.0398 - val_loss: 5.7790 - val_mae: 5.7790\n",
            "Epoch 806/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0390 - mae: 12.0390 - val_loss: 5.7656 - val_mae: 5.7656\n",
            "Epoch 807/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0409 - mae: 12.0409 - val_loss: 5.7834 - val_mae: 5.7834\n",
            "Epoch 808/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0374 - mae: 12.0374 - val_loss: 5.7594 - val_mae: 5.7594\n",
            "Epoch 809/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0584 - mae: 12.0584 - val_loss: 5.7882 - val_mae: 5.7882\n",
            "Epoch 810/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.1030 - mae: 12.1030 - val_loss: 5.8226 - val_mae: 5.8226\n",
            "Epoch 811/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0523 - mae: 12.0523 - val_loss: 5.7928 - val_mae: 5.7928\n",
            "Epoch 812/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0577 - mae: 12.0577 - val_loss: 5.8029 - val_mae: 5.8029\n",
            "Epoch 813/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0715 - mae: 12.0715 - val_loss: 5.8222 - val_mae: 5.8222\n",
            "Epoch 814/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0788 - mae: 12.0788 - val_loss: 5.8095 - val_mae: 5.8095\n",
            "Epoch 815/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0988 - mae: 12.0988 - val_loss: 5.7843 - val_mae: 5.7843\n",
            "Epoch 816/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0486 - mae: 12.0486 - val_loss: 5.7734 - val_mae: 5.7734\n",
            "Epoch 817/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0412 - mae: 12.0412 - val_loss: 5.7914 - val_mae: 5.7914\n",
            "Epoch 818/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.0396 - mae: 12.0396 - val_loss: 5.7756 - val_mae: 5.7756\n",
            "Epoch 819/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0381 - mae: 12.0381 - val_loss: 5.7547 - val_mae: 5.7547\n",
            "Epoch 820/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0691 - mae: 12.0691 - val_loss: 5.7949 - val_mae: 5.7949\n",
            "Epoch 821/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0645 - mae: 12.0645 - val_loss: 5.7889 - val_mae: 5.7889\n",
            "Epoch 822/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0373 - mae: 12.0373 - val_loss: 5.7764 - val_mae: 5.7764\n",
            "Epoch 823/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0362 - mae: 12.0362 - val_loss: 5.8014 - val_mae: 5.8014\n",
            "Epoch 824/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0512 - mae: 12.0512 - val_loss: 5.7626 - val_mae: 5.7626\n",
            "Epoch 825/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0246 - mae: 12.0246 - val_loss: 5.7562 - val_mae: 5.7562\n",
            "Epoch 826/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0266 - mae: 12.0266 - val_loss: 5.7567 - val_mae: 5.7567\n",
            "Epoch 827/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0268 - mae: 12.0268 - val_loss: 5.7691 - val_mae: 5.7691\n",
            "Epoch 828/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0259 - mae: 12.0259 - val_loss: 5.7521 - val_mae: 5.7521\n",
            "Epoch 829/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0256 - mae: 12.0256 - val_loss: 5.7660 - val_mae: 5.7660\n",
            "Epoch 830/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0387 - mae: 12.0387 - val_loss: 5.7631 - val_mae: 5.7631\n",
            "Epoch 831/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0260 - mae: 12.0260 - val_loss: 5.7517 - val_mae: 5.7517\n",
            "Epoch 832/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.0524 - mae: 12.0524 - val_loss: 5.7882 - val_mae: 5.7882\n",
            "Epoch 833/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0571 - mae: 12.0571 - val_loss: 5.7892 - val_mae: 5.7892\n",
            "Epoch 834/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0570 - mae: 12.0570 - val_loss: 5.7812 - val_mae: 5.7812\n",
            "Epoch 835/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0348 - mae: 12.0348 - val_loss: 5.7837 - val_mae: 5.7837\n",
            "Epoch 836/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0319 - mae: 12.0319 - val_loss: 5.7780 - val_mae: 5.7780\n",
            "Epoch 837/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0458 - mae: 12.0458 - val_loss: 5.7979 - val_mae: 5.7979\n",
            "Epoch 838/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0622 - mae: 12.0622 - val_loss: 5.7464 - val_mae: 5.7464\n",
            "Epoch 839/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0402 - mae: 12.0402 - val_loss: 5.7783 - val_mae: 5.7783\n",
            "Epoch 840/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0292 - mae: 12.0292 - val_loss: 5.7653 - val_mae: 5.7653\n",
            "Epoch 841/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0278 - mae: 12.0278 - val_loss: 5.7623 - val_mae: 5.7623\n",
            "Epoch 842/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 12.0245 - mae: 12.0245 - val_loss: 5.7432 - val_mae: 5.7432\n",
            "Epoch 843/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0195 - mae: 12.0195 - val_loss: 5.7850 - val_mae: 5.7850\n",
            "Epoch 844/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0574 - mae: 12.0574 - val_loss: 5.7522 - val_mae: 5.7522\n",
            "Epoch 845/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0238 - mae: 12.0238 - val_loss: 5.7512 - val_mae: 5.7512\n",
            "Epoch 846/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0389 - mae: 12.0389 - val_loss: 5.7619 - val_mae: 5.7619\n",
            "Epoch 847/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0231 - mae: 12.0231 - val_loss: 5.7387 - val_mae: 5.7387\n",
            "Epoch 848/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0128 - mae: 12.0128 - val_loss: 5.7454 - val_mae: 5.7454\n",
            "Epoch 849/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0080 - mae: 12.0080 - val_loss: 5.7406 - val_mae: 5.7406\n",
            "Epoch 850/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0077 - mae: 12.0077 - val_loss: 5.7413 - val_mae: 5.7413\n",
            "Epoch 851/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0147 - mae: 12.0147 - val_loss: 5.7402 - val_mae: 5.7402\n",
            "Epoch 852/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0073 - mae: 12.0073 - val_loss: 5.7462 - val_mae: 5.7462\n",
            "Epoch 853/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0190 - mae: 12.0190 - val_loss: 5.7406 - val_mae: 5.7406\n",
            "Epoch 854/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0226 - mae: 12.0226 - val_loss: 5.7438 - val_mae: 5.7438\n",
            "Epoch 855/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0080 - mae: 12.0080 - val_loss: 5.7364 - val_mae: 5.7364\n",
            "Epoch 856/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0169 - mae: 12.0169 - val_loss: 5.7395 - val_mae: 5.7395\n",
            "Epoch 857/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0119 - mae: 12.0119 - val_loss: 5.7342 - val_mae: 5.7342\n",
            "Epoch 858/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0115 - mae: 12.0115 - val_loss: 5.7455 - val_mae: 5.7455\n",
            "Epoch 859/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0103 - mae: 12.0103 - val_loss: 5.7364 - val_mae: 5.7364\n",
            "Epoch 860/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0060 - mae: 12.0060 - val_loss: 5.7495 - val_mae: 5.7495\n",
            "Epoch 861/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0143 - mae: 12.0143 - val_loss: 5.7580 - val_mae: 5.7580\n",
            "Epoch 862/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0126 - mae: 12.0126 - val_loss: 5.7323 - val_mae: 5.7323\n",
            "Epoch 863/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0082 - mae: 12.0082 - val_loss: 5.7401 - val_mae: 5.7401\n",
            "Epoch 864/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0179 - mae: 12.0179 - val_loss: 5.7488 - val_mae: 5.7488\n",
            "Epoch 865/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0254 - mae: 12.0254 - val_loss: 5.7450 - val_mae: 5.7450\n",
            "Epoch 866/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0058 - mae: 12.0058 - val_loss: 5.7300 - val_mae: 5.7300\n",
            "Epoch 867/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0064 - mae: 12.0064 - val_loss: 5.7447 - val_mae: 5.7447\n",
            "Epoch 868/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0057 - mae: 12.0057 - val_loss: 5.7266 - val_mae: 5.7266\n",
            "Epoch 869/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0128 - mae: 12.0128 - val_loss: 5.7484 - val_mae: 5.7484\n",
            "Epoch 870/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0115 - mae: 12.0115 - val_loss: 5.7688 - val_mae: 5.7688\n",
            "Epoch 871/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0113 - mae: 12.0113 - val_loss: 5.7434 - val_mae: 5.7434\n",
            "Epoch 872/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0141 - mae: 12.0141 - val_loss: 5.7383 - val_mae: 5.7383\n",
            "Epoch 873/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0008 - mae: 12.0008 - val_loss: 5.7287 - val_mae: 5.7287\n",
            "Epoch 874/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0194 - mae: 12.0194 - val_loss: 5.7582 - val_mae: 5.7582\n",
            "Epoch 875/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0132 - mae: 12.0132 - val_loss: 5.7739 - val_mae: 5.7739\n",
            "Epoch 876/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0329 - mae: 12.0329 - val_loss: 5.7590 - val_mae: 5.7590\n",
            "Epoch 877/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0344 - mae: 12.0344 - val_loss: 5.7702 - val_mae: 5.7702\n",
            "Epoch 878/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.0322 - mae: 12.0322 - val_loss: 5.7497 - val_mae: 5.7497\n",
            "Epoch 879/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0100 - mae: 12.0100 - val_loss: 5.7343 - val_mae: 5.7343\n",
            "Epoch 880/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0149 - mae: 12.0149 - val_loss: 5.7553 - val_mae: 5.7553\n",
            "Epoch 881/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0183 - mae: 12.0183 - val_loss: 5.7318 - val_mae: 5.7318\n",
            "Epoch 882/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0166 - mae: 12.0166 - val_loss: 5.7947 - val_mae: 5.7947\n",
            "Epoch 883/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0240 - mae: 12.0240 - val_loss: 5.7855 - val_mae: 5.7855\n",
            "Epoch 884/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0194 - mae: 12.0194 - val_loss: 5.7603 - val_mae: 5.7603\n",
            "Epoch 885/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0510 - mae: 12.0510 - val_loss: 5.7261 - val_mae: 5.7261\n",
            "Epoch 886/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0514 - mae: 12.0514 - val_loss: 5.7896 - val_mae: 5.7896\n",
            "Epoch 887/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0315 - mae: 12.0315 - val_loss: 5.7782 - val_mae: 5.7782\n",
            "Epoch 888/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0367 - mae: 12.0367 - val_loss: 5.7470 - val_mae: 5.7470\n",
            "Epoch 889/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0155 - mae: 12.0155 - val_loss: 5.7388 - val_mae: 5.7388\n",
            "Epoch 890/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0213 - mae: 12.0213 - val_loss: 5.7630 - val_mae: 5.7630\n",
            "Epoch 891/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0028 - mae: 12.0028 - val_loss: 5.7365 - val_mae: 5.7365\n",
            "Epoch 892/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0010 - mae: 12.0010 - val_loss: 5.7511 - val_mae: 5.7511\n",
            "Epoch 893/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0103 - mae: 12.0103 - val_loss: 5.7233 - val_mae: 5.7233\n",
            "Epoch 894/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9960 - mae: 11.9960 - val_loss: 5.7464 - val_mae: 5.7464\n",
            "Epoch 895/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9949 - mae: 11.9949 - val_loss: 5.7157 - val_mae: 5.7157\n",
            "Epoch 896/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0054 - mae: 12.0054 - val_loss: 5.7314 - val_mae: 5.7314\n",
            "Epoch 897/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0027 - mae: 12.0027 - val_loss: 5.7138 - val_mae: 5.7138\n",
            "Epoch 898/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9940 - mae: 11.9940 - val_loss: 5.7326 - val_mae: 5.7326\n",
            "Epoch 899/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9981 - mae: 11.9981 - val_loss: 5.7267 - val_mae: 5.7267\n",
            "Epoch 900/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9958 - mae: 11.9958 - val_loss: 5.7308 - val_mae: 5.7308\n",
            "Epoch 901/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 12.0061 - mae: 12.0061 - val_loss: 5.7226 - val_mae: 5.7226\n",
            "Epoch 902/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9996 - mae: 11.9996 - val_loss: 5.7158 - val_mae: 5.7158\n",
            "Epoch 903/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9952 - mae: 11.9952 - val_loss: 5.7175 - val_mae: 5.7175\n",
            "Epoch 904/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9918 - mae: 11.9918 - val_loss: 5.7267 - val_mae: 5.7267\n",
            "Epoch 905/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0057 - mae: 12.0057 - val_loss: 5.7210 - val_mae: 5.7210\n",
            "Epoch 906/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0036 - mae: 12.0036 - val_loss: 5.7131 - val_mae: 5.7131\n",
            "Epoch 907/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9920 - mae: 11.9920 - val_loss: 5.7298 - val_mae: 5.7298\n",
            "Epoch 908/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9980 - mae: 11.9980 - val_loss: 5.7093 - val_mae: 5.7093\n",
            "Epoch 909/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9913 - mae: 11.9913 - val_loss: 5.7415 - val_mae: 5.7415\n",
            "Epoch 910/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9979 - mae: 11.9979 - val_loss: 5.7226 - val_mae: 5.7226\n",
            "Epoch 911/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9878 - mae: 11.9878 - val_loss: 5.7124 - val_mae: 5.7124\n",
            "Epoch 912/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9900 - mae: 11.9900 - val_loss: 5.7142 - val_mae: 5.7142\n",
            "Epoch 913/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9909 - mae: 11.9909 - val_loss: 5.7268 - val_mae: 5.7268\n",
            "Epoch 914/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0022 - mae: 12.0022 - val_loss: 5.7161 - val_mae: 5.7161\n",
            "Epoch 915/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9989 - mae: 11.9989 - val_loss: 5.7171 - val_mae: 5.7171\n",
            "Epoch 916/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9857 - mae: 11.9857 - val_loss: 5.7149 - val_mae: 5.7149\n",
            "Epoch 917/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9973 - mae: 11.9973 - val_loss: 5.7485 - val_mae: 5.7485\n",
            "Epoch 918/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 12.0016 - mae: 12.0016 - val_loss: 5.7136 - val_mae: 5.7136\n",
            "Epoch 919/2000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 12.0085 - mae: 12.0085 - val_loss: 5.7235 - val_mae: 5.7235\n",
            "Epoch 920/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0031 - mae: 12.0031 - val_loss: 5.7320 - val_mae: 5.7320\n",
            "Epoch 921/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9938 - mae: 11.9938 - val_loss: 5.7061 - val_mae: 5.7061\n",
            "Epoch 922/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9962 - mae: 11.9962 - val_loss: 5.7339 - val_mae: 5.7339\n",
            "Epoch 923/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 12.0030 - mae: 12.0030 - val_loss: 5.7414 - val_mae: 5.7414\n",
            "Epoch 924/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0009 - mae: 12.0009 - val_loss: 5.7123 - val_mae: 5.7123\n",
            "Epoch 925/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9876 - mae: 11.9876 - val_loss: 5.7210 - val_mae: 5.7210\n",
            "Epoch 926/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9879 - mae: 11.9879 - val_loss: 5.7160 - val_mae: 5.7160\n",
            "Epoch 927/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9985 - mae: 11.9985 - val_loss: 5.7313 - val_mae: 5.7313\n",
            "Epoch 928/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0007 - mae: 12.0007 - val_loss: 5.7047 - val_mae: 5.7047\n",
            "Epoch 929/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0076 - mae: 12.0076 - val_loss: 5.7317 - val_mae: 5.7317\n",
            "Epoch 930/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0042 - mae: 12.0042 - val_loss: 5.7082 - val_mae: 5.7082\n",
            "Epoch 931/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9958 - mae: 11.9958 - val_loss: 5.7101 - val_mae: 5.7101\n",
            "Epoch 932/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9973 - mae: 11.9973 - val_loss: 5.7214 - val_mae: 5.7214\n",
            "Epoch 933/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9874 - mae: 11.9874 - val_loss: 5.7039 - val_mae: 5.7039\n",
            "Epoch 934/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9827 - mae: 11.9827 - val_loss: 5.7246 - val_mae: 5.7246\n",
            "Epoch 935/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9871 - mae: 11.9871 - val_loss: 5.6965 - val_mae: 5.6965\n",
            "Epoch 936/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9789 - mae: 11.9789 - val_loss: 5.7218 - val_mae: 5.7218\n",
            "Epoch 937/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9924 - mae: 11.9924 - val_loss: 5.6997 - val_mae: 5.6997\n",
            "Epoch 938/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9874 - mae: 11.9874 - val_loss: 5.7117 - val_mae: 5.7117\n",
            "Epoch 939/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9786 - mae: 11.9786 - val_loss: 5.7250 - val_mae: 5.7250\n",
            "Epoch 940/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9867 - mae: 11.9867 - val_loss: 5.7102 - val_mae: 5.7102\n",
            "Epoch 941/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9871 - mae: 11.9871 - val_loss: 5.7138 - val_mae: 5.7138\n",
            "Epoch 942/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9879 - mae: 11.9879 - val_loss: 5.6971 - val_mae: 5.6971\n",
            "Epoch 943/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0800 - mae: 12.0800 - val_loss: 5.8068 - val_mae: 5.8068\n",
            "Epoch 944/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0416 - mae: 12.0416 - val_loss: 5.7459 - val_mae: 5.7459\n",
            "Epoch 945/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0360 - mae: 12.0360 - val_loss: 5.7745 - val_mae: 5.7745\n",
            "Epoch 946/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 12.0307 - mae: 12.0307 - val_loss: 5.7765 - val_mae: 5.7765\n",
            "Epoch 947/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0179 - mae: 12.0179 - val_loss: 5.7286 - val_mae: 5.7286\n",
            "Epoch 948/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9853 - mae: 11.9853 - val_loss: 5.7164 - val_mae: 5.7164\n",
            "Epoch 949/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9891 - mae: 11.9891 - val_loss: 5.7262 - val_mae: 5.7262\n",
            "Epoch 950/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9884 - mae: 11.9884 - val_loss: 5.6974 - val_mae: 5.6974\n",
            "Epoch 951/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9880 - mae: 11.9880 - val_loss: 5.7176 - val_mae: 5.7176\n",
            "Epoch 952/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9964 - mae: 11.9964 - val_loss: 5.6967 - val_mae: 5.6967\n",
            "Epoch 953/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0092 - mae: 12.0092 - val_loss: 5.7333 - val_mae: 5.7333\n",
            "Epoch 954/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0069 - mae: 12.0069 - val_loss: 5.7518 - val_mae: 5.7518\n",
            "Epoch 955/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 12.0502 - mae: 12.0502 - val_loss: 5.7990 - val_mae: 5.7990\n",
            "Epoch 956/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0389 - mae: 12.0389 - val_loss: 5.7452 - val_mae: 5.7452\n",
            "Epoch 957/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9919 - mae: 11.9919 - val_loss: 5.7428 - val_mae: 5.7428\n",
            "Epoch 958/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9887 - mae: 11.9887 - val_loss: 5.7261 - val_mae: 5.7261\n",
            "Epoch 959/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9857 - mae: 11.9857 - val_loss: 5.6989 - val_mae: 5.6989\n",
            "Epoch 960/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9789 - mae: 11.9789 - val_loss: 5.7009 - val_mae: 5.7009\n",
            "Epoch 961/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9790 - mae: 11.9790 - val_loss: 5.7170 - val_mae: 5.7170\n",
            "Epoch 962/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9774 - mae: 11.9774 - val_loss: 5.7160 - val_mae: 5.7160\n",
            "Epoch 963/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9788 - mae: 11.9788 - val_loss: 5.7100 - val_mae: 5.7100\n",
            "Epoch 964/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9784 - mae: 11.9784 - val_loss: 5.6997 - val_mae: 5.6997\n",
            "Epoch 965/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9840 - mae: 11.9840 - val_loss: 5.7072 - val_mae: 5.7072\n",
            "Epoch 966/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9792 - mae: 11.9792 - val_loss: 5.6995 - val_mae: 5.6995\n",
            "Epoch 967/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9741 - mae: 11.9741 - val_loss: 5.7120 - val_mae: 5.7120\n",
            "Epoch 968/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9763 - mae: 11.9763 - val_loss: 5.6888 - val_mae: 5.6888\n",
            "Epoch 969/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9823 - mae: 11.9823 - val_loss: 5.7054 - val_mae: 5.7054\n",
            "Epoch 970/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9769 - mae: 11.9769 - val_loss: 5.6887 - val_mae: 5.6887\n",
            "Epoch 971/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9719 - mae: 11.9719 - val_loss: 5.7060 - val_mae: 5.7060\n",
            "Epoch 972/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9779 - mae: 11.9779 - val_loss: 5.6979 - val_mae: 5.6979\n",
            "Epoch 973/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9731 - mae: 11.9731 - val_loss: 5.6882 - val_mae: 5.6882\n",
            "Epoch 974/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9681 - mae: 11.9681 - val_loss: 5.6994 - val_mae: 5.6994\n",
            "Epoch 975/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9775 - mae: 11.9775 - val_loss: 5.6876 - val_mae: 5.6876\n",
            "Epoch 976/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9708 - mae: 11.9708 - val_loss: 5.6946 - val_mae: 5.6946\n",
            "Epoch 977/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9771 - mae: 11.9771 - val_loss: 5.6984 - val_mae: 5.6984\n",
            "Epoch 978/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9890 - mae: 11.9890 - val_loss: 5.6816 - val_mae: 5.6816\n",
            "Epoch 979/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9907 - mae: 11.9907 - val_loss: 5.7261 - val_mae: 5.7261\n",
            "Epoch 980/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9755 - mae: 11.9755 - val_loss: 5.6902 - val_mae: 5.6902\n",
            "Epoch 981/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9774 - mae: 11.9774 - val_loss: 5.7054 - val_mae: 5.7054\n",
            "Epoch 982/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9945 - mae: 11.9945 - val_loss: 5.7045 - val_mae: 5.7045\n",
            "Epoch 983/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9829 - mae: 11.9829 - val_loss: 5.6860 - val_mae: 5.6860\n",
            "Epoch 984/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9933 - mae: 11.9933 - val_loss: 5.7236 - val_mae: 5.7236\n",
            "Epoch 985/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9801 - mae: 11.9801 - val_loss: 5.6888 - val_mae: 5.6888\n",
            "Epoch 986/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9780 - mae: 11.9780 - val_loss: 5.7126 - val_mae: 5.7126\n",
            "Epoch 987/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9650 - mae: 11.9650 - val_loss: 5.6857 - val_mae: 5.6857\n",
            "Epoch 988/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9781 - mae: 11.9781 - val_loss: 5.6817 - val_mae: 5.6817\n",
            "Epoch 989/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9663 - mae: 11.9663 - val_loss: 5.7176 - val_mae: 5.7176\n",
            "Epoch 990/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9753 - mae: 11.9753 - val_loss: 5.6929 - val_mae: 5.6929\n",
            "Epoch 991/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9699 - mae: 11.9699 - val_loss: 5.6991 - val_mae: 5.6991\n",
            "Epoch 992/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9782 - mae: 11.9782 - val_loss: 5.6874 - val_mae: 5.6874\n",
            "Epoch 993/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9681 - mae: 11.9681 - val_loss: 5.6916 - val_mae: 5.6916\n",
            "Epoch 994/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9718 - mae: 11.9718 - val_loss: 5.7058 - val_mae: 5.7058\n",
            "Epoch 995/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9850 - mae: 11.9850 - val_loss: 5.7035 - val_mae: 5.7035\n",
            "Epoch 996/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9659 - mae: 11.9659 - val_loss: 5.6792 - val_mae: 5.6792\n",
            "Epoch 997/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9667 - mae: 11.9667 - val_loss: 5.6809 - val_mae: 5.6809\n",
            "Epoch 998/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9645 - mae: 11.9645 - val_loss: 5.6899 - val_mae: 5.6899\n",
            "Epoch 999/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9613 - mae: 11.9613 - val_loss: 5.6832 - val_mae: 5.6832\n",
            "Epoch 1000/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9630 - mae: 11.9630 - val_loss: 5.6914 - val_mae: 5.6914\n",
            "Epoch 1001/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9798 - mae: 11.9798 - val_loss: 5.6983 - val_mae: 5.6983\n",
            "Epoch 1002/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9656 - mae: 11.9656 - val_loss: 5.6822 - val_mae: 5.6822\n",
            "Epoch 1003/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9679 - mae: 11.9679 - val_loss: 5.6941 - val_mae: 5.6941\n",
            "Epoch 1004/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9677 - mae: 11.9677 - val_loss: 5.6836 - val_mae: 5.6836\n",
            "Epoch 1005/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9623 - mae: 11.9623 - val_loss: 5.6889 - val_mae: 5.6889\n",
            "Epoch 1006/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9737 - mae: 11.9737 - val_loss: 5.7049 - val_mae: 5.7049\n",
            "Epoch 1007/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9775 - mae: 11.9775 - val_loss: 5.7017 - val_mae: 5.7017\n",
            "Epoch 1008/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9741 - mae: 11.9741 - val_loss: 5.6893 - val_mae: 5.6893\n",
            "Epoch 1009/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9660 - mae: 11.9660 - val_loss: 5.6818 - val_mae: 5.6818\n",
            "Epoch 1010/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9616 - mae: 11.9616 - val_loss: 5.6869 - val_mae: 5.6869\n",
            "Epoch 1011/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9637 - mae: 11.9637 - val_loss: 5.6870 - val_mae: 5.6870\n",
            "Epoch 1012/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9671 - mae: 11.9671 - val_loss: 5.6909 - val_mae: 5.6909\n",
            "Epoch 1013/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9721 - mae: 11.9721 - val_loss: 5.6789 - val_mae: 5.6789\n",
            "Epoch 1014/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9987 - mae: 11.9987 - val_loss: 5.7296 - val_mae: 5.7296\n",
            "Epoch 1015/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9635 - mae: 11.9635 - val_loss: 5.6966 - val_mae: 5.6966\n",
            "Epoch 1016/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9676 - mae: 11.9676 - val_loss: 5.6891 - val_mae: 5.6891\n",
            "Epoch 1017/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9781 - mae: 11.9781 - val_loss: 5.6911 - val_mae: 5.6911\n",
            "Epoch 1018/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9844 - mae: 11.9844 - val_loss: 5.7005 - val_mae: 5.7005\n",
            "Epoch 1019/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9812 - mae: 11.9812 - val_loss: 5.7362 - val_mae: 5.7362\n",
            "Epoch 1020/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9764 - mae: 11.9764 - val_loss: 5.6918 - val_mae: 5.6918\n",
            "Epoch 1021/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9674 - mae: 11.9674 - val_loss: 5.7002 - val_mae: 5.7002\n",
            "Epoch 1022/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9776 - mae: 11.9776 - val_loss: 5.7197 - val_mae: 5.7197\n",
            "Epoch 1023/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9786 - mae: 11.9786 - val_loss: 5.7034 - val_mae: 5.7034\n",
            "Epoch 1024/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 12.0129 - mae: 12.0129 - val_loss: 5.6811 - val_mae: 5.6811\n",
            "Epoch 1025/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9755 - mae: 11.9755 - val_loss: 5.7029 - val_mae: 5.7029\n",
            "Epoch 1026/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9758 - mae: 11.9758 - val_loss: 5.7419 - val_mae: 5.7419\n",
            "Epoch 1027/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9827 - mae: 11.9827 - val_loss: 5.7319 - val_mae: 5.7319\n",
            "Epoch 1028/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9766 - mae: 11.9766 - val_loss: 5.7458 - val_mae: 5.7458\n",
            "Epoch 1029/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9869 - mae: 11.9869 - val_loss: 5.7221 - val_mae: 5.7221\n",
            "Epoch 1030/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9748 - mae: 11.9748 - val_loss: 5.7077 - val_mae: 5.7077\n",
            "Epoch 1031/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9868 - mae: 11.9868 - val_loss: 5.6886 - val_mae: 5.6886\n",
            "Epoch 1032/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9646 - mae: 11.9646 - val_loss: 5.6853 - val_mae: 5.6853\n",
            "Epoch 1033/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9586 - mae: 11.9586 - val_loss: 5.6722 - val_mae: 5.6722\n",
            "Epoch 1034/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9578 - mae: 11.9578 - val_loss: 5.6750 - val_mae: 5.6750\n",
            "Epoch 1035/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9532 - mae: 11.9532 - val_loss: 5.6782 - val_mae: 5.6782\n",
            "Epoch 1036/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9544 - mae: 11.9544 - val_loss: 5.6683 - val_mae: 5.6683\n",
            "Epoch 1037/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9527 - mae: 11.9527 - val_loss: 5.6787 - val_mae: 5.6787\n",
            "Epoch 1038/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9543 - mae: 11.9543 - val_loss: 5.7025 - val_mae: 5.7025\n",
            "Epoch 1039/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9696 - mae: 11.9696 - val_loss: 5.6842 - val_mae: 5.6842\n",
            "Epoch 1040/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9547 - mae: 11.9547 - val_loss: 5.6812 - val_mae: 5.6812\n",
            "Epoch 1041/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9590 - mae: 11.9590 - val_loss: 5.6758 - val_mae: 5.6758\n",
            "Epoch 1042/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9655 - mae: 11.9655 - val_loss: 5.7025 - val_mae: 5.7025\n",
            "Epoch 1043/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9626 - mae: 11.9626 - val_loss: 5.6774 - val_mae: 5.6774\n",
            "Epoch 1044/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9648 - mae: 11.9648 - val_loss: 5.6816 - val_mae: 5.6816\n",
            "Epoch 1045/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9543 - mae: 11.9543 - val_loss: 5.6738 - val_mae: 5.6738\n",
            "Epoch 1046/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9586 - mae: 11.9586 - val_loss: 5.6776 - val_mae: 5.6776\n",
            "Epoch 1047/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9579 - mae: 11.9579 - val_loss: 5.6868 - val_mae: 5.6868\n",
            "Epoch 1048/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9569 - mae: 11.9569 - val_loss: 5.6679 - val_mae: 5.6679\n",
            "Epoch 1049/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9644 - mae: 11.9644 - val_loss: 5.7006 - val_mae: 5.7006\n",
            "Epoch 1050/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9664 - mae: 11.9664 - val_loss: 5.6973 - val_mae: 5.6973\n",
            "Epoch 1051/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9622 - mae: 11.9622 - val_loss: 5.6764 - val_mae: 5.6764\n",
            "Epoch 1052/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9595 - mae: 11.9595 - val_loss: 5.6622 - val_mae: 5.6622\n",
            "Epoch 1053/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9607 - mae: 11.9607 - val_loss: 5.6820 - val_mae: 5.6820\n",
            "Epoch 1054/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9525 - mae: 11.9525 - val_loss: 5.6617 - val_mae: 5.6617\n",
            "Epoch 1055/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9526 - mae: 11.9526 - val_loss: 5.6654 - val_mae: 5.6654\n",
            "Epoch 1056/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9634 - mae: 11.9634 - val_loss: 5.6872 - val_mae: 5.6872\n",
            "Epoch 1057/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9723 - mae: 11.9723 - val_loss: 5.7136 - val_mae: 5.7136\n",
            "Epoch 1058/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9986 - mae: 11.9986 - val_loss: 5.7365 - val_mae: 5.7365\n",
            "Epoch 1059/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9700 - mae: 11.9700 - val_loss: 5.6866 - val_mae: 5.6866\n",
            "Epoch 1060/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9550 - mae: 11.9550 - val_loss: 5.6881 - val_mae: 5.6881\n",
            "Epoch 1061/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9606 - mae: 11.9606 - val_loss: 5.6660 - val_mae: 5.6660\n",
            "Epoch 1062/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9731 - mae: 11.9731 - val_loss: 5.6676 - val_mae: 5.6676\n",
            "Epoch 1063/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9774 - mae: 11.9774 - val_loss: 5.6979 - val_mae: 5.6979\n",
            "Epoch 1064/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9569 - mae: 11.9569 - val_loss: 5.6946 - val_mae: 5.6946\n",
            "Epoch 1065/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9791 - mae: 11.9791 - val_loss: 5.6997 - val_mae: 5.6997\n",
            "Epoch 1066/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9833 - mae: 11.9833 - val_loss: 5.6797 - val_mae: 5.6797\n",
            "Epoch 1067/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9626 - mae: 11.9626 - val_loss: 5.6862 - val_mae: 5.6862\n",
            "Epoch 1068/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9604 - mae: 11.9604 - val_loss: 5.6888 - val_mae: 5.6888\n",
            "Epoch 1069/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9556 - mae: 11.9556 - val_loss: 5.6575 - val_mae: 5.6575\n",
            "Epoch 1070/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9536 - mae: 11.9536 - val_loss: 5.6886 - val_mae: 5.6886\n",
            "Epoch 1071/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9612 - mae: 11.9612 - val_loss: 5.7116 - val_mae: 5.7116\n",
            "Epoch 1072/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9695 - mae: 11.9695 - val_loss: 5.7142 - val_mae: 5.7142\n",
            "Epoch 1073/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9634 - mae: 11.9634 - val_loss: 5.6985 - val_mae: 5.6985\n",
            "Epoch 1074/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9621 - mae: 11.9621 - val_loss: 5.6986 - val_mae: 5.6986\n",
            "Epoch 1075/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9711 - mae: 11.9711 - val_loss: 5.6734 - val_mae: 5.6734\n",
            "Epoch 1076/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9619 - mae: 11.9619 - val_loss: 5.6781 - val_mae: 5.6781\n",
            "Epoch 1077/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9660 - mae: 11.9660 - val_loss: 5.6818 - val_mae: 5.6818\n",
            "Epoch 1078/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9752 - mae: 11.9752 - val_loss: 5.6799 - val_mae: 5.6799\n",
            "Epoch 1079/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9553 - mae: 11.9553 - val_loss: 5.6996 - val_mae: 5.6996\n",
            "Epoch 1080/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9666 - mae: 11.9666 - val_loss: 5.6641 - val_mae: 5.6641\n",
            "Epoch 1081/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9655 - mae: 11.9655 - val_loss: 5.6593 - val_mae: 5.6593\n",
            "Epoch 1082/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9423 - mae: 11.9423 - val_loss: 5.6731 - val_mae: 5.6731\n",
            "Epoch 1083/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9604 - mae: 11.9604 - val_loss: 5.6922 - val_mae: 5.6922\n",
            "Epoch 1084/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9712 - mae: 11.9712 - val_loss: 5.7026 - val_mae: 5.7026\n",
            "Epoch 1085/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9648 - mae: 11.9648 - val_loss: 5.6643 - val_mae: 5.6643\n",
            "Epoch 1086/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9520 - mae: 11.9520 - val_loss: 5.6704 - val_mae: 5.6704\n",
            "Epoch 1087/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9519 - mae: 11.9519 - val_loss: 5.6644 - val_mae: 5.6644\n",
            "Epoch 1088/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9526 - mae: 11.9526 - val_loss: 5.6833 - val_mae: 5.6833\n",
            "Epoch 1089/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9519 - mae: 11.9519 - val_loss: 5.6757 - val_mae: 5.6757\n",
            "Epoch 1090/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9667 - mae: 11.9667 - val_loss: 5.7173 - val_mae: 5.7173\n",
            "Epoch 1091/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9607 - mae: 11.9607 - val_loss: 5.6942 - val_mae: 5.6942\n",
            "Epoch 1092/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9633 - mae: 11.9633 - val_loss: 5.6830 - val_mae: 5.6830\n",
            "Epoch 1093/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9437 - mae: 11.9437 - val_loss: 5.6603 - val_mae: 5.6603\n",
            "Epoch 1094/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9425 - mae: 11.9425 - val_loss: 5.6825 - val_mae: 5.6825\n",
            "Epoch 1095/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9675 - mae: 11.9675 - val_loss: 5.6580 - val_mae: 5.6580\n",
            "Epoch 1096/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9543 - mae: 11.9543 - val_loss: 5.6659 - val_mae: 5.6659\n",
            "Epoch 1097/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9546 - mae: 11.9546 - val_loss: 5.6601 - val_mae: 5.6601\n",
            "Epoch 1098/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9521 - mae: 11.9521 - val_loss: 5.6606 - val_mae: 5.6606\n",
            "Epoch 1099/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9427 - mae: 11.9427 - val_loss: 5.6735 - val_mae: 5.6735\n",
            "Epoch 1100/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9494 - mae: 11.9494 - val_loss: 5.6561 - val_mae: 5.6561\n",
            "Epoch 1101/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9426 - mae: 11.9426 - val_loss: 5.6487 - val_mae: 5.6487\n",
            "Epoch 1102/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9411 - mae: 11.9411 - val_loss: 5.6569 - val_mae: 5.6569\n",
            "Epoch 1103/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9479 - mae: 11.9479 - val_loss: 5.6494 - val_mae: 5.6494\n",
            "Epoch 1104/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9424 - mae: 11.9424 - val_loss: 5.6645 - val_mae: 5.6645\n",
            "Epoch 1105/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9530 - mae: 11.9530 - val_loss: 5.6638 - val_mae: 5.6638\n",
            "Epoch 1106/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9368 - mae: 11.9368 - val_loss: 5.6665 - val_mae: 5.6665\n",
            "Epoch 1107/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9587 - mae: 11.9587 - val_loss: 5.6581 - val_mae: 5.6581\n",
            "Epoch 1108/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9434 - mae: 11.9434 - val_loss: 5.6429 - val_mae: 5.6429\n",
            "Epoch 1109/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9418 - mae: 11.9418 - val_loss: 5.6652 - val_mae: 5.6652\n",
            "Epoch 1110/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9464 - mae: 11.9464 - val_loss: 5.6545 - val_mae: 5.6545\n",
            "Epoch 1111/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9497 - mae: 11.9497 - val_loss: 5.6718 - val_mae: 5.6718\n",
            "Epoch 1112/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.9362 - mae: 11.9362 - val_loss: 5.6468 - val_mae: 5.6468\n",
            "Epoch 1113/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9313 - mae: 11.9313 - val_loss: 5.6608 - val_mae: 5.6608\n",
            "Epoch 1114/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9485 - mae: 11.9485 - val_loss: 5.6548 - val_mae: 5.6548\n",
            "Epoch 1115/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9308 - mae: 11.9308 - val_loss: 5.6442 - val_mae: 5.6442\n",
            "Epoch 1116/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9365 - mae: 11.9365 - val_loss: 5.6523 - val_mae: 5.6523\n",
            "Epoch 1117/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9364 - mae: 11.9364 - val_loss: 5.6504 - val_mae: 5.6504\n",
            "Epoch 1118/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9352 - mae: 11.9352 - val_loss: 5.6473 - val_mae: 5.6473\n",
            "Epoch 1119/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9395 - mae: 11.9395 - val_loss: 5.6445 - val_mae: 5.6445\n",
            "Epoch 1120/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9399 - mae: 11.9399 - val_loss: 5.6639 - val_mae: 5.6639\n",
            "Epoch 1121/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9365 - mae: 11.9365 - val_loss: 5.6490 - val_mae: 5.6490\n",
            "Epoch 1122/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9539 - mae: 11.9539 - val_loss: 5.6645 - val_mae: 5.6645\n",
            "Epoch 1123/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9407 - mae: 11.9407 - val_loss: 5.6782 - val_mae: 5.6782\n",
            "Epoch 1124/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9505 - mae: 11.9505 - val_loss: 5.6826 - val_mae: 5.6826\n",
            "Epoch 1125/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9492 - mae: 11.9492 - val_loss: 5.6438 - val_mae: 5.6438\n",
            "Epoch 1126/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9561 - mae: 11.9561 - val_loss: 5.6769 - val_mae: 5.6769\n",
            "Epoch 1127/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9670 - mae: 11.9670 - val_loss: 5.6750 - val_mae: 5.6750\n",
            "Epoch 1128/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9432 - mae: 11.9432 - val_loss: 5.6611 - val_mae: 5.6611\n",
            "Epoch 1129/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9671 - mae: 11.9671 - val_loss: 5.6810 - val_mae: 5.6810\n",
            "Epoch 1130/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9522 - mae: 11.9522 - val_loss: 5.6590 - val_mae: 5.6590\n",
            "Epoch 1131/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9646 - mae: 11.9646 - val_loss: 5.6674 - val_mae: 5.6674\n",
            "Epoch 1132/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9825 - mae: 11.9825 - val_loss: 5.6652 - val_mae: 5.6652\n",
            "Epoch 1133/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9457 - mae: 11.9457 - val_loss: 5.7052 - val_mae: 5.7052\n",
            "Epoch 1134/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9569 - mae: 11.9569 - val_loss: 5.6441 - val_mae: 5.6441\n",
            "Epoch 1135/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9557 - mae: 11.9557 - val_loss: 5.6689 - val_mae: 5.6689\n",
            "Epoch 1136/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9490 - mae: 11.9490 - val_loss: 5.6869 - val_mae: 5.6869\n",
            "Epoch 1137/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9499 - mae: 11.9499 - val_loss: 5.6495 - val_mae: 5.6495\n",
            "Epoch 1138/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9372 - mae: 11.9372 - val_loss: 5.6425 - val_mae: 5.6425\n",
            "Epoch 1139/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9334 - mae: 11.9334 - val_loss: 5.6528 - val_mae: 5.6528\n",
            "Epoch 1140/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9363 - mae: 11.9363 - val_loss: 5.6482 - val_mae: 5.6482\n",
            "Epoch 1141/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9293 - mae: 11.9293 - val_loss: 5.6557 - val_mae: 5.6557\n",
            "Epoch 1142/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9343 - mae: 11.9343 - val_loss: 5.6435 - val_mae: 5.6435\n",
            "Epoch 1143/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9407 - mae: 11.9407 - val_loss: 5.6502 - val_mae: 5.6502\n",
            "Epoch 1144/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9542 - mae: 11.9542 - val_loss: 5.6747 - val_mae: 5.6747\n",
            "Epoch 1145/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9853 - mae: 11.9853 - val_loss: 5.6776 - val_mae: 5.6776\n",
            "Epoch 1146/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9433 - mae: 11.9433 - val_loss: 5.6933 - val_mae: 5.6933\n",
            "Epoch 1147/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9495 - mae: 11.9495 - val_loss: 5.6453 - val_mae: 5.6453\n",
            "Epoch 1148/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9536 - mae: 11.9536 - val_loss: 5.6586 - val_mae: 5.6586\n",
            "Epoch 1149/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9694 - mae: 11.9694 - val_loss: 5.6969 - val_mae: 5.6969\n",
            "Epoch 1150/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9663 - mae: 11.9663 - val_loss: 5.6523 - val_mae: 5.6523\n",
            "Epoch 1151/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9416 - mae: 11.9416 - val_loss: 5.6508 - val_mae: 5.6508\n",
            "Epoch 1152/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9407 - mae: 11.9407 - val_loss: 5.6648 - val_mae: 5.6648\n",
            "Epoch 1153/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9487 - mae: 11.9487 - val_loss: 5.6642 - val_mae: 5.6642\n",
            "Epoch 1154/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9468 - mae: 11.9468 - val_loss: 5.6933 - val_mae: 5.6933\n",
            "Epoch 1155/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9577 - mae: 11.9577 - val_loss: 5.6951 - val_mae: 5.6951\n",
            "Epoch 1156/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9449 - mae: 11.9449 - val_loss: 5.6600 - val_mae: 5.6600\n",
            "Epoch 1157/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9425 - mae: 11.9425 - val_loss: 5.6687 - val_mae: 5.6687\n",
            "Epoch 1158/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9478 - mae: 11.9478 - val_loss: 5.6577 - val_mae: 5.6577\n",
            "Epoch 1159/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9517 - mae: 11.9517 - val_loss: 5.6480 - val_mae: 5.6480\n",
            "Epoch 1160/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9437 - mae: 11.9437 - val_loss: 5.6564 - val_mae: 5.6564\n",
            "Epoch 1161/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9505 - mae: 11.9505 - val_loss: 5.6705 - val_mae: 5.6705\n",
            "Epoch 1162/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9397 - mae: 11.9397 - val_loss: 5.6749 - val_mae: 5.6749\n",
            "Epoch 1163/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9598 - mae: 11.9598 - val_loss: 5.6531 - val_mae: 5.6531\n",
            "Epoch 1164/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9432 - mae: 11.9432 - val_loss: 5.6626 - val_mae: 5.6626\n",
            "Epoch 1165/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9626 - mae: 11.9626 - val_loss: 5.6838 - val_mae: 5.6838\n",
            "Epoch 1166/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9749 - mae: 11.9749 - val_loss: 5.6971 - val_mae: 5.6971\n",
            "Epoch 1167/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9574 - mae: 11.9574 - val_loss: 5.7035 - val_mae: 5.7035\n",
            "Epoch 1168/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9549 - mae: 11.9549 - val_loss: 5.6566 - val_mae: 5.6566\n",
            "Epoch 1169/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9333 - mae: 11.9333 - val_loss: 5.6550 - val_mae: 5.6550\n",
            "Epoch 1170/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9459 - mae: 11.9459 - val_loss: 5.6434 - val_mae: 5.6434\n",
            "Epoch 1171/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9511 - mae: 11.9511 - val_loss: 5.6384 - val_mae: 5.6384\n",
            "Epoch 1172/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9334 - mae: 11.9334 - val_loss: 5.6760 - val_mae: 5.6760\n",
            "Epoch 1173/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9672 - mae: 11.9672 - val_loss: 5.6435 - val_mae: 5.6435\n",
            "Epoch 1174/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9270 - mae: 11.9270 - val_loss: 5.6583 - val_mae: 5.6583\n",
            "Epoch 1175/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9429 - mae: 11.9429 - val_loss: 5.6474 - val_mae: 5.6474\n",
            "Epoch 1176/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9472 - mae: 11.9472 - val_loss: 5.6513 - val_mae: 5.6513\n",
            "Epoch 1177/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9307 - mae: 11.9307 - val_loss: 5.6390 - val_mae: 5.6390\n",
            "Epoch 1178/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9271 - mae: 11.9271 - val_loss: 5.6358 - val_mae: 5.6358\n",
            "Epoch 1179/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9227 - mae: 11.9227 - val_loss: 5.6292 - val_mae: 5.6292\n",
            "Epoch 1180/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9243 - mae: 11.9243 - val_loss: 5.6421 - val_mae: 5.6421\n",
            "Epoch 1181/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9295 - mae: 11.9295 - val_loss: 5.6460 - val_mae: 5.6460\n",
            "Epoch 1182/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9354 - mae: 11.9354 - val_loss: 5.6334 - val_mae: 5.6334\n",
            "Epoch 1183/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9464 - mae: 11.9464 - val_loss: 5.6776 - val_mae: 5.6776\n",
            "Epoch 1184/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9441 - mae: 11.9441 - val_loss: 5.6623 - val_mae: 5.6623\n",
            "Epoch 1185/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9418 - mae: 11.9418 - val_loss: 5.6548 - val_mae: 5.6548\n",
            "Epoch 1186/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9287 - mae: 11.9287 - val_loss: 5.6418 - val_mae: 5.6418\n",
            "Epoch 1187/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9317 - mae: 11.9317 - val_loss: 5.6649 - val_mae: 5.6649\n",
            "Epoch 1188/2000\n",
            "5/5 [==============================] - 0s 19ms/step - loss: 11.9497 - mae: 11.9497 - val_loss: 5.6480 - val_mae: 5.6480\n",
            "Epoch 1189/2000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11.9681 - mae: 11.9681 - val_loss: 5.6383 - val_mae: 5.6383\n",
            "Epoch 1190/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9310 - mae: 11.9310 - val_loss: 5.6874 - val_mae: 5.6874\n",
            "Epoch 1191/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9377 - mae: 11.9377 - val_loss: 5.6320 - val_mae: 5.6320\n",
            "Epoch 1192/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9638 - mae: 11.9638 - val_loss: 5.6295 - val_mae: 5.6295\n",
            "Epoch 1193/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9180 - mae: 11.9180 - val_loss: 5.6445 - val_mae: 5.6445\n",
            "Epoch 1194/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9284 - mae: 11.9284 - val_loss: 5.6317 - val_mae: 5.6317\n",
            "Epoch 1195/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9221 - mae: 11.9221 - val_loss: 5.6392 - val_mae: 5.6392\n",
            "Epoch 1196/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9314 - mae: 11.9314 - val_loss: 5.6367 - val_mae: 5.6367\n",
            "Epoch 1197/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9385 - mae: 11.9385 - val_loss: 5.6320 - val_mae: 5.6320\n",
            "Epoch 1198/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9397 - mae: 11.9397 - val_loss: 5.6343 - val_mae: 5.6343\n",
            "Epoch 1199/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9369 - mae: 11.9369 - val_loss: 5.6379 - val_mae: 5.6379\n",
            "Epoch 1200/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9637 - mae: 11.9637 - val_loss: 5.6314 - val_mae: 5.6314\n",
            "Epoch 1201/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9318 - mae: 11.9318 - val_loss: 5.6849 - val_mae: 5.6849\n",
            "Epoch 1202/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9427 - mae: 11.9427 - val_loss: 5.6358 - val_mae: 5.6358\n",
            "Epoch 1203/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9352 - mae: 11.9352 - val_loss: 5.6433 - val_mae: 5.6433\n",
            "Epoch 1204/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9320 - mae: 11.9320 - val_loss: 5.6444 - val_mae: 5.6444\n",
            "Epoch 1205/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9308 - mae: 11.9308 - val_loss: 5.6268 - val_mae: 5.6268\n",
            "Epoch 1206/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9362 - mae: 11.9362 - val_loss: 5.6599 - val_mae: 5.6599\n",
            "Epoch 1207/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9249 - mae: 11.9249 - val_loss: 5.6478 - val_mae: 5.6478\n",
            "Epoch 1208/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9305 - mae: 11.9305 - val_loss: 5.6386 - val_mae: 5.6386\n",
            "Epoch 1209/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9297 - mae: 11.9297 - val_loss: 5.6234 - val_mae: 5.6234\n",
            "Epoch 1210/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9233 - mae: 11.9233 - val_loss: 5.6241 - val_mae: 5.6241\n",
            "Epoch 1211/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9332 - mae: 11.9332 - val_loss: 5.6324 - val_mae: 5.6324\n",
            "Epoch 1212/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9340 - mae: 11.9340 - val_loss: 5.6651 - val_mae: 5.6651\n",
            "Epoch 1213/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9312 - mae: 11.9312 - val_loss: 5.6243 - val_mae: 5.6243\n",
            "Epoch 1214/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9235 - mae: 11.9235 - val_loss: 5.6245 - val_mae: 5.6245\n",
            "Epoch 1215/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9506 - mae: 11.9506 - val_loss: 5.6603 - val_mae: 5.6603\n",
            "Epoch 1216/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9260 - mae: 11.9260 - val_loss: 5.6388 - val_mae: 5.6388\n",
            "Epoch 1217/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9386 - mae: 11.9386 - val_loss: 5.6418 - val_mae: 5.6418\n",
            "Epoch 1218/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9348 - mae: 11.9348 - val_loss: 5.6332 - val_mae: 5.6332\n",
            "Epoch 1219/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9258 - mae: 11.9258 - val_loss: 5.6284 - val_mae: 5.6284\n",
            "Epoch 1220/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9248 - mae: 11.9248 - val_loss: 5.6288 - val_mae: 5.6288\n",
            "Epoch 1221/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9296 - mae: 11.9296 - val_loss: 5.6248 - val_mae: 5.6248\n",
            "Epoch 1222/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9360 - mae: 11.9360 - val_loss: 5.6504 - val_mae: 5.6504\n",
            "Epoch 1223/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9179 - mae: 11.9179 - val_loss: 5.6279 - val_mae: 5.6279\n",
            "Epoch 1224/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9208 - mae: 11.9208 - val_loss: 5.6332 - val_mae: 5.6332\n",
            "Epoch 1225/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9241 - mae: 11.9241 - val_loss: 5.6210 - val_mae: 5.6210\n",
            "Epoch 1226/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9183 - mae: 11.9183 - val_loss: 5.6214 - val_mae: 5.6214\n",
            "Epoch 1227/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9205 - mae: 11.9205 - val_loss: 5.6336 - val_mae: 5.6336\n",
            "Epoch 1228/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9199 - mae: 11.9199 - val_loss: 5.6296 - val_mae: 5.6296\n",
            "Epoch 1229/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9178 - mae: 11.9178 - val_loss: 5.6271 - val_mae: 5.6271\n",
            "Epoch 1230/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9315 - mae: 11.9315 - val_loss: 5.6269 - val_mae: 5.6269\n",
            "Epoch 1231/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9465 - mae: 11.9465 - val_loss: 5.6428 - val_mae: 5.6428\n",
            "Epoch 1232/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9351 - mae: 11.9351 - val_loss: 5.6720 - val_mae: 5.6720\n",
            "Epoch 1233/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9286 - mae: 11.9286 - val_loss: 5.6231 - val_mae: 5.6231\n",
            "Epoch 1234/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9241 - mae: 11.9241 - val_loss: 5.6220 - val_mae: 5.6220\n",
            "Epoch 1235/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9168 - mae: 11.9168 - val_loss: 5.6237 - val_mae: 5.6237\n",
            "Epoch 1236/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9144 - mae: 11.9144 - val_loss: 5.6152 - val_mae: 5.6152\n",
            "Epoch 1237/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9158 - mae: 11.9158 - val_loss: 5.6181 - val_mae: 5.6181\n",
            "Epoch 1238/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9166 - mae: 11.9166 - val_loss: 5.6311 - val_mae: 5.6311\n",
            "Epoch 1239/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9340 - mae: 11.9340 - val_loss: 5.6356 - val_mae: 5.6356\n",
            "Epoch 1240/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9258 - mae: 11.9258 - val_loss: 5.6364 - val_mae: 5.6364\n",
            "Epoch 1241/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9265 - mae: 11.9265 - val_loss: 5.6371 - val_mae: 5.6371\n",
            "Epoch 1242/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9311 - mae: 11.9311 - val_loss: 5.6428 - val_mae: 5.6428\n",
            "Epoch 1243/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9390 - mae: 11.9390 - val_loss: 5.6568 - val_mae: 5.6568\n",
            "Epoch 1244/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9325 - mae: 11.9325 - val_loss: 5.6555 - val_mae: 5.6555\n",
            "Epoch 1245/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9502 - mae: 11.9502 - val_loss: 5.6823 - val_mae: 5.6823\n",
            "Epoch 1246/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9349 - mae: 11.9349 - val_loss: 5.6381 - val_mae: 5.6381\n",
            "Epoch 1247/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9385 - mae: 11.9385 - val_loss: 5.6238 - val_mae: 5.6238\n",
            "Epoch 1248/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9364 - mae: 11.9364 - val_loss: 5.6265 - val_mae: 5.6265\n",
            "Epoch 1249/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9274 - mae: 11.9274 - val_loss: 5.6405 - val_mae: 5.6405\n",
            "Epoch 1250/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9267 - mae: 11.9267 - val_loss: 5.6239 - val_mae: 5.6239\n",
            "Epoch 1251/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9190 - mae: 11.9190 - val_loss: 5.6451 - val_mae: 5.6451\n",
            "Epoch 1252/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9252 - mae: 11.9252 - val_loss: 5.6240 - val_mae: 5.6240\n",
            "Epoch 1253/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9160 - mae: 11.9160 - val_loss: 5.6368 - val_mae: 5.6368\n",
            "Epoch 1254/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9235 - mae: 11.9235 - val_loss: 5.6278 - val_mae: 5.6278\n",
            "Epoch 1255/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9199 - mae: 11.9199 - val_loss: 5.6221 - val_mae: 5.6221\n",
            "Epoch 1256/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9201 - mae: 11.9201 - val_loss: 5.6207 - val_mae: 5.6207\n",
            "Epoch 1257/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9189 - mae: 11.9189 - val_loss: 5.6197 - val_mae: 5.6197\n",
            "Epoch 1258/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9484 - mae: 11.9484 - val_loss: 5.6782 - val_mae: 5.6782\n",
            "Epoch 1259/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9317 - mae: 11.9317 - val_loss: 5.6399 - val_mae: 5.6399\n",
            "Epoch 1260/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9335 - mae: 11.9335 - val_loss: 5.6492 - val_mae: 5.6492\n",
            "Epoch 1261/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9258 - mae: 11.9258 - val_loss: 5.6321 - val_mae: 5.6321\n",
            "Epoch 1262/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9657 - mae: 11.9657 - val_loss: 5.6197 - val_mae: 5.6197\n",
            "Epoch 1263/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9405 - mae: 11.9405 - val_loss: 5.6952 - val_mae: 5.6952\n",
            "Epoch 1264/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9354 - mae: 11.9354 - val_loss: 5.6320 - val_mae: 5.6320\n",
            "Epoch 1265/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9325 - mae: 11.9325 - val_loss: 5.6382 - val_mae: 5.6382\n",
            "Epoch 1266/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9190 - mae: 11.9190 - val_loss: 5.6387 - val_mae: 5.6387\n",
            "Epoch 1267/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9215 - mae: 11.9215 - val_loss: 5.6567 - val_mae: 5.6567\n",
            "Epoch 1268/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9275 - mae: 11.9275 - val_loss: 5.6463 - val_mae: 5.6463\n",
            "Epoch 1269/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9257 - mae: 11.9257 - val_loss: 5.6431 - val_mae: 5.6431\n",
            "Epoch 1270/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9172 - mae: 11.9172 - val_loss: 5.6154 - val_mae: 5.6154\n",
            "Epoch 1271/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9318 - mae: 11.9318 - val_loss: 5.6320 - val_mae: 5.6320\n",
            "Epoch 1272/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9344 - mae: 11.9344 - val_loss: 5.6453 - val_mae: 5.6453\n",
            "Epoch 1273/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9278 - mae: 11.9278 - val_loss: 5.6348 - val_mae: 5.6348\n",
            "Epoch 1274/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9171 - mae: 11.9171 - val_loss: 5.6217 - val_mae: 5.6217\n",
            "Epoch 1275/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9311 - mae: 11.9311 - val_loss: 5.6507 - val_mae: 5.6507\n",
            "Epoch 1276/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9269 - mae: 11.9269 - val_loss: 5.6219 - val_mae: 5.6219\n",
            "Epoch 1277/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9225 - mae: 11.9225 - val_loss: 5.6396 - val_mae: 5.6396\n",
            "Epoch 1278/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9255 - mae: 11.9255 - val_loss: 5.6282 - val_mae: 5.6282\n",
            "Epoch 1279/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9148 - mae: 11.9148 - val_loss: 5.6362 - val_mae: 5.6362\n",
            "Epoch 1280/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9186 - mae: 11.9186 - val_loss: 5.6209 - val_mae: 5.6209\n",
            "Epoch 1281/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9382 - mae: 11.9382 - val_loss: 5.6219 - val_mae: 5.6219\n",
            "Epoch 1282/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9230 - mae: 11.9230 - val_loss: 5.6351 - val_mae: 5.6351\n",
            "Epoch 1283/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9150 - mae: 11.9150 - val_loss: 5.6207 - val_mae: 5.6207\n",
            "Epoch 1284/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9180 - mae: 11.9180 - val_loss: 5.6373 - val_mae: 5.6373\n",
            "Epoch 1285/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9269 - mae: 11.9269 - val_loss: 5.6183 - val_mae: 5.6183\n",
            "Epoch 1286/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9216 - mae: 11.9216 - val_loss: 5.6154 - val_mae: 5.6154\n",
            "Epoch 1287/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9178 - mae: 11.9178 - val_loss: 5.6255 - val_mae: 5.6255\n",
            "Epoch 1288/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9390 - mae: 11.9390 - val_loss: 5.6295 - val_mae: 5.6295\n",
            "Epoch 1289/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9263 - mae: 11.9263 - val_loss: 5.6319 - val_mae: 5.6319\n",
            "Epoch 1290/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9187 - mae: 11.9187 - val_loss: 5.6116 - val_mae: 5.6116\n",
            "Epoch 1291/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9242 - mae: 11.9242 - val_loss: 5.6419 - val_mae: 5.6419\n",
            "Epoch 1292/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9191 - mae: 11.9191 - val_loss: 5.6219 - val_mae: 5.6219\n",
            "Epoch 1293/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9112 - mae: 11.9112 - val_loss: 5.6121 - val_mae: 5.6121\n",
            "Epoch 1294/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9093 - mae: 11.9093 - val_loss: 5.6113 - val_mae: 5.6113\n",
            "Epoch 1295/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9106 - mae: 11.9106 - val_loss: 5.6048 - val_mae: 5.6048\n",
            "Epoch 1296/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9086 - mae: 11.9086 - val_loss: 5.6081 - val_mae: 5.6081\n",
            "Epoch 1297/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9106 - mae: 11.9106 - val_loss: 5.6208 - val_mae: 5.6208\n",
            "Epoch 1298/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9252 - mae: 11.9252 - val_loss: 5.6405 - val_mae: 5.6405\n",
            "Epoch 1299/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9175 - mae: 11.9175 - val_loss: 5.6147 - val_mae: 5.6147\n",
            "Epoch 1300/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9297 - mae: 11.9297 - val_loss: 5.6079 - val_mae: 5.6079\n",
            "Epoch 1301/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9217 - mae: 11.9217 - val_loss: 5.6292 - val_mae: 5.6292\n",
            "Epoch 1302/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9210 - mae: 11.9210 - val_loss: 5.6156 - val_mae: 5.6156\n",
            "Epoch 1303/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9156 - mae: 11.9156 - val_loss: 5.6283 - val_mae: 5.6283\n",
            "Epoch 1304/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9123 - mae: 11.9123 - val_loss: 5.6568 - val_mae: 5.6568\n",
            "Epoch 1305/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9245 - mae: 11.9245 - val_loss: 5.6156 - val_mae: 5.6156\n",
            "Epoch 1306/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9123 - mae: 11.9123 - val_loss: 5.6126 - val_mae: 5.6126\n",
            "Epoch 1307/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9330 - mae: 11.9330 - val_loss: 5.6558 - val_mae: 5.6558\n",
            "Epoch 1308/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9152 - mae: 11.9152 - val_loss: 5.6352 - val_mae: 5.6352\n",
            "Epoch 1309/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9313 - mae: 11.9313 - val_loss: 5.6171 - val_mae: 5.6171\n",
            "Epoch 1310/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9120 - mae: 11.9120 - val_loss: 5.6041 - val_mae: 5.6041\n",
            "Epoch 1311/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9030 - mae: 11.9030 - val_loss: 5.6123 - val_mae: 5.6123\n",
            "Epoch 1312/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9147 - mae: 11.9147 - val_loss: 5.6128 - val_mae: 5.6128\n",
            "Epoch 1313/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9117 - mae: 11.9117 - val_loss: 5.6042 - val_mae: 5.6042\n",
            "Epoch 1314/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.9070 - mae: 11.9070 - val_loss: 5.6281 - val_mae: 5.6281\n",
            "Epoch 1315/2000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11.9175 - mae: 11.9175 - val_loss: 5.6112 - val_mae: 5.6112\n",
            "Epoch 1316/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9117 - mae: 11.9117 - val_loss: 5.6195 - val_mae: 5.6195\n",
            "Epoch 1317/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9154 - mae: 11.9154 - val_loss: 5.6292 - val_mae: 5.6292\n",
            "Epoch 1318/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9116 - mae: 11.9116 - val_loss: 5.6078 - val_mae: 5.6078\n",
            "Epoch 1319/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9299 - mae: 11.9299 - val_loss: 5.6496 - val_mae: 5.6496\n",
            "Epoch 1320/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9436 - mae: 11.9436 - val_loss: 5.6418 - val_mae: 5.6418\n",
            "Epoch 1321/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9290 - mae: 11.9290 - val_loss: 5.6329 - val_mae: 5.6329\n",
            "Epoch 1322/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9240 - mae: 11.9240 - val_loss: 5.6635 - val_mae: 5.6635\n",
            "Epoch 1323/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9286 - mae: 11.9286 - val_loss: 5.6155 - val_mae: 5.6155\n",
            "Epoch 1324/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9145 - mae: 11.9145 - val_loss: 5.6157 - val_mae: 5.6157\n",
            "Epoch 1325/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9168 - mae: 11.9168 - val_loss: 5.6288 - val_mae: 5.6288\n",
            "Epoch 1326/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9068 - mae: 11.9068 - val_loss: 5.6150 - val_mae: 5.6150\n",
            "Epoch 1327/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9108 - mae: 11.9108 - val_loss: 5.6052 - val_mae: 5.6052\n",
            "Epoch 1328/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9146 - mae: 11.9146 - val_loss: 5.6034 - val_mae: 5.6034\n",
            "Epoch 1329/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9019 - mae: 11.9019 - val_loss: 5.6065 - val_mae: 5.6065\n",
            "Epoch 1330/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9025 - mae: 11.9025 - val_loss: 5.6055 - val_mae: 5.6055\n",
            "Epoch 1331/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9121 - mae: 11.9121 - val_loss: 5.6097 - val_mae: 5.6097\n",
            "Epoch 1332/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9068 - mae: 11.9068 - val_loss: 5.6103 - val_mae: 5.6103\n",
            "Epoch 1333/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9107 - mae: 11.9107 - val_loss: 5.6034 - val_mae: 5.6034\n",
            "Epoch 1334/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9126 - mae: 11.9126 - val_loss: 5.6073 - val_mae: 5.6073\n",
            "Epoch 1335/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9084 - mae: 11.9084 - val_loss: 5.6259 - val_mae: 5.6259\n",
            "Epoch 1336/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9176 - mae: 11.9176 - val_loss: 5.6225 - val_mae: 5.6225\n",
            "Epoch 1337/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9115 - mae: 11.9115 - val_loss: 5.6194 - val_mae: 5.6194\n",
            "Epoch 1338/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9196 - mae: 11.9196 - val_loss: 5.6109 - val_mae: 5.6109\n",
            "Epoch 1339/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9141 - mae: 11.9141 - val_loss: 5.6273 - val_mae: 5.6273\n",
            "Epoch 1340/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9233 - mae: 11.9233 - val_loss: 5.6264 - val_mae: 5.6264\n",
            "Epoch 1341/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9075 - mae: 11.9075 - val_loss: 5.6185 - val_mae: 5.6185\n",
            "Epoch 1342/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9134 - mae: 11.9134 - val_loss: 5.6222 - val_mae: 5.6222\n",
            "Epoch 1343/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9317 - mae: 11.9317 - val_loss: 5.6651 - val_mae: 5.6651\n",
            "Epoch 1344/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9179 - mae: 11.9179 - val_loss: 5.6182 - val_mae: 5.6182\n",
            "Epoch 1345/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9155 - mae: 11.9155 - val_loss: 5.5979 - val_mae: 5.5979\n",
            "Epoch 1346/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9098 - mae: 11.9098 - val_loss: 5.6091 - val_mae: 5.6091\n",
            "Epoch 1347/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9119 - mae: 11.9119 - val_loss: 5.6186 - val_mae: 5.6186\n",
            "Epoch 1348/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9063 - mae: 11.9063 - val_loss: 5.6143 - val_mae: 5.6143\n",
            "Epoch 1349/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9108 - mae: 11.9108 - val_loss: 5.6379 - val_mae: 5.6379\n",
            "Epoch 1350/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9169 - mae: 11.9169 - val_loss: 5.6055 - val_mae: 5.6055\n",
            "Epoch 1351/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9124 - mae: 11.9124 - val_loss: 5.6009 - val_mae: 5.6009\n",
            "Epoch 1352/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9102 - mae: 11.9102 - val_loss: 5.6254 - val_mae: 5.6254\n",
            "Epoch 1353/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9045 - mae: 11.9045 - val_loss: 5.6032 - val_mae: 5.6032\n",
            "Epoch 1354/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9070 - mae: 11.9070 - val_loss: 5.6037 - val_mae: 5.6037\n",
            "Epoch 1355/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8982 - mae: 11.8982 - val_loss: 5.6060 - val_mae: 5.6060\n",
            "Epoch 1356/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9036 - mae: 11.9036 - val_loss: 5.6064 - val_mae: 5.6064\n",
            "Epoch 1357/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8986 - mae: 11.8986 - val_loss: 5.6127 - val_mae: 5.6127\n",
            "Epoch 1358/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9063 - mae: 11.9063 - val_loss: 5.6060 - val_mae: 5.6060\n",
            "Epoch 1359/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8991 - mae: 11.8991 - val_loss: 5.6163 - val_mae: 5.6163\n",
            "Epoch 1360/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9026 - mae: 11.9026 - val_loss: 5.6006 - val_mae: 5.6006\n",
            "Epoch 1361/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9067 - mae: 11.9067 - val_loss: 5.5962 - val_mae: 5.5962\n",
            "Epoch 1362/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8947 - mae: 11.8947 - val_loss: 5.6257 - val_mae: 5.6257\n",
            "Epoch 1363/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9226 - mae: 11.9226 - val_loss: 5.6236 - val_mae: 5.6236\n",
            "Epoch 1364/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9185 - mae: 11.9185 - val_loss: 5.6256 - val_mae: 5.6256\n",
            "Epoch 1365/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9135 - mae: 11.9135 - val_loss: 5.6366 - val_mae: 5.6366\n",
            "Epoch 1366/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9183 - mae: 11.9183 - val_loss: 5.6347 - val_mae: 5.6347\n",
            "Epoch 1367/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9204 - mae: 11.9204 - val_loss: 5.6318 - val_mae: 5.6318\n",
            "Epoch 1368/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9155 - mae: 11.9155 - val_loss: 5.6384 - val_mae: 5.6384\n",
            "Epoch 1369/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9167 - mae: 11.9167 - val_loss: 5.6320 - val_mae: 5.6320\n",
            "Epoch 1370/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9114 - mae: 11.9114 - val_loss: 5.6019 - val_mae: 5.6019\n",
            "Epoch 1371/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8993 - mae: 11.8993 - val_loss: 5.6087 - val_mae: 5.6087\n",
            "Epoch 1372/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8985 - mae: 11.8985 - val_loss: 5.6251 - val_mae: 5.6251\n",
            "Epoch 1373/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9260 - mae: 11.9260 - val_loss: 5.6286 - val_mae: 5.6286\n",
            "Epoch 1374/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9118 - mae: 11.9118 - val_loss: 5.5963 - val_mae: 5.5963\n",
            "Epoch 1375/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9150 - mae: 11.9150 - val_loss: 5.6169 - val_mae: 5.6169\n",
            "Epoch 1376/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9188 - mae: 11.9188 - val_loss: 5.6260 - val_mae: 5.6260\n",
            "Epoch 1377/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.9086 - mae: 11.9086 - val_loss: 5.6065 - val_mae: 5.6065\n",
            "Epoch 1378/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9052 - mae: 11.9052 - val_loss: 5.6282 - val_mae: 5.6282\n",
            "Epoch 1379/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9069 - mae: 11.9069 - val_loss: 5.6025 - val_mae: 5.6025\n",
            "Epoch 1380/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9112 - mae: 11.9112 - val_loss: 5.6185 - val_mae: 5.6185\n",
            "Epoch 1381/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9337 - mae: 11.9337 - val_loss: 5.6168 - val_mae: 5.6168\n",
            "Epoch 1382/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9172 - mae: 11.9172 - val_loss: 5.6376 - val_mae: 5.6376\n",
            "Epoch 1383/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9189 - mae: 11.9189 - val_loss: 5.5975 - val_mae: 5.5975\n",
            "Epoch 1384/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9009 - mae: 11.9009 - val_loss: 5.6188 - val_mae: 5.6188\n",
            "Epoch 1385/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9117 - mae: 11.9117 - val_loss: 5.6013 - val_mae: 5.6013\n",
            "Epoch 1386/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9129 - mae: 11.9129 - val_loss: 5.5998 - val_mae: 5.5998\n",
            "Epoch 1387/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9068 - mae: 11.9068 - val_loss: 5.6149 - val_mae: 5.6149\n",
            "Epoch 1388/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9126 - mae: 11.9126 - val_loss: 5.6048 - val_mae: 5.6048\n",
            "Epoch 1389/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9060 - mae: 11.9060 - val_loss: 5.6079 - val_mae: 5.6079\n",
            "Epoch 1390/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9139 - mae: 11.9139 - val_loss: 5.6294 - val_mae: 5.6294\n",
            "Epoch 1391/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9084 - mae: 11.9084 - val_loss: 5.6406 - val_mae: 5.6406\n",
            "Epoch 1392/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9286 - mae: 11.9286 - val_loss: 5.6479 - val_mae: 5.6479\n",
            "Epoch 1393/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9100 - mae: 11.9100 - val_loss: 5.6197 - val_mae: 5.6197\n",
            "Epoch 1394/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9107 - mae: 11.9107 - val_loss: 5.6266 - val_mae: 5.6266\n",
            "Epoch 1395/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9174 - mae: 11.9174 - val_loss: 5.6407 - val_mae: 5.6407\n",
            "Epoch 1396/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9060 - mae: 11.9060 - val_loss: 5.5912 - val_mae: 5.5912\n",
            "Epoch 1397/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9027 - mae: 11.9027 - val_loss: 5.5897 - val_mae: 5.5897\n",
            "Epoch 1398/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9159 - mae: 11.9159 - val_loss: 5.5973 - val_mae: 5.5973\n",
            "Epoch 1399/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9046 - mae: 11.9046 - val_loss: 5.6074 - val_mae: 5.6074\n",
            "Epoch 1400/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8987 - mae: 11.8987 - val_loss: 5.6061 - val_mae: 5.6061\n",
            "Epoch 1401/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9103 - mae: 11.9103 - val_loss: 5.5947 - val_mae: 5.5947\n",
            "Epoch 1402/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8997 - mae: 11.8997 - val_loss: 5.5911 - val_mae: 5.5911\n",
            "Epoch 1403/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9000 - mae: 11.9000 - val_loss: 5.6049 - val_mae: 5.6049\n",
            "Epoch 1404/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9034 - mae: 11.9034 - val_loss: 5.6035 - val_mae: 5.6035\n",
            "Epoch 1405/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9034 - mae: 11.9034 - val_loss: 5.6061 - val_mae: 5.6061\n",
            "Epoch 1406/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9094 - mae: 11.9094 - val_loss: 5.6142 - val_mae: 5.6142\n",
            "Epoch 1407/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9100 - mae: 11.9100 - val_loss: 5.6297 - val_mae: 5.6297\n",
            "Epoch 1408/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9181 - mae: 11.9181 - val_loss: 5.6176 - val_mae: 5.6176\n",
            "Epoch 1409/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9088 - mae: 11.9088 - val_loss: 5.6696 - val_mae: 5.6696\n",
            "Epoch 1410/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9300 - mae: 11.9300 - val_loss: 5.5922 - val_mae: 5.5922\n",
            "Epoch 1411/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9094 - mae: 11.9094 - val_loss: 5.6037 - val_mae: 5.6037\n",
            "Epoch 1412/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9181 - mae: 11.9181 - val_loss: 5.6120 - val_mae: 5.6120\n",
            "Epoch 1413/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9041 - mae: 11.9041 - val_loss: 5.6035 - val_mae: 5.6035\n",
            "Epoch 1414/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.9062 - mae: 11.9062 - val_loss: 5.6142 - val_mae: 5.6142\n",
            "Epoch 1415/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9074 - mae: 11.9074 - val_loss: 5.6029 - val_mae: 5.6029\n",
            "Epoch 1416/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8937 - mae: 11.8937 - val_loss: 5.5986 - val_mae: 5.5986\n",
            "Epoch 1417/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9044 - mae: 11.9044 - val_loss: 5.5920 - val_mae: 5.5920\n",
            "Epoch 1418/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9065 - mae: 11.9065 - val_loss: 5.6279 - val_mae: 5.6279\n",
            "Epoch 1419/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9050 - mae: 11.9050 - val_loss: 5.5982 - val_mae: 5.5982\n",
            "Epoch 1420/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8993 - mae: 11.8993 - val_loss: 5.6028 - val_mae: 5.6028\n",
            "Epoch 1421/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8950 - mae: 11.8950 - val_loss: 5.5982 - val_mae: 5.5982\n",
            "Epoch 1422/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8975 - mae: 11.8975 - val_loss: 5.5858 - val_mae: 5.5858\n",
            "Epoch 1423/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8905 - mae: 11.8905 - val_loss: 5.5889 - val_mae: 5.5889\n",
            "Epoch 1424/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8904 - mae: 11.8904 - val_loss: 5.5974 - val_mae: 5.5974\n",
            "Epoch 1425/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9037 - mae: 11.9037 - val_loss: 5.5825 - val_mae: 5.5825\n",
            "Epoch 1426/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9208 - mae: 11.9208 - val_loss: 5.6169 - val_mae: 5.6169\n",
            "Epoch 1427/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9116 - mae: 11.9116 - val_loss: 5.6002 - val_mae: 5.6002\n",
            "Epoch 1428/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9085 - mae: 11.9085 - val_loss: 5.6326 - val_mae: 5.6326\n",
            "Epoch 1429/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9131 - mae: 11.9131 - val_loss: 5.6589 - val_mae: 5.6589\n",
            "Epoch 1430/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9175 - mae: 11.9175 - val_loss: 5.6490 - val_mae: 5.6490\n",
            "Epoch 1431/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9191 - mae: 11.9191 - val_loss: 5.6069 - val_mae: 5.6069\n",
            "Epoch 1432/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9040 - mae: 11.9040 - val_loss: 5.6120 - val_mae: 5.6120\n",
            "Epoch 1433/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9024 - mae: 11.9024 - val_loss: 5.6022 - val_mae: 5.6022\n",
            "Epoch 1434/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8904 - mae: 11.8904 - val_loss: 5.5910 - val_mae: 5.5910\n",
            "Epoch 1435/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9151 - mae: 11.9151 - val_loss: 5.6378 - val_mae: 5.6378\n",
            "Epoch 1436/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9096 - mae: 11.9096 - val_loss: 5.6142 - val_mae: 5.6142\n",
            "Epoch 1437/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8978 - mae: 11.8978 - val_loss: 5.5930 - val_mae: 5.5930\n",
            "Epoch 1438/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9045 - mae: 11.9045 - val_loss: 5.5892 - val_mae: 5.5892\n",
            "Epoch 1439/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8952 - mae: 11.8952 - val_loss: 5.5822 - val_mae: 5.5822\n",
            "Epoch 1440/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8894 - mae: 11.8894 - val_loss: 5.5823 - val_mae: 5.5823\n",
            "Epoch 1441/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8932 - mae: 11.8932 - val_loss: 5.6031 - val_mae: 5.6031\n",
            "Epoch 1442/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8977 - mae: 11.8977 - val_loss: 5.5868 - val_mae: 5.5868\n",
            "Epoch 1443/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8896 - mae: 11.8896 - val_loss: 5.5854 - val_mae: 5.5854\n",
            "Epoch 1444/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8949 - mae: 11.8949 - val_loss: 5.5989 - val_mae: 5.5989\n",
            "Epoch 1445/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8988 - mae: 11.8988 - val_loss: 5.5864 - val_mae: 5.5864\n",
            "Epoch 1446/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9071 - mae: 11.9071 - val_loss: 5.5903 - val_mae: 5.5903\n",
            "Epoch 1447/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8970 - mae: 11.8970 - val_loss: 5.5941 - val_mae: 5.5941\n",
            "Epoch 1448/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8917 - mae: 11.8917 - val_loss: 5.6013 - val_mae: 5.6013\n",
            "Epoch 1449/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9037 - mae: 11.9037 - val_loss: 5.6009 - val_mae: 5.6009\n",
            "Epoch 1450/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8908 - mae: 11.8908 - val_loss: 5.6090 - val_mae: 5.6090\n",
            "Epoch 1451/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8980 - mae: 11.8980 - val_loss: 5.6007 - val_mae: 5.6007\n",
            "Epoch 1452/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8998 - mae: 11.8998 - val_loss: 5.6141 - val_mae: 5.6141\n",
            "Epoch 1453/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8991 - mae: 11.8991 - val_loss: 5.5976 - val_mae: 5.5976\n",
            "Epoch 1454/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8947 - mae: 11.8947 - val_loss: 5.5864 - val_mae: 5.5864\n",
            "Epoch 1455/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9165 - mae: 11.9165 - val_loss: 5.5953 - val_mae: 5.5953\n",
            "Epoch 1456/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8948 - mae: 11.8948 - val_loss: 5.6370 - val_mae: 5.6370\n",
            "Epoch 1457/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9173 - mae: 11.9173 - val_loss: 5.6028 - val_mae: 5.6028\n",
            "Epoch 1458/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9096 - mae: 11.9096 - val_loss: 5.6044 - val_mae: 5.6044\n",
            "Epoch 1459/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9059 - mae: 11.9059 - val_loss: 5.5925 - val_mae: 5.5925\n",
            "Epoch 1460/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9084 - mae: 11.9084 - val_loss: 5.6223 - val_mae: 5.6223\n",
            "Epoch 1461/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8955 - mae: 11.8955 - val_loss: 5.5930 - val_mae: 5.5930\n",
            "Epoch 1462/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8922 - mae: 11.8922 - val_loss: 5.6006 - val_mae: 5.6006\n",
            "Epoch 1463/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9075 - mae: 11.9075 - val_loss: 5.6176 - val_mae: 5.6176\n",
            "Epoch 1464/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9014 - mae: 11.9014 - val_loss: 5.6268 - val_mae: 5.6268\n",
            "Epoch 1465/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9079 - mae: 11.9079 - val_loss: 5.5879 - val_mae: 5.5879\n",
            "Epoch 1466/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8876 - mae: 11.8876 - val_loss: 5.5950 - val_mae: 5.5950\n",
            "Epoch 1467/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8909 - mae: 11.8909 - val_loss: 5.5834 - val_mae: 5.5834\n",
            "Epoch 1468/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8863 - mae: 11.8863 - val_loss: 5.5850 - val_mae: 5.5850\n",
            "Epoch 1469/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8869 - mae: 11.8869 - val_loss: 5.5941 - val_mae: 5.5941\n",
            "Epoch 1470/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8934 - mae: 11.8934 - val_loss: 5.5888 - val_mae: 5.5888\n",
            "Epoch 1471/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8992 - mae: 11.8992 - val_loss: 5.5964 - val_mae: 5.5964\n",
            "Epoch 1472/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8907 - mae: 11.8907 - val_loss: 5.5854 - val_mae: 5.5854\n",
            "Epoch 1473/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8924 - mae: 11.8924 - val_loss: 5.5762 - val_mae: 5.5762\n",
            "Epoch 1474/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8916 - mae: 11.8916 - val_loss: 5.5765 - val_mae: 5.5765\n",
            "Epoch 1475/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8996 - mae: 11.8996 - val_loss: 5.5998 - val_mae: 5.5998\n",
            "Epoch 1476/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9192 - mae: 11.9192 - val_loss: 5.6076 - val_mae: 5.6076\n",
            "Epoch 1477/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9527 - mae: 11.9527 - val_loss: 5.6056 - val_mae: 5.6056\n",
            "Epoch 1478/2000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11.9291 - mae: 11.9291 - val_loss: 5.6379 - val_mae: 5.6379\n",
            "Epoch 1479/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9421 - mae: 11.9421 - val_loss: 5.6088 - val_mae: 5.6088\n",
            "Epoch 1480/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8975 - mae: 11.8975 - val_loss: 5.5967 - val_mae: 5.5967\n",
            "Epoch 1481/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9113 - mae: 11.9113 - val_loss: 5.6303 - val_mae: 5.6303\n",
            "Epoch 1482/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9033 - mae: 11.9033 - val_loss: 5.6104 - val_mae: 5.6104\n",
            "Epoch 1483/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9013 - mae: 11.9013 - val_loss: 5.5932 - val_mae: 5.5932\n",
            "Epoch 1484/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8932 - mae: 11.8932 - val_loss: 5.6046 - val_mae: 5.6046\n",
            "Epoch 1485/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8983 - mae: 11.8983 - val_loss: 5.5834 - val_mae: 5.5834\n",
            "Epoch 1486/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8913 - mae: 11.8913 - val_loss: 5.5926 - val_mae: 5.5926\n",
            "Epoch 1487/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8882 - mae: 11.8882 - val_loss: 5.5811 - val_mae: 5.5811\n",
            "Epoch 1488/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8930 - mae: 11.8930 - val_loss: 5.5859 - val_mae: 5.5859\n",
            "Epoch 1489/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9119 - mae: 11.9119 - val_loss: 5.5773 - val_mae: 5.5773\n",
            "Epoch 1490/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9051 - mae: 11.9051 - val_loss: 5.5984 - val_mae: 5.5984\n",
            "Epoch 1491/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8858 - mae: 11.8858 - val_loss: 5.5849 - val_mae: 5.5849\n",
            "Epoch 1492/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8902 - mae: 11.8902 - val_loss: 5.5957 - val_mae: 5.5957\n",
            "Epoch 1493/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9001 - mae: 11.9001 - val_loss: 5.5797 - val_mae: 5.5797\n",
            "Epoch 1494/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8872 - mae: 11.8872 - val_loss: 5.5818 - val_mae: 5.5818\n",
            "Epoch 1495/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8933 - mae: 11.8933 - val_loss: 5.6094 - val_mae: 5.6094\n",
            "Epoch 1496/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8952 - mae: 11.8952 - val_loss: 5.5840 - val_mae: 5.5840\n",
            "Epoch 1497/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8811 - mae: 11.8811 - val_loss: 5.5712 - val_mae: 5.5712\n",
            "Epoch 1498/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8847 - mae: 11.8847 - val_loss: 5.5810 - val_mae: 5.5810\n",
            "Epoch 1499/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8972 - mae: 11.8972 - val_loss: 5.5692 - val_mae: 5.5692\n",
            "Epoch 1500/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8847 - mae: 11.8847 - val_loss: 5.5960 - val_mae: 5.5960\n",
            "Epoch 1501/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8859 - mae: 11.8859 - val_loss: 5.5913 - val_mae: 5.5913\n",
            "Epoch 1502/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8939 - mae: 11.8939 - val_loss: 5.5998 - val_mae: 5.5998\n",
            "Epoch 1503/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8916 - mae: 11.8916 - val_loss: 5.5751 - val_mae: 5.5751\n",
            "Epoch 1504/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8871 - mae: 11.8871 - val_loss: 5.5969 - val_mae: 5.5969\n",
            "Epoch 1505/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8878 - mae: 11.8878 - val_loss: 5.5790 - val_mae: 5.5790\n",
            "Epoch 1506/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8851 - mae: 11.8851 - val_loss: 5.6005 - val_mae: 5.6005\n",
            "Epoch 1507/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8895 - mae: 11.8895 - val_loss: 5.5998 - val_mae: 5.5998\n",
            "Epoch 1508/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8934 - mae: 11.8934 - val_loss: 5.5887 - val_mae: 5.5887\n",
            "Epoch 1509/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8930 - mae: 11.8930 - val_loss: 5.5813 - val_mae: 5.5813\n",
            "Epoch 1510/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8851 - mae: 11.8851 - val_loss: 5.6186 - val_mae: 5.6186\n",
            "Epoch 1511/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9013 - mae: 11.9013 - val_loss: 5.6072 - val_mae: 5.6072\n",
            "Epoch 1512/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9054 - mae: 11.9054 - val_loss: 5.5778 - val_mae: 5.5778\n",
            "Epoch 1513/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8936 - mae: 11.8936 - val_loss: 5.5838 - val_mae: 5.5838\n",
            "Epoch 1514/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8932 - mae: 11.8932 - val_loss: 5.5992 - val_mae: 5.5992\n",
            "Epoch 1515/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8940 - mae: 11.8940 - val_loss: 5.6146 - val_mae: 5.6146\n",
            "Epoch 1516/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8909 - mae: 11.8909 - val_loss: 5.5755 - val_mae: 5.5755\n",
            "Epoch 1517/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8907 - mae: 11.8907 - val_loss: 5.5963 - val_mae: 5.5963\n",
            "Epoch 1518/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8957 - mae: 11.8957 - val_loss: 5.6118 - val_mae: 5.6118\n",
            "Epoch 1519/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8891 - mae: 11.8891 - val_loss: 5.6005 - val_mae: 5.6005\n",
            "Epoch 1520/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9042 - mae: 11.9042 - val_loss: 5.6272 - val_mae: 5.6272\n",
            "Epoch 1521/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8922 - mae: 11.8922 - val_loss: 5.5899 - val_mae: 5.5899\n",
            "Epoch 1522/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8914 - mae: 11.8914 - val_loss: 5.5766 - val_mae: 5.5766\n",
            "Epoch 1523/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8885 - mae: 11.8885 - val_loss: 5.6045 - val_mae: 5.6045\n",
            "Epoch 1524/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9122 - mae: 11.9122 - val_loss: 5.6175 - val_mae: 5.6175\n",
            "Epoch 1525/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.9033 - mae: 11.9033 - val_loss: 5.5917 - val_mae: 5.5917\n",
            "Epoch 1526/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8946 - mae: 11.8946 - val_loss: 5.5966 - val_mae: 5.5966\n",
            "Epoch 1527/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8887 - mae: 11.8887 - val_loss: 5.5926 - val_mae: 5.5926\n",
            "Epoch 1528/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8980 - mae: 11.8980 - val_loss: 5.5855 - val_mae: 5.5855\n",
            "Epoch 1529/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8915 - mae: 11.8915 - val_loss: 5.5929 - val_mae: 5.5929\n",
            "Epoch 1530/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8870 - mae: 11.8870 - val_loss: 5.5707 - val_mae: 5.5707\n",
            "Epoch 1531/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8838 - mae: 11.8838 - val_loss: 5.5872 - val_mae: 5.5872\n",
            "Epoch 1532/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8879 - mae: 11.8879 - val_loss: 5.6005 - val_mae: 5.6005\n",
            "Epoch 1533/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8926 - mae: 11.8926 - val_loss: 5.5709 - val_mae: 5.5709\n",
            "Epoch 1534/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8973 - mae: 11.8973 - val_loss: 5.5801 - val_mae: 5.5801\n",
            "Epoch 1535/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8825 - mae: 11.8825 - val_loss: 5.5752 - val_mae: 5.5752\n",
            "Epoch 1536/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8807 - mae: 11.8807 - val_loss: 5.5934 - val_mae: 5.5934\n",
            "Epoch 1537/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8929 - mae: 11.8929 - val_loss: 5.6178 - val_mae: 5.6178\n",
            "Epoch 1538/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8959 - mae: 11.8959 - val_loss: 5.6002 - val_mae: 5.6002\n",
            "Epoch 1539/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9110 - mae: 11.9110 - val_loss: 5.5925 - val_mae: 5.5925\n",
            "Epoch 1540/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8751 - mae: 11.8751 - val_loss: 5.5786 - val_mae: 5.5786\n",
            "Epoch 1541/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9025 - mae: 11.9025 - val_loss: 5.5936 - val_mae: 5.5936\n",
            "Epoch 1542/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9160 - mae: 11.9160 - val_loss: 5.6388 - val_mae: 5.6388\n",
            "Epoch 1543/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9168 - mae: 11.9168 - val_loss: 5.6162 - val_mae: 5.6162\n",
            "Epoch 1544/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9208 - mae: 11.9208 - val_loss: 5.6261 - val_mae: 5.6261\n",
            "Epoch 1545/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8989 - mae: 11.8989 - val_loss: 5.5818 - val_mae: 5.5818\n",
            "Epoch 1546/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8831 - mae: 11.8831 - val_loss: 5.5825 - val_mae: 5.5825\n",
            "Epoch 1547/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8847 - mae: 11.8847 - val_loss: 5.5826 - val_mae: 5.5826\n",
            "Epoch 1548/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8815 - mae: 11.8815 - val_loss: 5.5698 - val_mae: 5.5698\n",
            "Epoch 1549/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8801 - mae: 11.8801 - val_loss: 5.5655 - val_mae: 5.5655\n",
            "Epoch 1550/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8776 - mae: 11.8776 - val_loss: 5.5949 - val_mae: 5.5949\n",
            "Epoch 1551/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8834 - mae: 11.8834 - val_loss: 5.5648 - val_mae: 5.5648\n",
            "Epoch 1552/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8814 - mae: 11.8814 - val_loss: 5.5984 - val_mae: 5.5984\n",
            "Epoch 1553/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8869 - mae: 11.8869 - val_loss: 5.5961 - val_mae: 5.5961\n",
            "Epoch 1554/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8933 - mae: 11.8933 - val_loss: 5.5869 - val_mae: 5.5869\n",
            "Epoch 1555/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.9063 - mae: 11.9063 - val_loss: 5.5968 - val_mae: 5.5968\n",
            "Epoch 1556/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9045 - mae: 11.9045 - val_loss: 5.5904 - val_mae: 5.5904\n",
            "Epoch 1557/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9178 - mae: 11.9178 - val_loss: 5.5972 - val_mae: 5.5972\n",
            "Epoch 1558/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8939 - mae: 11.8939 - val_loss: 5.6065 - val_mae: 5.6065\n",
            "Epoch 1559/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9054 - mae: 11.9054 - val_loss: 5.6134 - val_mae: 5.6134\n",
            "Epoch 1560/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8966 - mae: 11.8966 - val_loss: 5.5979 - val_mae: 5.5979\n",
            "Epoch 1561/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8898 - mae: 11.8898 - val_loss: 5.5992 - val_mae: 5.5992\n",
            "Epoch 1562/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8923 - mae: 11.8923 - val_loss: 5.5754 - val_mae: 5.5754\n",
            "Epoch 1563/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8807 - mae: 11.8807 - val_loss: 5.5803 - val_mae: 5.5803\n",
            "Epoch 1564/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8808 - mae: 11.8808 - val_loss: 5.5868 - val_mae: 5.5868\n",
            "Epoch 1565/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8831 - mae: 11.8831 - val_loss: 5.6044 - val_mae: 5.6044\n",
            "Epoch 1566/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8889 - mae: 11.8889 - val_loss: 5.5765 - val_mae: 5.5765\n",
            "Epoch 1567/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8747 - mae: 11.8747 - val_loss: 5.5642 - val_mae: 5.5642\n",
            "Epoch 1568/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8742 - mae: 11.8742 - val_loss: 5.5803 - val_mae: 5.5803\n",
            "Epoch 1569/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8861 - mae: 11.8861 - val_loss: 5.5867 - val_mae: 5.5867\n",
            "Epoch 1570/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8895 - mae: 11.8895 - val_loss: 5.5743 - val_mae: 5.5743\n",
            "Epoch 1571/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8887 - mae: 11.8887 - val_loss: 5.5938 - val_mae: 5.5938\n",
            "Epoch 1572/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8783 - mae: 11.8783 - val_loss: 5.5777 - val_mae: 5.5777\n",
            "Epoch 1573/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8816 - mae: 11.8816 - val_loss: 5.5759 - val_mae: 5.5759\n",
            "Epoch 1574/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8786 - mae: 11.8786 - val_loss: 5.5792 - val_mae: 5.5792\n",
            "Epoch 1575/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8755 - mae: 11.8755 - val_loss: 5.5704 - val_mae: 5.5704\n",
            "Epoch 1576/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8763 - mae: 11.8763 - val_loss: 5.5721 - val_mae: 5.5721\n",
            "Epoch 1577/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8849 - mae: 11.8849 - val_loss: 5.5802 - val_mae: 5.5802\n",
            "Epoch 1578/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8813 - mae: 11.8813 - val_loss: 5.5602 - val_mae: 5.5602\n",
            "Epoch 1579/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8894 - mae: 11.8894 - val_loss: 5.5919 - val_mae: 5.5919\n",
            "Epoch 1580/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8961 - mae: 11.8961 - val_loss: 5.6072 - val_mae: 5.6072\n",
            "Epoch 1581/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8835 - mae: 11.8835 - val_loss: 5.5751 - val_mae: 5.5751\n",
            "Epoch 1582/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8789 - mae: 11.8789 - val_loss: 5.5866 - val_mae: 5.5866\n",
            "Epoch 1583/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8939 - mae: 11.8939 - val_loss: 5.5797 - val_mae: 5.5797\n",
            "Epoch 1584/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8771 - mae: 11.8771 - val_loss: 5.5912 - val_mae: 5.5912\n",
            "Epoch 1585/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8874 - mae: 11.8874 - val_loss: 5.5892 - val_mae: 5.5892\n",
            "Epoch 1586/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8906 - mae: 11.8906 - val_loss: 5.5798 - val_mae: 5.5798\n",
            "Epoch 1587/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8723 - mae: 11.8723 - val_loss: 5.5759 - val_mae: 5.5759\n",
            "Epoch 1588/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8886 - mae: 11.8886 - val_loss: 5.5647 - val_mae: 5.5647\n",
            "Epoch 1589/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8851 - mae: 11.8851 - val_loss: 5.5863 - val_mae: 5.5863\n",
            "Epoch 1590/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8865 - mae: 11.8865 - val_loss: 5.5897 - val_mae: 5.5897\n",
            "Epoch 1591/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8890 - mae: 11.8890 - val_loss: 5.5902 - val_mae: 5.5902\n",
            "Epoch 1592/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8953 - mae: 11.8953 - val_loss: 5.5742 - val_mae: 5.5742\n",
            "Epoch 1593/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8814 - mae: 11.8814 - val_loss: 5.5678 - val_mae: 5.5678\n",
            "Epoch 1594/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8723 - mae: 11.8723 - val_loss: 5.5585 - val_mae: 5.5585\n",
            "Epoch 1595/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8828 - mae: 11.8828 - val_loss: 5.5673 - val_mae: 5.5673\n",
            "Epoch 1596/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8675 - mae: 11.8675 - val_loss: 5.5715 - val_mae: 5.5715\n",
            "Epoch 1597/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8960 - mae: 11.8960 - val_loss: 5.5872 - val_mae: 5.5872\n",
            "Epoch 1598/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8917 - mae: 11.8917 - val_loss: 5.6026 - val_mae: 5.6026\n",
            "Epoch 1599/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8854 - mae: 11.8854 - val_loss: 5.5962 - val_mae: 5.5962\n",
            "Epoch 1600/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8902 - mae: 11.8902 - val_loss: 5.5886 - val_mae: 5.5886\n",
            "Epoch 1601/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8730 - mae: 11.8730 - val_loss: 5.5658 - val_mae: 5.5658\n",
            "Epoch 1602/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8794 - mae: 11.8794 - val_loss: 5.5752 - val_mae: 5.5752\n",
            "Epoch 1603/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8792 - mae: 11.8792 - val_loss: 5.5691 - val_mae: 5.5691\n",
            "Epoch 1604/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8735 - mae: 11.8735 - val_loss: 5.5827 - val_mae: 5.5827\n",
            "Epoch 1605/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8887 - mae: 11.8887 - val_loss: 5.5612 - val_mae: 5.5612\n",
            "Epoch 1606/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8827 - mae: 11.8827 - val_loss: 5.5996 - val_mae: 5.5996\n",
            "Epoch 1607/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8820 - mae: 11.8820 - val_loss: 5.5620 - val_mae: 5.5620\n",
            "Epoch 1608/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8742 - mae: 11.8742 - val_loss: 5.5578 - val_mae: 5.5578\n",
            "Epoch 1609/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8754 - mae: 11.8754 - val_loss: 5.5891 - val_mae: 5.5891\n",
            "Epoch 1610/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8776 - mae: 11.8776 - val_loss: 5.5599 - val_mae: 5.5599\n",
            "Epoch 1611/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8933 - mae: 11.8933 - val_loss: 5.6033 - val_mae: 5.6033\n",
            "Epoch 1612/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.9164 - mae: 11.9164 - val_loss: 5.6241 - val_mae: 5.6241\n",
            "Epoch 1613/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8955 - mae: 11.8955 - val_loss: 5.5846 - val_mae: 5.5846\n",
            "Epoch 1614/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.9042 - mae: 11.9042 - val_loss: 5.5857 - val_mae: 5.5857\n",
            "Epoch 1615/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8873 - mae: 11.8873 - val_loss: 5.6347 - val_mae: 5.6347\n",
            "Epoch 1616/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8972 - mae: 11.8972 - val_loss: 5.5929 - val_mae: 5.5929\n",
            "Epoch 1617/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8770 - mae: 11.8770 - val_loss: 5.5732 - val_mae: 5.5732\n",
            "Epoch 1618/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8769 - mae: 11.8769 - val_loss: 5.5648 - val_mae: 5.5648\n",
            "Epoch 1619/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8676 - mae: 11.8676 - val_loss: 5.5683 - val_mae: 5.5683\n",
            "Epoch 1620/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8811 - mae: 11.8811 - val_loss: 5.5786 - val_mae: 5.5786\n",
            "Epoch 1621/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8781 - mae: 11.8781 - val_loss: 5.5840 - val_mae: 5.5840\n",
            "Epoch 1622/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8774 - mae: 11.8774 - val_loss: 5.5668 - val_mae: 5.5668\n",
            "Epoch 1623/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8767 - mae: 11.8767 - val_loss: 5.5700 - val_mae: 5.5700\n",
            "Epoch 1624/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8780 - mae: 11.8780 - val_loss: 5.5768 - val_mae: 5.5768\n",
            "Epoch 1625/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8866 - mae: 11.8866 - val_loss: 5.5796 - val_mae: 5.5796\n",
            "Epoch 1626/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8813 - mae: 11.8813 - val_loss: 5.6106 - val_mae: 5.6106\n",
            "Epoch 1627/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8927 - mae: 11.8927 - val_loss: 5.6239 - val_mae: 5.6239\n",
            "Epoch 1628/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8835 - mae: 11.8835 - val_loss: 5.5988 - val_mae: 5.5988\n",
            "Epoch 1629/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8964 - mae: 11.8964 - val_loss: 5.5866 - val_mae: 5.5866\n",
            "Epoch 1630/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8988 - mae: 11.8988 - val_loss: 5.5815 - val_mae: 5.5815\n",
            "Epoch 1631/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8755 - mae: 11.8755 - val_loss: 5.5772 - val_mae: 5.5772\n",
            "Epoch 1632/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8814 - mae: 11.8814 - val_loss: 5.5784 - val_mae: 5.5784\n",
            "Epoch 1633/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8846 - mae: 11.8846 - val_loss: 5.5596 - val_mae: 5.5596\n",
            "Epoch 1634/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8843 - mae: 11.8843 - val_loss: 5.5879 - val_mae: 5.5879\n",
            "Epoch 1635/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8811 - mae: 11.8811 - val_loss: 5.5885 - val_mae: 5.5885\n",
            "Epoch 1636/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8716 - mae: 11.8716 - val_loss: 5.5593 - val_mae: 5.5593\n",
            "Epoch 1637/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8761 - mae: 11.8761 - val_loss: 5.5882 - val_mae: 5.5882\n",
            "Epoch 1638/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.9111 - mae: 11.9111 - val_loss: 5.5711 - val_mae: 5.5711\n",
            "Epoch 1639/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8779 - mae: 11.8779 - val_loss: 5.5717 - val_mae: 5.5717\n",
            "Epoch 1640/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8712 - mae: 11.8712 - val_loss: 5.5576 - val_mae: 5.5576\n",
            "Epoch 1641/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8704 - mae: 11.8704 - val_loss: 5.5707 - val_mae: 5.5707\n",
            "Epoch 1642/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8795 - mae: 11.8795 - val_loss: 5.5758 - val_mae: 5.5758\n",
            "Epoch 1643/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8712 - mae: 11.8712 - val_loss: 5.5812 - val_mae: 5.5812\n",
            "Epoch 1644/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8780 - mae: 11.8780 - val_loss: 5.5506 - val_mae: 5.5506\n",
            "Epoch 1645/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8739 - mae: 11.8739 - val_loss: 5.5507 - val_mae: 5.5507\n",
            "Epoch 1646/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8840 - mae: 11.8840 - val_loss: 5.5685 - val_mae: 5.5685\n",
            "Epoch 1647/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8770 - mae: 11.8770 - val_loss: 5.5581 - val_mae: 5.5581\n",
            "Epoch 1648/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8846 - mae: 11.8846 - val_loss: 5.5748 - val_mae: 5.5748\n",
            "Epoch 1649/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8739 - mae: 11.8739 - val_loss: 5.5937 - val_mae: 5.5937\n",
            "Epoch 1650/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8775 - mae: 11.8775 - val_loss: 5.5650 - val_mae: 5.5650\n",
            "Epoch 1651/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8772 - mae: 11.8772 - val_loss: 5.5661 - val_mae: 5.5661\n",
            "Epoch 1652/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8788 - mae: 11.8788 - val_loss: 5.5678 - val_mae: 5.5678\n",
            "Epoch 1653/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8721 - mae: 11.8721 - val_loss: 5.5581 - val_mae: 5.5581\n",
            "Epoch 1654/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8742 - mae: 11.8742 - val_loss: 5.5701 - val_mae: 5.5701\n",
            "Epoch 1655/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8720 - mae: 11.8720 - val_loss: 5.5800 - val_mae: 5.5800\n",
            "Epoch 1656/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8846 - mae: 11.8846 - val_loss: 5.5772 - val_mae: 5.5772\n",
            "Epoch 1657/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8752 - mae: 11.8752 - val_loss: 5.5558 - val_mae: 5.5558\n",
            "Epoch 1658/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8649 - mae: 11.8649 - val_loss: 5.5642 - val_mae: 5.5642\n",
            "Epoch 1659/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8667 - mae: 11.8667 - val_loss: 5.5552 - val_mae: 5.5552\n",
            "Epoch 1660/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8636 - mae: 11.8636 - val_loss: 5.5497 - val_mae: 5.5497\n",
            "Epoch 1661/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8698 - mae: 11.8698 - val_loss: 5.5525 - val_mae: 5.5525\n",
            "Epoch 1662/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8678 - mae: 11.8678 - val_loss: 5.5645 - val_mae: 5.5645\n",
            "Epoch 1663/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8651 - mae: 11.8651 - val_loss: 5.5522 - val_mae: 5.5522\n",
            "Epoch 1664/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8689 - mae: 11.8689 - val_loss: 5.5666 - val_mae: 5.5666\n",
            "Epoch 1665/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8754 - mae: 11.8754 - val_loss: 5.5728 - val_mae: 5.5728\n",
            "Epoch 1666/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8671 - mae: 11.8671 - val_loss: 5.5696 - val_mae: 5.5696\n",
            "Epoch 1667/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8816 - mae: 11.8816 - val_loss: 5.5735 - val_mae: 5.5735\n",
            "Epoch 1668/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8696 - mae: 11.8696 - val_loss: 5.5490 - val_mae: 5.5490\n",
            "Epoch 1669/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8674 - mae: 11.8674 - val_loss: 5.5654 - val_mae: 5.5654\n",
            "Epoch 1670/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8644 - mae: 11.8644 - val_loss: 5.5485 - val_mae: 5.5485\n",
            "Epoch 1671/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8655 - mae: 11.8655 - val_loss: 5.5765 - val_mae: 5.5765\n",
            "Epoch 1672/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8669 - mae: 11.8669 - val_loss: 5.5492 - val_mae: 5.5492\n",
            "Epoch 1673/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8746 - mae: 11.8746 - val_loss: 5.5882 - val_mae: 5.5882\n",
            "Epoch 1674/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8877 - mae: 11.8877 - val_loss: 5.5733 - val_mae: 5.5733\n",
            "Epoch 1675/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8889 - mae: 11.8889 - val_loss: 5.5831 - val_mae: 5.5831\n",
            "Epoch 1676/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8753 - mae: 11.8753 - val_loss: 5.5725 - val_mae: 5.5725\n",
            "Epoch 1677/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8744 - mae: 11.8744 - val_loss: 5.5628 - val_mae: 5.5628\n",
            "Epoch 1678/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8747 - mae: 11.8747 - val_loss: 5.5693 - val_mae: 5.5693\n",
            "Epoch 1679/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8657 - mae: 11.8657 - val_loss: 5.5634 - val_mae: 5.5634\n",
            "Epoch 1680/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8709 - mae: 11.8709 - val_loss: 5.5645 - val_mae: 5.5645\n",
            "Epoch 1681/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8852 - mae: 11.8852 - val_loss: 5.5515 - val_mae: 5.5515\n",
            "Epoch 1682/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8736 - mae: 11.8736 - val_loss: 5.5659 - val_mae: 5.5659\n",
            "Epoch 1683/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8675 - mae: 11.8675 - val_loss: 5.5634 - val_mae: 5.5634\n",
            "Epoch 1684/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8681 - mae: 11.8681 - val_loss: 5.5606 - val_mae: 5.5606\n",
            "Epoch 1685/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8765 - mae: 11.8765 - val_loss: 5.5665 - val_mae: 5.5665\n",
            "Epoch 1686/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8678 - mae: 11.8678 - val_loss: 5.5565 - val_mae: 5.5565\n",
            "Epoch 1687/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8663 - mae: 11.8663 - val_loss: 5.5478 - val_mae: 5.5478\n",
            "Epoch 1688/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8702 - mae: 11.8702 - val_loss: 5.5875 - val_mae: 5.5875\n",
            "Epoch 1689/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8798 - mae: 11.8798 - val_loss: 5.5608 - val_mae: 5.5608\n",
            "Epoch 1690/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8791 - mae: 11.8791 - val_loss: 5.5689 - val_mae: 5.5689\n",
            "Epoch 1691/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8828 - mae: 11.8828 - val_loss: 5.6027 - val_mae: 5.6027\n",
            "Epoch 1692/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8852 - mae: 11.8852 - val_loss: 5.5561 - val_mae: 5.5561\n",
            "Epoch 1693/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8750 - mae: 11.8750 - val_loss: 5.5584 - val_mae: 5.5584\n",
            "Epoch 1694/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8677 - mae: 11.8677 - val_loss: 5.5614 - val_mae: 5.5614\n",
            "Epoch 1695/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8586 - mae: 11.8586 - val_loss: 5.5656 - val_mae: 5.5656\n",
            "Epoch 1696/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8809 - mae: 11.8809 - val_loss: 5.5671 - val_mae: 5.5671\n",
            "Epoch 1697/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8688 - mae: 11.8688 - val_loss: 5.5512 - val_mae: 5.5512\n",
            "Epoch 1698/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8595 - mae: 11.8595 - val_loss: 5.5505 - val_mae: 5.5505\n",
            "Epoch 1699/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8655 - mae: 11.8655 - val_loss: 5.5496 - val_mae: 5.5496\n",
            "Epoch 1700/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8640 - mae: 11.8640 - val_loss: 5.5509 - val_mae: 5.5509\n",
            "Epoch 1701/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8644 - mae: 11.8644 - val_loss: 5.5558 - val_mae: 5.5558\n",
            "Epoch 1702/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8605 - mae: 11.8605 - val_loss: 5.5603 - val_mae: 5.5603\n",
            "Epoch 1703/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8649 - mae: 11.8649 - val_loss: 5.5564 - val_mae: 5.5564\n",
            "Epoch 1704/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8591 - mae: 11.8591 - val_loss: 5.5541 - val_mae: 5.5541\n",
            "Epoch 1705/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8621 - mae: 11.8621 - val_loss: 5.5538 - val_mae: 5.5538\n",
            "Epoch 1706/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8662 - mae: 11.8662 - val_loss: 5.5591 - val_mae: 5.5591\n",
            "Epoch 1707/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8675 - mae: 11.8675 - val_loss: 5.5471 - val_mae: 5.5471\n",
            "Epoch 1708/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8634 - mae: 11.8634 - val_loss: 5.5559 - val_mae: 5.5559\n",
            "Epoch 1709/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8652 - mae: 11.8652 - val_loss: 5.5539 - val_mae: 5.5539\n",
            "Epoch 1710/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8636 - mae: 11.8636 - val_loss: 5.5512 - val_mae: 5.5512\n",
            "Epoch 1711/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8687 - mae: 11.8687 - val_loss: 5.5595 - val_mae: 5.5595\n",
            "Epoch 1712/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8693 - mae: 11.8693 - val_loss: 5.5590 - val_mae: 5.5590\n",
            "Epoch 1713/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8954 - mae: 11.8954 - val_loss: 5.5740 - val_mae: 5.5740\n",
            "Epoch 1714/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8648 - mae: 11.8648 - val_loss: 5.5908 - val_mae: 5.5908\n",
            "Epoch 1715/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8860 - mae: 11.8860 - val_loss: 5.5598 - val_mae: 5.5598\n",
            "Epoch 1716/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8775 - mae: 11.8775 - val_loss: 5.5673 - val_mae: 5.5673\n",
            "Epoch 1717/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8658 - mae: 11.8658 - val_loss: 5.5871 - val_mae: 5.5871\n",
            "Epoch 1718/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8689 - mae: 11.8689 - val_loss: 5.5374 - val_mae: 5.5374\n",
            "Epoch 1719/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8796 - mae: 11.8796 - val_loss: 5.5613 - val_mae: 5.5613\n",
            "Epoch 1720/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8675 - mae: 11.8675 - val_loss: 5.5551 - val_mae: 5.5551\n",
            "Epoch 1721/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8640 - mae: 11.8640 - val_loss: 5.5426 - val_mae: 5.5426\n",
            "Epoch 1722/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8543 - mae: 11.8543 - val_loss: 5.5635 - val_mae: 5.5635\n",
            "Epoch 1723/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8652 - mae: 11.8652 - val_loss: 5.5451 - val_mae: 5.5451\n",
            "Epoch 1724/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8568 - mae: 11.8568 - val_loss: 5.5662 - val_mae: 5.5662\n",
            "Epoch 1725/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8657 - mae: 11.8657 - val_loss: 5.5437 - val_mae: 5.5437\n",
            "Epoch 1726/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8588 - mae: 11.8588 - val_loss: 5.5778 - val_mae: 5.5778\n",
            "Epoch 1727/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8641 - mae: 11.8641 - val_loss: 5.5647 - val_mae: 5.5647\n",
            "Epoch 1728/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8792 - mae: 11.8792 - val_loss: 5.5445 - val_mae: 5.5445\n",
            "Epoch 1729/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8596 - mae: 11.8596 - val_loss: 5.5858 - val_mae: 5.5858\n",
            "Epoch 1730/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8668 - mae: 11.8668 - val_loss: 5.5492 - val_mae: 5.5492\n",
            "Epoch 1731/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8651 - mae: 11.8651 - val_loss: 5.5515 - val_mae: 5.5515\n",
            "Epoch 1732/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8604 - mae: 11.8604 - val_loss: 5.5724 - val_mae: 5.5724\n",
            "Epoch 1733/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8729 - mae: 11.8729 - val_loss: 5.5725 - val_mae: 5.5725\n",
            "Epoch 1734/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8694 - mae: 11.8694 - val_loss: 5.5409 - val_mae: 5.5409\n",
            "Epoch 1735/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8650 - mae: 11.8650 - val_loss: 5.5631 - val_mae: 5.5631\n",
            "Epoch 1736/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8654 - mae: 11.8654 - val_loss: 5.5453 - val_mae: 5.5453\n",
            "Epoch 1737/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8567 - mae: 11.8567 - val_loss: 5.5539 - val_mae: 5.5539\n",
            "Epoch 1738/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8565 - mae: 11.8565 - val_loss: 5.5409 - val_mae: 5.5409\n",
            "Epoch 1739/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8555 - mae: 11.8555 - val_loss: 5.5491 - val_mae: 5.5491\n",
            "Epoch 1740/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8618 - mae: 11.8618 - val_loss: 5.5681 - val_mae: 5.5681\n",
            "Epoch 1741/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8594 - mae: 11.8594 - val_loss: 5.5444 - val_mae: 5.5444\n",
            "Epoch 1742/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8584 - mae: 11.8584 - val_loss: 5.5436 - val_mae: 5.5436\n",
            "Epoch 1743/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8544 - mae: 11.8544 - val_loss: 5.5463 - val_mae: 5.5463\n",
            "Epoch 1744/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8578 - mae: 11.8578 - val_loss: 5.5521 - val_mae: 5.5521\n",
            "Epoch 1745/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8631 - mae: 11.8631 - val_loss: 5.5496 - val_mae: 5.5496\n",
            "Epoch 1746/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8569 - mae: 11.8569 - val_loss: 5.5572 - val_mae: 5.5572\n",
            "Epoch 1747/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8578 - mae: 11.8578 - val_loss: 5.5472 - val_mae: 5.5472\n",
            "Epoch 1748/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8676 - mae: 11.8676 - val_loss: 5.5394 - val_mae: 5.5394\n",
            "Epoch 1749/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8532 - mae: 11.8532 - val_loss: 5.5413 - val_mae: 5.5413\n",
            "Epoch 1750/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8685 - mae: 11.8685 - val_loss: 5.5698 - val_mae: 5.5698\n",
            "Epoch 1751/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8807 - mae: 11.8807 - val_loss: 5.5757 - val_mae: 5.5757\n",
            "Epoch 1752/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8645 - mae: 11.8645 - val_loss: 5.5902 - val_mae: 5.5902\n",
            "Epoch 1753/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8778 - mae: 11.8778 - val_loss: 5.5704 - val_mae: 5.5704\n",
            "Epoch 1754/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8688 - mae: 11.8688 - val_loss: 5.5630 - val_mae: 5.5630\n",
            "Epoch 1755/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8654 - mae: 11.8654 - val_loss: 5.5611 - val_mae: 5.5611\n",
            "Epoch 1756/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8667 - mae: 11.8667 - val_loss: 5.5505 - val_mae: 5.5505\n",
            "Epoch 1757/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8705 - mae: 11.8705 - val_loss: 5.5446 - val_mae: 5.5446\n",
            "Epoch 1758/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8836 - mae: 11.8836 - val_loss: 5.5477 - val_mae: 5.5477\n",
            "Epoch 1759/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8665 - mae: 11.8665 - val_loss: 5.5714 - val_mae: 5.5714\n",
            "Epoch 1760/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8633 - mae: 11.8633 - val_loss: 5.5348 - val_mae: 5.5348\n",
            "Epoch 1761/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8542 - mae: 11.8542 - val_loss: 5.5409 - val_mae: 5.5409\n",
            "Epoch 1762/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8501 - mae: 11.8501 - val_loss: 5.5635 - val_mae: 5.5635\n",
            "Epoch 1763/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8831 - mae: 11.8831 - val_loss: 5.5502 - val_mae: 5.5502\n",
            "Epoch 1764/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8739 - mae: 11.8739 - val_loss: 5.5518 - val_mae: 5.5518\n",
            "Epoch 1765/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8553 - mae: 11.8553 - val_loss: 5.5654 - val_mae: 5.5654\n",
            "Epoch 1766/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8735 - mae: 11.8735 - val_loss: 5.5621 - val_mae: 5.5621\n",
            "Epoch 1767/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8512 - mae: 11.8512 - val_loss: 5.5387 - val_mae: 5.5387\n",
            "Epoch 1768/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8480 - mae: 11.8480 - val_loss: 5.5639 - val_mae: 5.5639\n",
            "Epoch 1769/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8671 - mae: 11.8671 - val_loss: 5.5640 - val_mae: 5.5640\n",
            "Epoch 1770/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8563 - mae: 11.8563 - val_loss: 5.5373 - val_mae: 5.5373\n",
            "Epoch 1771/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8519 - mae: 11.8519 - val_loss: 5.5622 - val_mae: 5.5622\n",
            "Epoch 1772/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8721 - mae: 11.8721 - val_loss: 5.5492 - val_mae: 5.5492\n",
            "Epoch 1773/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8754 - mae: 11.8754 - val_loss: 5.5501 - val_mae: 5.5501\n",
            "Epoch 1774/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8574 - mae: 11.8574 - val_loss: 5.5535 - val_mae: 5.5535\n",
            "Epoch 1775/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8657 - mae: 11.8657 - val_loss: 5.5555 - val_mae: 5.5555\n",
            "Epoch 1776/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8441 - mae: 11.8441 - val_loss: 5.5495 - val_mae: 5.5495\n",
            "Epoch 1777/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8625 - mae: 11.8625 - val_loss: 5.5366 - val_mae: 5.5366\n",
            "Epoch 1778/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8551 - mae: 11.8551 - val_loss: 5.5472 - val_mae: 5.5472\n",
            "Epoch 1779/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8437 - mae: 11.8437 - val_loss: 5.5408 - val_mae: 5.5408\n",
            "Epoch 1780/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8638 - mae: 11.8638 - val_loss: 5.5596 - val_mae: 5.5596\n",
            "Epoch 1781/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8676 - mae: 11.8676 - val_loss: 5.5434 - val_mae: 5.5434\n",
            "Epoch 1782/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8745 - mae: 11.8745 - val_loss: 5.5436 - val_mae: 5.5436\n",
            "Epoch 1783/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8487 - mae: 11.8487 - val_loss: 5.5825 - val_mae: 5.5825\n",
            "Epoch 1784/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8713 - mae: 11.8713 - val_loss: 5.5522 - val_mae: 5.5522\n",
            "Epoch 1785/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8752 - mae: 11.8752 - val_loss: 5.5623 - val_mae: 5.5623\n",
            "Epoch 1786/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8682 - mae: 11.8682 - val_loss: 5.5494 - val_mae: 5.5494\n",
            "Epoch 1787/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8637 - mae: 11.8637 - val_loss: 5.5515 - val_mae: 5.5515\n",
            "Epoch 1788/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8606 - mae: 11.8606 - val_loss: 5.5457 - val_mae: 5.5457\n",
            "Epoch 1789/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8626 - mae: 11.8626 - val_loss: 5.5370 - val_mae: 5.5370\n",
            "Epoch 1790/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8631 - mae: 11.8631 - val_loss: 5.5493 - val_mae: 5.5493\n",
            "Epoch 1791/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8595 - mae: 11.8595 - val_loss: 5.5761 - val_mae: 5.5761\n",
            "Epoch 1792/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8781 - mae: 11.8781 - val_loss: 5.5500 - val_mae: 5.5500\n",
            "Epoch 1793/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8782 - mae: 11.8782 - val_loss: 5.5685 - val_mae: 5.5685\n",
            "Epoch 1794/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8550 - mae: 11.8550 - val_loss: 5.5471 - val_mae: 5.5471\n",
            "Epoch 1795/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8617 - mae: 11.8617 - val_loss: 5.5382 - val_mae: 5.5382\n",
            "Epoch 1796/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8546 - mae: 11.8546 - val_loss: 5.5362 - val_mae: 5.5362\n",
            "Epoch 1797/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8499 - mae: 11.8499 - val_loss: 5.5443 - val_mae: 5.5443\n",
            "Epoch 1798/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8721 - mae: 11.8721 - val_loss: 5.5672 - val_mae: 5.5672\n",
            "Epoch 1799/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8604 - mae: 11.8604 - val_loss: 5.5668 - val_mae: 5.5668\n",
            "Epoch 1800/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8732 - mae: 11.8732 - val_loss: 5.5875 - val_mae: 5.5875\n",
            "Epoch 1801/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8638 - mae: 11.8638 - val_loss: 5.5611 - val_mae: 5.5611\n",
            "Epoch 1802/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8610 - mae: 11.8610 - val_loss: 5.5571 - val_mae: 5.5571\n",
            "Epoch 1803/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8691 - mae: 11.8691 - val_loss: 5.5390 - val_mae: 5.5390\n",
            "Epoch 1804/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8838 - mae: 11.8838 - val_loss: 5.5571 - val_mae: 5.5571\n",
            "Epoch 1805/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.9199 - mae: 11.9199 - val_loss: 5.5932 - val_mae: 5.5932\n",
            "Epoch 1806/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8914 - mae: 11.8914 - val_loss: 5.5385 - val_mae: 5.5385\n",
            "Epoch 1807/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8699 - mae: 11.8699 - val_loss: 5.5582 - val_mae: 5.5582\n",
            "Epoch 1808/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8756 - mae: 11.8756 - val_loss: 5.5866 - val_mae: 5.5866\n",
            "Epoch 1809/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8736 - mae: 11.8736 - val_loss: 5.5721 - val_mae: 5.5721\n",
            "Epoch 1810/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8643 - mae: 11.8643 - val_loss: 5.5944 - val_mae: 5.5944\n",
            "Epoch 1811/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8654 - mae: 11.8654 - val_loss: 5.5516 - val_mae: 5.5516\n",
            "Epoch 1812/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8610 - mae: 11.8610 - val_loss: 5.5540 - val_mae: 5.5540\n",
            "Epoch 1813/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8609 - mae: 11.8609 - val_loss: 5.5456 - val_mae: 5.5456\n",
            "Epoch 1814/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.9025 - mae: 11.9025 - val_loss: 5.5679 - val_mae: 5.5679\n",
            "Epoch 1815/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8917 - mae: 11.8917 - val_loss: 5.6215 - val_mae: 5.6215\n",
            "Epoch 1816/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8905 - mae: 11.8905 - val_loss: 5.5359 - val_mae: 5.5359\n",
            "Epoch 1817/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8813 - mae: 11.8813 - val_loss: 5.5711 - val_mae: 5.5711\n",
            "Epoch 1818/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8721 - mae: 11.8721 - val_loss: 5.5880 - val_mae: 5.5880\n",
            "Epoch 1819/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8700 - mae: 11.8700 - val_loss: 5.5490 - val_mae: 5.5490\n",
            "Epoch 1820/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8557 - mae: 11.8557 - val_loss: 5.5390 - val_mae: 5.5390\n",
            "Epoch 1821/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8602 - mae: 11.8602 - val_loss: 5.5482 - val_mae: 5.5482\n",
            "Epoch 1822/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8587 - mae: 11.8587 - val_loss: 5.5334 - val_mae: 5.5334\n",
            "Epoch 1823/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8558 - mae: 11.8558 - val_loss: 5.5574 - val_mae: 5.5574\n",
            "Epoch 1824/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8661 - mae: 11.8661 - val_loss: 5.5547 - val_mae: 5.5547\n",
            "Epoch 1825/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8570 - mae: 11.8570 - val_loss: 5.5640 - val_mae: 5.5640\n",
            "Epoch 1826/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8701 - mae: 11.8701 - val_loss: 5.5557 - val_mae: 5.5557\n",
            "Epoch 1827/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8638 - mae: 11.8638 - val_loss: 5.5467 - val_mae: 5.5467\n",
            "Epoch 1828/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8617 - mae: 11.8617 - val_loss: 5.5568 - val_mae: 5.5568\n",
            "Epoch 1829/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8547 - mae: 11.8547 - val_loss: 5.5367 - val_mae: 5.5367\n",
            "Epoch 1830/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8507 - mae: 11.8507 - val_loss: 5.5708 - val_mae: 5.5708\n",
            "Epoch 1831/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8673 - mae: 11.8673 - val_loss: 5.5376 - val_mae: 5.5376\n",
            "Epoch 1832/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8462 - mae: 11.8462 - val_loss: 5.5275 - val_mae: 5.5275\n",
            "Epoch 1833/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8443 - mae: 11.8443 - val_loss: 5.5249 - val_mae: 5.5249\n",
            "Epoch 1834/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8415 - mae: 11.8415 - val_loss: 5.5290 - val_mae: 5.5290\n",
            "Epoch 1835/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8484 - mae: 11.8484 - val_loss: 5.5270 - val_mae: 5.5270\n",
            "Epoch 1836/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8473 - mae: 11.8473 - val_loss: 5.5508 - val_mae: 5.5508\n",
            "Epoch 1837/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8529 - mae: 11.8529 - val_loss: 5.5762 - val_mae: 5.5762\n",
            "Epoch 1838/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8654 - mae: 11.8654 - val_loss: 5.5357 - val_mae: 5.5357\n",
            "Epoch 1839/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8541 - mae: 11.8541 - val_loss: 5.5496 - val_mae: 5.5496\n",
            "Epoch 1840/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8585 - mae: 11.8585 - val_loss: 5.5612 - val_mae: 5.5612\n",
            "Epoch 1841/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8610 - mae: 11.8610 - val_loss: 5.5720 - val_mae: 5.5720\n",
            "Epoch 1842/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8835 - mae: 11.8835 - val_loss: 5.5877 - val_mae: 5.5877\n",
            "Epoch 1843/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8741 - mae: 11.8741 - val_loss: 5.5522 - val_mae: 5.5522\n",
            "Epoch 1844/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8701 - mae: 11.8701 - val_loss: 5.5557 - val_mae: 5.5557\n",
            "Epoch 1845/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8685 - mae: 11.8685 - val_loss: 5.5491 - val_mae: 5.5491\n",
            "Epoch 1846/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8579 - mae: 11.8579 - val_loss: 5.5560 - val_mae: 5.5560\n",
            "Epoch 1847/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8602 - mae: 11.8602 - val_loss: 5.5701 - val_mae: 5.5701\n",
            "Epoch 1848/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8729 - mae: 11.8729 - val_loss: 5.5631 - val_mae: 5.5631\n",
            "Epoch 1849/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8536 - mae: 11.8536 - val_loss: 5.5566 - val_mae: 5.5566\n",
            "Epoch 1850/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8507 - mae: 11.8507 - val_loss: 5.5710 - val_mae: 5.5710\n",
            "Epoch 1851/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8650 - mae: 11.8650 - val_loss: 5.5385 - val_mae: 5.5385\n",
            "Epoch 1852/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8553 - mae: 11.8553 - val_loss: 5.5566 - val_mae: 5.5566\n",
            "Epoch 1853/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8531 - mae: 11.8531 - val_loss: 5.5431 - val_mae: 5.5431\n",
            "Epoch 1854/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8786 - mae: 11.8786 - val_loss: 5.5604 - val_mae: 5.5604\n",
            "Epoch 1855/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8678 - mae: 11.8678 - val_loss: 5.5712 - val_mae: 5.5712\n",
            "Epoch 1856/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8749 - mae: 11.8749 - val_loss: 5.5906 - val_mae: 5.5906\n",
            "Epoch 1857/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8807 - mae: 11.8807 - val_loss: 5.5687 - val_mae: 5.5687\n",
            "Epoch 1858/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8759 - mae: 11.8759 - val_loss: 5.5642 - val_mae: 5.5642\n",
            "Epoch 1859/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8809 - mae: 11.8809 - val_loss: 5.6021 - val_mae: 5.6021\n",
            "Epoch 1860/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8732 - mae: 11.8732 - val_loss: 5.5604 - val_mae: 5.5604\n",
            "Epoch 1861/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8566 - mae: 11.8566 - val_loss: 5.5403 - val_mae: 5.5403\n",
            "Epoch 1862/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8765 - mae: 11.8765 - val_loss: 5.5525 - val_mae: 5.5525\n",
            "Epoch 1863/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8818 - mae: 11.8818 - val_loss: 5.5907 - val_mae: 5.5907\n",
            "Epoch 1864/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8681 - mae: 11.8681 - val_loss: 5.5424 - val_mae: 5.5424\n",
            "Epoch 1865/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8642 - mae: 11.8642 - val_loss: 5.5522 - val_mae: 5.5522\n",
            "Epoch 1866/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8540 - mae: 11.8540 - val_loss: 5.5387 - val_mae: 5.5387\n",
            "Epoch 1867/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8495 - mae: 11.8495 - val_loss: 5.5298 - val_mae: 5.5298\n",
            "Epoch 1868/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8441 - mae: 11.8441 - val_loss: 5.5197 - val_mae: 5.5197\n",
            "Epoch 1869/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8388 - mae: 11.8388 - val_loss: 5.5259 - val_mae: 5.5259\n",
            "Epoch 1870/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8397 - mae: 11.8397 - val_loss: 5.5382 - val_mae: 5.5382\n",
            "Epoch 1871/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8420 - mae: 11.8420 - val_loss: 5.5351 - val_mae: 5.5351\n",
            "Epoch 1872/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8474 - mae: 11.8474 - val_loss: 5.5299 - val_mae: 5.5299\n",
            "Epoch 1873/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8528 - mae: 11.8528 - val_loss: 5.5316 - val_mae: 5.5316\n",
            "Epoch 1874/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8836 - mae: 11.8836 - val_loss: 5.5571 - val_mae: 5.5571\n",
            "Epoch 1875/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8516 - mae: 11.8516 - val_loss: 5.5476 - val_mae: 5.5476\n",
            "Epoch 1876/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8832 - mae: 11.8832 - val_loss: 5.5653 - val_mae: 5.5653\n",
            "Epoch 1877/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8573 - mae: 11.8573 - val_loss: 5.5387 - val_mae: 5.5387\n",
            "Epoch 1878/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8453 - mae: 11.8453 - val_loss: 5.5548 - val_mae: 5.5548\n",
            "Epoch 1879/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8561 - mae: 11.8561 - val_loss: 5.5337 - val_mae: 5.5337\n",
            "Epoch 1880/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8548 - mae: 11.8548 - val_loss: 5.5473 - val_mae: 5.5473\n",
            "Epoch 1881/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8465 - mae: 11.8465 - val_loss: 5.5247 - val_mae: 5.5247\n",
            "Epoch 1882/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8491 - mae: 11.8491 - val_loss: 5.5357 - val_mae: 5.5357\n",
            "Epoch 1883/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8471 - mae: 11.8471 - val_loss: 5.5524 - val_mae: 5.5524\n",
            "Epoch 1884/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8497 - mae: 11.8497 - val_loss: 5.5212 - val_mae: 5.5212\n",
            "Epoch 1885/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8696 - mae: 11.8696 - val_loss: 5.5544 - val_mae: 5.5544\n",
            "Epoch 1886/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8837 - mae: 11.8837 - val_loss: 5.5768 - val_mae: 5.5768\n",
            "Epoch 1887/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8529 - mae: 11.8529 - val_loss: 5.5400 - val_mae: 5.5400\n",
            "Epoch 1888/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8541 - mae: 11.8541 - val_loss: 5.5764 - val_mae: 5.5764\n",
            "Epoch 1889/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8590 - mae: 11.8590 - val_loss: 5.5267 - val_mae: 5.5267\n",
            "Epoch 1890/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8409 - mae: 11.8409 - val_loss: 5.5231 - val_mae: 5.5231\n",
            "Epoch 1891/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8375 - mae: 11.8375 - val_loss: 5.5317 - val_mae: 5.5317\n",
            "Epoch 1892/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8470 - mae: 11.8470 - val_loss: 5.5236 - val_mae: 5.5236\n",
            "Epoch 1893/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8352 - mae: 11.8352 - val_loss: 5.5647 - val_mae: 5.5647\n",
            "Epoch 1894/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8583 - mae: 11.8583 - val_loss: 5.5363 - val_mae: 5.5363\n",
            "Epoch 1895/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8465 - mae: 11.8465 - val_loss: 5.5254 - val_mae: 5.5254\n",
            "Epoch 1896/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8487 - mae: 11.8487 - val_loss: 5.5297 - val_mae: 5.5297\n",
            "Epoch 1897/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8451 - mae: 11.8451 - val_loss: 5.5191 - val_mae: 5.5191\n",
            "Epoch 1898/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8382 - mae: 11.8382 - val_loss: 5.5235 - val_mae: 5.5235\n",
            "Epoch 1899/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8362 - mae: 11.8362 - val_loss: 5.5228 - val_mae: 5.5228\n",
            "Epoch 1900/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8399 - mae: 11.8399 - val_loss: 5.5348 - val_mae: 5.5348\n",
            "Epoch 1901/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8368 - mae: 11.8368 - val_loss: 5.5174 - val_mae: 5.5174\n",
            "Epoch 1902/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8325 - mae: 11.8325 - val_loss: 5.5176 - val_mae: 5.5176\n",
            "Epoch 1903/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8397 - mae: 11.8397 - val_loss: 5.5258 - val_mae: 5.5258\n",
            "Epoch 1904/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8426 - mae: 11.8426 - val_loss: 5.5420 - val_mae: 5.5420\n",
            "Epoch 1905/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8479 - mae: 11.8479 - val_loss: 5.5492 - val_mae: 5.5492\n",
            "Epoch 1906/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8522 - mae: 11.8522 - val_loss: 5.5264 - val_mae: 5.5264\n",
            "Epoch 1907/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8426 - mae: 11.8426 - val_loss: 5.5287 - val_mae: 5.5287\n",
            "Epoch 1908/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8478 - mae: 11.8478 - val_loss: 5.5275 - val_mae: 5.5275\n",
            "Epoch 1909/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8444 - mae: 11.8444 - val_loss: 5.5219 - val_mae: 5.5219\n",
            "Epoch 1910/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8363 - mae: 11.8363 - val_loss: 5.5220 - val_mae: 5.5220\n",
            "Epoch 1911/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8469 - mae: 11.8469 - val_loss: 5.5183 - val_mae: 5.5183\n",
            "Epoch 1912/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8703 - mae: 11.8703 - val_loss: 5.5363 - val_mae: 5.5363\n",
            "Epoch 1913/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8556 - mae: 11.8556 - val_loss: 5.5431 - val_mae: 5.5431\n",
            "Epoch 1914/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8484 - mae: 11.8484 - val_loss: 5.5235 - val_mae: 5.5235\n",
            "Epoch 1915/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8414 - mae: 11.8414 - val_loss: 5.5211 - val_mae: 5.5211\n",
            "Epoch 1916/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8451 - mae: 11.8451 - val_loss: 5.5376 - val_mae: 5.5376\n",
            "Epoch 1917/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8486 - mae: 11.8486 - val_loss: 5.5142 - val_mae: 5.5142\n",
            "Epoch 1918/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8526 - mae: 11.8526 - val_loss: 5.5502 - val_mae: 5.5502\n",
            "Epoch 1919/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8701 - mae: 11.8701 - val_loss: 5.5337 - val_mae: 5.5337\n",
            "Epoch 1920/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8596 - mae: 11.8596 - val_loss: 5.5638 - val_mae: 5.5638\n",
            "Epoch 1921/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8598 - mae: 11.8598 - val_loss: 5.5426 - val_mae: 5.5426\n",
            "Epoch 1922/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8425 - mae: 11.8425 - val_loss: 5.5521 - val_mae: 5.5521\n",
            "Epoch 1923/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8490 - mae: 11.8490 - val_loss: 5.5728 - val_mae: 5.5728\n",
            "Epoch 1924/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8455 - mae: 11.8455 - val_loss: 5.5983 - val_mae: 5.5983\n",
            "Epoch 1925/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8723 - mae: 11.8723 - val_loss: 5.5264 - val_mae: 5.5264\n",
            "Epoch 1926/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8479 - mae: 11.8479 - val_loss: 5.5244 - val_mae: 5.5244\n",
            "Epoch 1927/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8405 - mae: 11.8405 - val_loss: 5.5244 - val_mae: 5.5244\n",
            "Epoch 1928/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8433 - mae: 11.8433 - val_loss: 5.5282 - val_mae: 5.5282\n",
            "Epoch 1929/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8375 - mae: 11.8375 - val_loss: 5.5198 - val_mae: 5.5198\n",
            "Epoch 1930/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8380 - mae: 11.8380 - val_loss: 5.5149 - val_mae: 5.5149\n",
            "Epoch 1931/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8326 - mae: 11.8326 - val_loss: 5.5158 - val_mae: 5.5158\n",
            "Epoch 1932/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8348 - mae: 11.8348 - val_loss: 5.5284 - val_mae: 5.5284\n",
            "Epoch 1933/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8409 - mae: 11.8409 - val_loss: 5.5403 - val_mae: 5.5403\n",
            "Epoch 1934/2000\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 11.8559 - mae: 11.8559 - val_loss: 5.5279 - val_mae: 5.5279\n",
            "Epoch 1935/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8460 - mae: 11.8460 - val_loss: 5.5189 - val_mae: 5.5189\n",
            "Epoch 1936/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8417 - mae: 11.8417 - val_loss: 5.5343 - val_mae: 5.5343\n",
            "Epoch 1937/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8441 - mae: 11.8441 - val_loss: 5.5368 - val_mae: 5.5368\n",
            "Epoch 1938/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8465 - mae: 11.8465 - val_loss: 5.5291 - val_mae: 5.5291\n",
            "Epoch 1939/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8412 - mae: 11.8412 - val_loss: 5.5168 - val_mae: 5.5168\n",
            "Epoch 1940/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8345 - mae: 11.8345 - val_loss: 5.5138 - val_mae: 5.5138\n",
            "Epoch 1941/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8403 - mae: 11.8403 - val_loss: 5.5435 - val_mae: 5.5435\n",
            "Epoch 1942/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8513 - mae: 11.8513 - val_loss: 5.5408 - val_mae: 5.5408\n",
            "Epoch 1943/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8444 - mae: 11.8444 - val_loss: 5.5198 - val_mae: 5.5198\n",
            "Epoch 1944/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8511 - mae: 11.8511 - val_loss: 5.5394 - val_mae: 5.5394\n",
            "Epoch 1945/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8460 - mae: 11.8460 - val_loss: 5.5341 - val_mae: 5.5341\n",
            "Epoch 1946/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8429 - mae: 11.8429 - val_loss: 5.5408 - val_mae: 5.5408\n",
            "Epoch 1947/2000\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 11.8675 - mae: 11.8675 - val_loss: 5.5370 - val_mae: 5.5370\n",
            "Epoch 1948/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8636 - mae: 11.8636 - val_loss: 5.5337 - val_mae: 5.5337\n",
            "Epoch 1949/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8368 - mae: 11.8368 - val_loss: 5.5631 - val_mae: 5.5631\n",
            "Epoch 1950/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8471 - mae: 11.8471 - val_loss: 5.5530 - val_mae: 5.5530\n",
            "Epoch 1951/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8546 - mae: 11.8546 - val_loss: 5.5390 - val_mae: 5.5390\n",
            "Epoch 1952/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8506 - mae: 11.8506 - val_loss: 5.5395 - val_mae: 5.5395\n",
            "Epoch 1953/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8443 - mae: 11.8443 - val_loss: 5.5586 - val_mae: 5.5586\n",
            "Epoch 1954/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8506 - mae: 11.8506 - val_loss: 5.5313 - val_mae: 5.5313\n",
            "Epoch 1955/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8408 - mae: 11.8408 - val_loss: 5.5373 - val_mae: 5.5373\n",
            "Epoch 1956/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8515 - mae: 11.8515 - val_loss: 5.5260 - val_mae: 5.5260\n",
            "Epoch 1957/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8421 - mae: 11.8421 - val_loss: 5.5423 - val_mae: 5.5423\n",
            "Epoch 1958/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8575 - mae: 11.8575 - val_loss: 5.5461 - val_mae: 5.5461\n",
            "Epoch 1959/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8442 - mae: 11.8442 - val_loss: 5.5186 - val_mae: 5.5186\n",
            "Epoch 1960/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8453 - mae: 11.8453 - val_loss: 5.5238 - val_mae: 5.5238\n",
            "Epoch 1961/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8318 - mae: 11.8318 - val_loss: 5.5177 - val_mae: 5.5177\n",
            "Epoch 1962/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8374 - mae: 11.8374 - val_loss: 5.5167 - val_mae: 5.5167\n",
            "Epoch 1963/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8334 - mae: 11.8334 - val_loss: 5.5137 - val_mae: 5.5137\n",
            "Epoch 1964/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8370 - mae: 11.8370 - val_loss: 5.5290 - val_mae: 5.5290\n",
            "Epoch 1965/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8409 - mae: 11.8409 - val_loss: 5.5327 - val_mae: 5.5327\n",
            "Epoch 1966/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8322 - mae: 11.8322 - val_loss: 5.5148 - val_mae: 5.5148\n",
            "Epoch 1967/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8318 - mae: 11.8318 - val_loss: 5.5176 - val_mae: 5.5176\n",
            "Epoch 1968/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8364 - mae: 11.8364 - val_loss: 5.5234 - val_mae: 5.5234\n",
            "Epoch 1969/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8355 - mae: 11.8355 - val_loss: 5.5085 - val_mae: 5.5085\n",
            "Epoch 1970/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8288 - mae: 11.8288 - val_loss: 5.5117 - val_mae: 5.5117\n",
            "Epoch 1971/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8416 - mae: 11.8416 - val_loss: 5.5155 - val_mae: 5.5155\n",
            "Epoch 1972/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8433 - mae: 11.8433 - val_loss: 5.5484 - val_mae: 5.5484\n",
            "Epoch 1973/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8459 - mae: 11.8459 - val_loss: 5.5113 - val_mae: 5.5113\n",
            "Epoch 1974/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8414 - mae: 11.8414 - val_loss: 5.5171 - val_mae: 5.5171\n",
            "Epoch 1975/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8313 - mae: 11.8313 - val_loss: 5.5443 - val_mae: 5.5443\n",
            "Epoch 1976/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8388 - mae: 11.8388 - val_loss: 5.5208 - val_mae: 5.5208\n",
            "Epoch 1977/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8345 - mae: 11.8345 - val_loss: 5.5165 - val_mae: 5.5165\n",
            "Epoch 1978/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8318 - mae: 11.8318 - val_loss: 5.5125 - val_mae: 5.5125\n",
            "Epoch 1979/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8247 - mae: 11.8247 - val_loss: 5.5106 - val_mae: 5.5106\n",
            "Epoch 1980/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8357 - mae: 11.8357 - val_loss: 5.5589 - val_mae: 5.5589\n",
            "Epoch 1981/2000\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 11.8447 - mae: 11.8447 - val_loss: 5.5564 - val_mae: 5.5564\n",
            "Epoch 1982/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8430 - mae: 11.8430 - val_loss: 5.5131 - val_mae: 5.5131\n",
            "Epoch 1983/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8351 - mae: 11.8351 - val_loss: 5.5154 - val_mae: 5.5154\n",
            "Epoch 1984/2000\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 11.8363 - mae: 11.8363 - val_loss: 5.5395 - val_mae: 5.5395\n",
            "Epoch 1985/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8445 - mae: 11.8445 - val_loss: 5.5241 - val_mae: 5.5241\n",
            "Epoch 1986/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8432 - mae: 11.8432 - val_loss: 5.5397 - val_mae: 5.5397\n",
            "Epoch 1987/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8500 - mae: 11.8500 - val_loss: 5.5266 - val_mae: 5.5266\n",
            "Epoch 1988/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8607 - mae: 11.8607 - val_loss: 5.5623 - val_mae: 5.5623\n",
            "Epoch 1989/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8614 - mae: 11.8614 - val_loss: 5.5311 - val_mae: 5.5311\n",
            "Epoch 1990/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8428 - mae: 11.8428 - val_loss: 5.5518 - val_mae: 5.5518\n",
            "Epoch 1991/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8439 - mae: 11.8439 - val_loss: 5.5404 - val_mae: 5.5404\n",
            "Epoch 1992/2000\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 11.8375 - mae: 11.8375 - val_loss: 5.5568 - val_mae: 5.5568\n",
            "Epoch 1993/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8384 - mae: 11.8384 - val_loss: 5.5200 - val_mae: 5.5200\n",
            "Epoch 1994/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8306 - mae: 11.8306 - val_loss: 5.5193 - val_mae: 5.5193\n",
            "Epoch 1995/2000\n",
            "5/5 [==============================] - 0s 17ms/step - loss: 11.8358 - mae: 11.8358 - val_loss: 5.5222 - val_mae: 5.5222\n",
            "Epoch 1996/2000\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 11.8421 - mae: 11.8421 - val_loss: 5.5414 - val_mae: 5.5414\n",
            "Epoch 1997/2000\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 11.8405 - mae: 11.8405 - val_loss: 5.5547 - val_mae: 5.5547\n",
            "Epoch 1998/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8588 - mae: 11.8588 - val_loss: 5.5280 - val_mae: 5.5280\n",
            "Epoch 1999/2000\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 11.8364 - mae: 11.8364 - val_loss: 5.5354 - val_mae: 5.5354\n",
            "Epoch 2000/2000\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 11.8540 - mae: 11.8540 - val_loss: 5.5493 - val_mae: 5.5493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2auRvYetE3ss",
        "outputId": "65e4381b-24fc-494d-d494-7e94d59aca4e"
      },
      "source": [
        "# Evaluate model \n",
        "model.evaluate(X_test,y_test)"
      ],
      "id": "2auRvYetE3ss",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5493 - mae: 5.5493\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5.549330711364746, 5.549330711364746]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IWt3f0pVR-1"
      },
      "source": [
        "Converting dataframe into numpy array"
      ],
      "id": "-IWt3f0pVR-1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0v54l30znmA",
        "outputId": "0152177e-5d14-4bc5-e295-49d298a3331c"
      },
      "source": [
        "type(y_test)"
      ],
      "id": "M0v54l30znmA",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfBSqf4OzuBX"
      },
      "source": [
        "y_test=np.array(y_test)"
      ],
      "id": "mfBSqf4OzuBX",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqwmmFT38LM-"
      },
      "source": [
        "Plotting graph for Real data vs Predicted data"
      ],
      "id": "sqwmmFT38LM-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "9cd99315",
        "outputId": "65e18cd2-a93f-4ab5-96c3-06ab800e7ed5"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "print(type(y_pred))\n",
        "plt.plot(y_test, color = 'red', label = 'Real data')\n",
        "plt.plot(y_pred, color = 'black', label = 'Predicted data')\n",
        "plt.title('Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "id": "9cd99315",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdK-JQED8WnZ"
      },
      "source": [
        "Plotting graph for \n",
        "\n",
        "1.   Training & Validation Accuracy vs Epochs\n",
        "2.   Training & Validation Loss vs Epochs\n"
      ],
      "id": "HdK-JQED8WnZ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "8pZtiL8uCJG7",
        "outputId": "1bf65055-95dd-4828-fa50-81ed460da846"
      },
      "source": [
        "# For mae\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "accuracy = history_dict['mae']\n",
        "val_accuracy = history_dict['val_mae']\n",
        " \n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
        "\n",
        "# Plot the model accuracy (MAE) vs Epochs\n",
        "\n",
        "ax[0].plot(epochs, accuracy, 'b', label='Training accuracy',color=\"red\")\n",
        "ax[0].plot(epochs, val_accuracy, 'b', label='Validation accuracy',color=\"black\")\n",
        "ax[0].set_title('Training & Validation Accuracy', fontsize=16)\n",
        "ax[0].set_xlabel('Epochs', fontsize=16)\n",
        "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
        "ax[0].legend()\n",
        "\n",
        "# Plot the loss vs Epochs\n",
        "\n",
        "ax[1].plot(epochs, loss_values, 'b', label='Training loss',color=\"red\")\n",
        "ax[1].plot(epochs, val_loss_values, 'b', label='Validation loss',color=\"black\")\n",
        "ax[1].set_title('Training & Validation Loss', fontsize=16)\n",
        "ax[1].set_xlabel('Epochs', fontsize=16)\n",
        "ax[1].set_ylabel('Loss', fontsize=16)\n",
        "ax[1].legend()"
      ],
      "id": "8pZtiL8uCJG7",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f532a78a890>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWxcdHBy9yLR"
      },
      "source": [
        "Comparing Predicted data with Real data"
      ],
      "id": "wWxcdHBy9yLR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16e0d2fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e01320-85b3-4a16-9636-436b95a97863"
      },
      "source": [
        "for i in range(len(y_pred)):\n",
        "    print(\"Prediction =\",max([0.],y_pred[i]),\"Actual =\" ,y_test[i])"
      ],
      "id": "16e0d2fe",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction = [0.03841799] Actual = [0.]\n",
            "Prediction = [0.01868302] Actual = [0.]\n",
            "Prediction = [0.0450744] Actual = [0.]\n",
            "Prediction = [0.03529042] Actual = [0.]\n",
            "Prediction = [0.06111997] Actual = [0.]\n",
            "Prediction = [92.98658] Actual = [93.33284888]\n",
            "Prediction = [0.02401417] Actual = [0.]\n",
            "Prediction = [0.0525133] Actual = [0.]\n",
            "Prediction = [62.170017] Actual = [63.07122956]\n",
            "Prediction = [0.06411785] Actual = [0.]\n",
            "Prediction = [0.01072514] Actual = [0.]\n",
            "Prediction = [78.290886] Actual = [84.10493782]\n",
            "Prediction = [0.01070911] Actual = [0.]\n",
            "Prediction = [31.125204] Actual = [0.]\n",
            "Prediction = [0.07329285] Actual = [0.]\n",
            "Prediction = [73.679474] Actual = [73.99971561]\n",
            "Prediction = [42.502697] Actual = [42.85647607]\n",
            "Prediction = [11.26111] Actual = [69.07089942]\n",
            "Prediction = [75.84706] Actual = [76.51493959]\n",
            "Prediction = [0.02389544] Actual = [0.]\n",
            "Prediction = [0.01204658] Actual = [0.]\n",
            "Prediction = [0.00678778] Actual = [0.]\n",
            "Prediction = [0.03256047] Actual = [0.]\n",
            "Prediction = [0.05975199] Actual = [0.]\n",
            "Prediction = [0.03718972] Actual = [0.]\n",
            "Prediction = [76.59009] Actual = [77.12109355]\n",
            "Prediction = [0.00644648] Actual = [0.]\n",
            "Prediction = [0.0] Actual = [0.]\n",
            "Prediction = [0.04604566] Actual = [0.]\n",
            "Prediction = [0.03100407] Actual = [0.]\n",
            "Prediction = [0.04588026] Actual = [0.]\n",
            "Prediction = [90.96414] Actual = [90.78247643]\n",
            "Prediction = [0.03095901] Actual = [0.]\n",
            "Prediction = [82.17836] Actual = [82.4372817]\n",
            "Prediction = [31.847303] Actual = [31.5539306]\n",
            "Prediction = [38.522945] Actual = [0.]\n",
            "Prediction = [0.00374591] Actual = [0.]\n",
            "Prediction = [0.04216462] Actual = [0.]\n",
            "Prediction = [45.809544] Actual = [0.]\n",
            "Prediction = [38.22433] Actual = [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K8ed37b8-mp"
      },
      "source": [
        "Checking R2 score of our model"
      ],
      "id": "8K8ed37b8-mp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXNgw453Dew4",
        "outputId": "5d582f11-c4de-4657-9af3-816209b64c23"
      },
      "source": [
        "r2_score(y_test,model.predict(X_test))"
      ],
      "id": "xXNgw453Dew4",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7879418821802172"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYqGh8LU9Exd"
      },
      "source": [
        "Since model is working well so now, extracting weights and biases from model for implementing the forward pass in the Simulator."
      ],
      "id": "kYqGh8LU9Exd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT6sjYPDmmV0",
        "outputId": "f0071954-36bb-43cf-b30a-db6551e7bca8"
      },
      "source": [
        "model.weights"
      ],
      "id": "uT6sjYPDmmV0",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'dense_21/kernel:0' shape=(2, 7) dtype=float32, numpy=\n",
              " array([[-0.4151496 , -0.26421493,  0.3135231 , -1.2521678 , -0.48760554,\n",
              "         -0.61379135,  0.5947052 ],\n",
              "        [ 0.44373405, -0.00803267, -0.7766129 ,  0.93123084, -0.73851335,\n",
              "          0.18878712,  0.47466454]], dtype=float32)>,\n",
              " <tf.Variable 'dense_21/bias:0' shape=(7,) dtype=float32, numpy=\n",
              " array([-3.2539866 ,  0.        , -0.02472453, -3.6391356 ,  0.        ,\n",
              "         1.6801617 ,  2.4059265 ], dtype=float32)>,\n",
              " <tf.Variable 'dense_22/kernel:0' shape=(7, 9) dtype=float32, numpy=\n",
              " array([[ 0.5849904 , -0.19816121, -0.4910823 , -0.31706598, -0.3657042 ,\n",
              "         -0.27402547, -0.1582511 ,  0.53360426,  0.4281763 ],\n",
              "        [-0.56390417,  0.6891103 , -0.55388504,  0.15042147,  0.2743768 ,\n",
              "         -0.08655491, -0.2097642 , -0.06703684, -0.2367927 ],\n",
              "        [-0.00353913, -0.08639619,  0.10100517,  0.02635749, -0.0724325 ,\n",
              "          0.47995248,  0.2948826 ,  0.40263915,  0.08876697],\n",
              "        [ 0.9448879 ,  0.01231049, -1.2018261 , -0.06614713,  0.00811482,\n",
              "          0.0701426 , -0.9309507 ,  0.40564016,  0.5428177 ],\n",
              "        [-0.4239326 , -0.34418222, -0.23520783, -0.4604447 ,  0.6523544 ,\n",
              "          0.06492429,  0.21805646,  0.62056464,  0.29087767],\n",
              "        [-1.0454929 ,  0.3016038 , -0.28672296,  0.16849387, -0.1565325 ,\n",
              "          0.03756765, -1.4061453 , -1.3094757 , -1.3731613 ],\n",
              "        [-0.2022129 , -0.18989314,  0.27644405, -0.21372734, -0.49845544,\n",
              "         -0.00212658,  0.62326103,  0.33012542,  0.76410127]],\n",
              "       dtype=float32)>,\n",
              " <tf.Variable 'dense_22/bias:0' shape=(9,) dtype=float32, numpy=\n",
              " array([-3.0668378 ,  0.        ,  1.8701594 ,  0.        ,  0.        ,\n",
              "        -0.01298803,  0.58112186, -0.93002635, -1.089445  ], dtype=float32)>,\n",
              " <tf.Variable 'dense_23/kernel:0' shape=(9, 1) dtype=float32, numpy=\n",
              " array([[ 0.90990716],\n",
              "        [-0.2506563 ],\n",
              "        [ 1.1351497 ],\n",
              "        [-0.40106028],\n",
              "        [-0.46258327],\n",
              "        [-0.0830033 ],\n",
              "        [-1.0956517 ],\n",
              "        [ 0.5047472 ],\n",
              "        [ 0.26671278]], dtype=float32)>,\n",
              " <tf.Variable 'dense_23/bias:0' shape=(1,) dtype=float32, numpy=array([-0.7577006], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dadC1sYtA-5z"
      },
      "source": [
        "For regression model-\n",
        "\n",
        "$Y_{predicted}=W^T.X+b$\n",
        "\n",
        "So need to find transpose of weights for implementing forward pass(matrix multiplication)."
      ],
      "id": "dadC1sYtA-5z"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzZk0udBvlB"
      },
      "source": [
        "w1=np.array([[-0.4151496 , -0.26421493,  0.3135231 , -1.2521678 , -0.48760554,\n",
        "         -0.61379135,  0.5947052 ],\n",
        "        [ 0.44373405, -0.00803267, -0.7766129 ,  0.93123084, -0.73851335,\n",
        "          0.18878712,  0.47466454]])"
      ],
      "id": "XBzZk0udBvlB",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwUdu-gLB08C"
      },
      "source": [
        "w1_T=w1.T"
      ],
      "id": "zwUdu-gLB08C",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nBOmKPIB3-Z",
        "outputId": "fad418bf-8db8-4241-b508-f381490f6ad1"
      },
      "source": [
        "# w1 Transpose\n",
        "w1_T"
      ],
      "id": "1nBOmKPIB3-Z",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.4151496 ,  0.44373405],\n",
              "       [-0.26421493, -0.00803267],\n",
              "       [ 0.3135231 , -0.7766129 ],\n",
              "       [-1.2521678 ,  0.93123084],\n",
              "       [-0.48760554, -0.73851335],\n",
              "       [-0.61379135,  0.18878712],\n",
              "       [ 0.5947052 ,  0.47466454]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPqyVzZkEIjz"
      },
      "source": [
        "bias1=np.array([-3.2539866 , 0.0 , -0.02472453, -3.6391356 , 0.0 , 1.6801617 , 2.4059265])"
      ],
      "id": "DPqyVzZkEIjz",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXem4B27DXht"
      },
      "source": [
        "w2=np.array([[ 0.5849904 , -0.19816121, -0.4910823 , -0.31706598, -0.3657042 ,\n",
        "         -0.27402547, -0.1582511 ,  0.53360426,  0.4281763 ],\n",
        "        [-0.56390417,  0.6891103 , -0.55388504,  0.15042147,  0.2743768 ,\n",
        "         -0.08655491, -0.2097642 , -0.06703684, -0.2367927 ],\n",
        "        [-0.00353913, -0.08639619,  0.10100517,  0.02635749, -0.0724325 ,\n",
        "          0.47995248,  0.2948826 ,  0.40263915,  0.08876697],\n",
        "        [ 0.9448879 ,  0.01231049, -1.2018261 , -0.06614713,  0.00811482,\n",
        "          0.0701426 , -0.9309507 ,  0.40564016,  0.5428177 ],\n",
        "        [-0.4239326 , -0.34418222, -0.23520783, -0.4604447 ,  0.6523544 ,\n",
        "          0.06492429,  0.21805646,  0.62056464,  0.29087767],\n",
        "        [-1.0454929 ,  0.3016038 , -0.28672296,  0.16849387, -0.1565325 ,\n",
        "          0.03756765, -1.4061453 , -1.3094757 , -1.3731613 ],\n",
        "        [-0.2022129 , -0.18989314,  0.27644405, -0.21372734, -0.49845544,\n",
        "         -0.00212658,  0.62326103,  0.33012542,  0.76410127]])"
      ],
      "id": "lXem4B27DXht",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPepAiz_DXhu"
      },
      "source": [
        "w2_T=w2.T"
      ],
      "id": "QPepAiz_DXhu",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoUoB87WDXhv",
        "outputId": "ed2025dc-d662-44bb-8917-f1eab07fc193"
      },
      "source": [
        "# w2 Transpose\n",
        "w2_T"
      ],
      "id": "FoUoB87WDXhv",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5849904 , -0.56390417, -0.00353913,  0.9448879 , -0.4239326 ,\n",
              "        -1.0454929 , -0.2022129 ],\n",
              "       [-0.19816121,  0.6891103 , -0.08639619,  0.01231049, -0.34418222,\n",
              "         0.3016038 , -0.18989314],\n",
              "       [-0.4910823 , -0.55388504,  0.10100517, -1.2018261 , -0.23520783,\n",
              "        -0.28672296,  0.27644405],\n",
              "       [-0.31706598,  0.15042147,  0.02635749, -0.06614713, -0.4604447 ,\n",
              "         0.16849387, -0.21372734],\n",
              "       [-0.3657042 ,  0.2743768 , -0.0724325 ,  0.00811482,  0.6523544 ,\n",
              "        -0.1565325 , -0.49845544],\n",
              "       [-0.27402547, -0.08655491,  0.47995248,  0.0701426 ,  0.06492429,\n",
              "         0.03756765, -0.00212658],\n",
              "       [-0.1582511 , -0.2097642 ,  0.2948826 , -0.9309507 ,  0.21805646,\n",
              "        -1.4061453 ,  0.62326103],\n",
              "       [ 0.53360426, -0.06703684,  0.40263915,  0.40564016,  0.62056464,\n",
              "        -1.3094757 ,  0.33012542],\n",
              "       [ 0.4281763 , -0.2367927 ,  0.08876697,  0.5428177 ,  0.29087767,\n",
              "        -1.3731613 ,  0.76410127]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYBsl4y1EWhU"
      },
      "source": [
        "bias2=np.array([-3.0668378 , 0.0 , 1.8701594 , 0.0 , 0.0 , -0.01298803,  0.58112186, -0.93002635, -1.089445  ])"
      ],
      "id": "TYBsl4y1EWhU",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu0KwJoGDXwe"
      },
      "source": [
        "w3=np.array([[ 0.90990716],\n",
        "        [-0.2506563 ],\n",
        "        [ 1.1351497 ],\n",
        "        [-0.40106028],\n",
        "        [-0.46258327],\n",
        "        [-0.0830033 ],\n",
        "        [-1.0956517 ],\n",
        "        [ 0.5047472 ],\n",
        "        [ 0.26671278]])"
      ],
      "id": "bu0KwJoGDXwe",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RC8Mb5ZDXwf"
      },
      "source": [
        "w3_T=w3.T"
      ],
      "id": "4RC8Mb5ZDXwf",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNwwf3NfDXwg",
        "outputId": "9e6c6437-f3a5-4957-9f01-a8bd217012c1"
      },
      "source": [
        "# w3 Transpose\n",
        "w3_T"
      ],
      "id": "ZNwwf3NfDXwg",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.90990716, -0.2506563 ,  1.1351497 , -0.40106028, -0.46258327,\n",
              "        -0.0830033 , -1.0956517 ,  0.5047472 ,  0.26671278]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxVcdHgHEp0m"
      },
      "source": [
        "bias3=np.array([-0.7577006])"
      ],
      "id": "kxVcdHgHEp0m",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_gj1cGBECPV"
      },
      "source": [
        "Feeding this weights and biases in simulator."
      ],
      "id": "-_gj1cGBECPV"
    }
  ]
}